{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this notebook is to run an example experiment using the functions from `fsnet-tools.py` to illustrate it's intended use.\n",
    "\n",
    "# Data\n",
    "\n",
    "A wide toy dataset will be generated using `make_regression` from `sklearn`.  I'll then split off a test dataset, standardize, and split off a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# generate example regression dataset\n",
    "X, y = make_regression(n_samples=500, n_features=4000, n_informative=25)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape - X: (300, 4000) , y: (300,)\n",
      "valid shape - X: (100, 4000) , y: (100,)\n",
      "test shape - X: (100, 4000) , y: (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full_scaled, y_train_full)\n",
    "\n",
    "print(\"train shape - X:\", X_train.shape, \", y:\", y_train.shape)\n",
    "print(\"valid shape - X:\", X_valid.shape, \", y:\", y_valid.shape)\n",
    "print(\"test shape - X:\", X_test.shape, \", y:\", y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "Now I'll build the model using the newly created `fsnet-tools`.  `u_train` and `alpha` should be generated first, using the respective functions.  They will only need to be regenerated if `X_train` changes.  This is important to note, say, inside a cross-fold validation experiment.  \n",
    "\n",
    "It's also important that hyperparameters match between the various function calls.  Here, I'm defining a hyperparameter dictionary, as this is consistent with my typical model experiment workflow.  This method also lends itself well to hyperparameter tuning via optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fsnet_tools import get_utrain\n",
    "from fsnet_tools import get_alpha\n",
    "from fsnet_tools import build_model\n",
    "\n",
    "hps = {\n",
    "    \"bins\": 10,\n",
    "    \"min_temp\": 0.01,\n",
    "    \"start_temp\": 10.0,\n",
    "    \"num_epochs\": 500,\n",
    "    \"nfeat\": 50,\n",
    "    \"h_size\": 16,\n",
    "}\n",
    "\n",
    "u_train = get_utrain(X_train, bins=hps[\"bins\"])\n",
    "alpha = get_alpha(\n",
    "    X_train,\n",
    "    min_temp=hps[\"min_temp\"],\n",
    "    start_temp=hps[\"start_temp\"],\n",
    "    num_epochs=hps[\"num_epochs\"],\n",
    ")\n",
    "model = build_model(\n",
    "    num_inputs=X_train.shape[1],\n",
    "    nfeat=hps[\"nfeat\"],\n",
    "    u_train=u_train,\n",
    "    alpha=alpha,\n",
    "    h_size=hps[\"h_size\"],\n",
    "    bins=hps[\"bins\"],\n",
    "    start_temp=hps[\"start_temp\"],\n",
    "    min_temp=hps[\"min_temp\"],\n",
    "    num_epochs=hps[\"num_epochs\"],\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit\n",
    "\n",
    "Now I'll fit the data with the model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/500\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 97668.2273 - recon_loss: 1.0018 - reg_output_loss: 97568.0448 - recon_mean_squared_error: 1.0018 - reg_output_mean_squared_error: 97568.0448 - val_loss: 86327.6764 - val_recon_loss: 1.2337 - val_reg_output_loss: 86204.3052 - val_recon_mean_squared_error: 1.2337 - val_reg_output_mean_squared_error: 86204.3052\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 97659.1739 - recon_loss: 1.0033 - reg_output_loss: 97558.8434 - recon_mean_squared_error: 1.0033 - reg_output_mean_squared_error: 97558.8434 - val_loss: 86331.0055 - val_recon_loss: 1.3519 - val_reg_output_loss: 86195.8194 - val_recon_mean_squared_error: 1.3519 - val_reg_output_mean_squared_error: 86195.8194\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 97650.9131 - recon_loss: 1.0053 - reg_output_loss: 97550.3809 - recon_mean_squared_error: 1.0053 - reg_output_mean_squared_error: 97550.3809 - val_loss: 86392.3617 - val_recon_loss: 2.1147 - val_reg_output_loss: 86180.8923 - val_recon_mean_squared_error: 2.1147 - val_reg_output_mean_squared_error: 86180.8923\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 97638.5579 - recon_loss: 1.0104 - reg_output_loss: 97537.5178 - recon_mean_squared_error: 1.0104 - reg_output_mean_squared_error: 97537.5178 - val_loss: 86299.6383 - val_recon_loss: 1.3754 - val_reg_output_loss: 86162.1002 - val_recon_mean_squared_error: 1.3754 - val_reg_output_mean_squared_error: 86162.1002\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 97622.9033 - recon_loss: 1.0167 - reg_output_loss: 97521.2329 - recon_mean_squared_error: 1.0167 - reg_output_mean_squared_error: 97521.2329 - val_loss: 86263.8519 - val_recon_loss: 1.2383 - val_reg_output_loss: 86140.0209 - val_recon_mean_squared_error: 1.2383 - val_reg_output_mean_squared_error: 86140.0209\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 97608.2633 - recon_loss: 1.0151 - reg_output_loss: 97506.7583 - recon_mean_squared_error: 1.0151 - reg_output_mean_squared_error: 97506.7583 - val_loss: 86272.2205 - val_recon_loss: 1.6148 - val_reg_output_loss: 86110.7363 - val_recon_mean_squared_error: 1.6148 - val_reg_output_mean_squared_error: 86110.7363\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 97596.3587 - recon_loss: 1.0233 - reg_output_loss: 97494.0281 - recon_mean_squared_error: 1.0233 - reg_output_mean_squared_error: 97494.0281 - val_loss: 86208.4978 - val_recon_loss: 1.3180 - val_reg_output_loss: 86076.6942 - val_recon_mean_squared_error: 1.3180 - val_reg_output_mean_squared_error: 86076.6942\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 97552.7218 - recon_loss: 1.0284 - reg_output_loss: 97449.8859 - recon_mean_squared_error: 1.0284 - reg_output_mean_squared_error: 97449.8859 - val_loss: 86144.0202 - val_recon_loss: 1.1956 - val_reg_output_loss: 86024.4644 - val_recon_mean_squared_error: 1.1956 - val_reg_output_mean_squared_error: 86024.4644\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 97514.9739 - recon_loss: 1.0343 - reg_output_loss: 97411.5389 - recon_mean_squared_error: 1.0343 - reg_output_mean_squared_error: 97411.5389 - val_loss: 86078.0959 - val_recon_loss: 1.3172 - val_reg_output_loss: 85946.3802 - val_recon_mean_squared_error: 1.3172 - val_reg_output_mean_squared_error: 85946.3802\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 97491.3595 - recon_loss: 1.0590 - reg_output_loss: 97385.4620 - recon_mean_squared_error: 1.0590 - reg_output_mean_squared_error: 97385.4620 - val_loss: 86096.5330 - val_recon_loss: 1.9878 - val_reg_output_loss: 85897.7513 - val_recon_mean_squared_error: 1.9878 - val_reg_output_mean_squared_error: 85897.7513\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 97421.4195 - recon_loss: 1.0772 - reg_output_loss: 97313.7042 - recon_mean_squared_error: 1.0772 - reg_output_mean_squared_error: 97313.7042 - val_loss: 85989.2717 - val_recon_loss: 1.4363 - val_reg_output_loss: 85845.6475 - val_recon_mean_squared_error: 1.4363 - val_reg_output_mean_squared_error: 85845.6475\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 97405.6306 - recon_loss: 1.0745 - reg_output_loss: 97298.1837 - recon_mean_squared_error: 1.0745 - reg_output_mean_squared_error: 97298.1837 - val_loss: 85947.6248 - val_recon_loss: 1.6077 - val_reg_output_loss: 85786.8541 - val_recon_mean_squared_error: 1.6077 - val_reg_output_mean_squared_error: 85786.8541\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 97286.4731 - recon_loss: 1.1092 - reg_output_loss: 97175.5508 - recon_mean_squared_error: 1.1092 - reg_output_mean_squared_error: 97175.5508 - val_loss: 85889.8953 - val_recon_loss: 1.6763 - val_reg_output_loss: 85722.2697 - val_recon_mean_squared_error: 1.6763 - val_reg_output_mean_squared_error: 85722.2697\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 97154.9579 - recon_loss: 1.1177 - reg_output_loss: 97043.1893 - recon_mean_squared_error: 1.1177 - reg_output_mean_squared_error: 97043.1893 - val_loss: 85825.6219 - val_recon_loss: 1.6033 - val_reg_output_loss: 85665.2925 - val_recon_mean_squared_error: 1.6033 - val_reg_output_mean_squared_error: 85665.2925\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 97183.3153 - recon_loss: 1.1244 - reg_output_loss: 97070.8747 - recon_mean_squared_error: 1.1244 - reg_output_mean_squared_error: 97070.8747 - val_loss: 85816.1231 - val_recon_loss: 1.8838 - val_reg_output_loss: 85627.7461 - val_recon_mean_squared_error: 1.8838 - val_reg_output_mean_squared_error: 85627.7461\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 97114.6998 - recon_loss: 1.1635 - reg_output_loss: 96998.3518 - recon_mean_squared_error: 1.1635 - reg_output_mean_squared_error: 96998.3518 - val_loss: 85790.1483 - val_recon_loss: 1.6079 - val_reg_output_loss: 85629.3559 - val_recon_mean_squared_error: 1.6079 - val_reg_output_mean_squared_error: 85629.3559\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 96913.9448 - recon_loss: 1.1867 - reg_output_loss: 96795.2716 - recon_mean_squared_error: 1.1867 - reg_output_mean_squared_error: 96795.2716 - val_loss: 85863.4739 - val_recon_loss: 1.9875 - val_reg_output_loss: 85664.7197 - val_recon_mean_squared_error: 1.9875 - val_reg_output_mean_squared_error: 85664.7197\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 96898.2539 - recon_loss: 1.2662 - reg_output_loss: 96771.6312 - recon_mean_squared_error: 1.2662 - reg_output_mean_squared_error: 96771.6312 - val_loss: 85956.2797 - val_recon_loss: 2.2346 - val_reg_output_loss: 85732.8191 - val_recon_mean_squared_error: 2.2346 - val_reg_output_mean_squared_error: 85732.8191\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 96566.0320 - recon_loss: 1.1982 - reg_output_loss: 96446.2130 - recon_mean_squared_error: 1.1982 - reg_output_mean_squared_error: 96446.2130 - val_loss: 86107.3414 - val_recon_loss: 1.8416 - val_reg_output_loss: 85923.1780 - val_recon_mean_squared_error: 1.8416 - val_reg_output_mean_squared_error: 85923.1780\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 96424.4837 - recon_loss: 1.3136 - reg_output_loss: 96293.1280 - recon_mean_squared_error: 1.3136 - reg_output_mean_squared_error: 96293.1280 - val_loss: 86751.0513 - val_recon_loss: 5.9503 - val_reg_output_loss: 86156.0264 - val_recon_mean_squared_error: 5.9503 - val_reg_output_mean_squared_error: 86156.0264\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 96392.9887 - recon_loss: 1.3178 - reg_output_loss: 96261.2049 - recon_mean_squared_error: 1.3178 - reg_output_mean_squared_error: 96261.2049 - val_loss: 86705.4423 - val_recon_loss: 1.6042 - val_reg_output_loss: 86545.0178 - val_recon_mean_squared_error: 1.6042 - val_reg_output_mean_squared_error: 86545.0178\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 95994.7428 - recon_loss: 1.3466 - reg_output_loss: 95860.0842 - recon_mean_squared_error: 1.3466 - reg_output_mean_squared_error: 95860.0842 - val_loss: 87492.3592 - val_recon_loss: 2.3243 - val_reg_output_loss: 87259.9328 - val_recon_mean_squared_error: 2.3243 - val_reg_output_mean_squared_error: 87259.9328\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 96113.4930 - recon_loss: 1.5323 - reg_output_loss: 95960.2665 - recon_mean_squared_error: 1.5323 - reg_output_mean_squared_error: 95960.2665 - val_loss: 88058.2997 - val_recon_loss: 1.5800 - val_reg_output_loss: 87900.2969 - val_recon_mean_squared_error: 1.5800 - val_reg_output_mean_squared_error: 87900.2969\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 95865.5005 - recon_loss: 1.3933 - reg_output_loss: 95726.1724 - recon_mean_squared_error: 1.3933 - reg_output_mean_squared_error: 95726.1724 - val_loss: 89269.1944 - val_recon_loss: 4.6630 - val_reg_output_loss: 88802.8948 - val_recon_mean_squared_error: 4.6630 - val_reg_output_mean_squared_error: 88802.8948\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 95618.2865 - recon_loss: 1.6093 - reg_output_loss: 95457.3566 - recon_mean_squared_error: 1.6093 - reg_output_mean_squared_error: 95457.3566 - val_loss: 90673.6156 - val_recon_loss: 5.0687 - val_reg_output_loss: 90166.7519 - val_recon_mean_squared_error: 5.0687 - val_reg_output_mean_squared_error: 90166.7519\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 95183.9607 - recon_loss: 1.6071 - reg_output_loss: 95023.2485 - recon_mean_squared_error: 1.6071 - reg_output_mean_squared_error: 95023.2485 - val_loss: 91966.3017 - val_recon_loss: 1.9095 - val_reg_output_loss: 91775.3491 - val_recon_mean_squared_error: 1.9095 - val_reg_output_mean_squared_error: 91775.3491\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 95374.9408 - recon_loss: 1.5507 - reg_output_loss: 95219.8690 - recon_mean_squared_error: 1.5507 - reg_output_mean_squared_error: 95219.8690 - val_loss: 93816.6392 - val_recon_loss: 1.8524 - val_reg_output_loss: 93631.3984 - val_recon_mean_squared_error: 1.8524 - val_reg_output_mean_squared_error: 93631.3984\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 94779.6740 - recon_loss: 1.7494 - reg_output_loss: 94604.7329 - recon_mean_squared_error: 1.7494 - reg_output_mean_squared_error: 94604.7329 - val_loss: 95603.5116 - val_recon_loss: 1.6474 - val_reg_output_loss: 95438.7702 - val_recon_mean_squared_error: 1.6474 - val_reg_output_mean_squared_error: 95438.7702\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 94831.2485 - recon_loss: 1.6960 - reg_output_loss: 94661.6489 - recon_mean_squared_error: 1.6960 - reg_output_mean_squared_error: 94661.6489 - val_loss: 97969.6341 - val_recon_loss: 5.7698 - val_reg_output_loss: 97392.6503 - val_recon_mean_squared_error: 5.7698 - val_reg_output_mean_squared_error: 97392.6503\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 94522.5291 - recon_loss: 1.9172 - reg_output_loss: 94330.8141 - recon_mean_squared_error: 1.9172 - reg_output_mean_squared_error: 94330.8141 - val_loss: 100887.0094 - val_recon_loss: 3.9023 - val_reg_output_loss: 100496.7830 - val_recon_mean_squared_error: 3.9023 - val_reg_output_mean_squared_error: 100496.7830\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 94497.2417 - recon_loss: 1.7933 - reg_output_loss: 94317.9147 - recon_mean_squared_error: 1.7933 - reg_output_mean_squared_error: 94317.9147 - val_loss: 104461.4516 - val_recon_loss: 3.5331 - val_reg_output_loss: 104108.1438 - val_recon_mean_squared_error: 3.5331 - val_reg_output_mean_squared_error: 104108.1438\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 94221.4536 - recon_loss: 1.7722 - reg_output_loss: 94044.2334 - recon_mean_squared_error: 1.7722 - reg_output_mean_squared_error: 94044.2334 - val_loss: 108715.5152 - val_recon_loss: 9.7198 - val_reg_output_loss: 107743.5352 - val_recon_mean_squared_error: 9.7198 - val_reg_output_mean_squared_error: 107743.5352\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 93968.3306 - recon_loss: 2.2928 - reg_output_loss: 93739.0546 - recon_mean_squared_error: 2.2928 - reg_output_mean_squared_error: 93739.0546 - val_loss: 111668.1141 - val_recon_loss: 2.0368 - val_reg_output_loss: 111464.4319 - val_recon_mean_squared_error: 2.0368 - val_reg_output_mean_squared_error: 111464.4319\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 93776.5908 - recon_loss: 2.0751 - reg_output_loss: 93569.0791 - recon_mean_squared_error: 2.0751 - reg_output_mean_squared_error: 93569.0791 - val_loss: 116170.5412 - val_recon_loss: 1.4872 - val_reg_output_loss: 116021.8203 - val_recon_mean_squared_error: 1.4872 - val_reg_output_mean_squared_error: 116021.8203\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 93578.3887 - recon_loss: 1.7702 - reg_output_loss: 93401.3718 - recon_mean_squared_error: 1.7702 - reg_output_mean_squared_error: 93401.3718 - val_loss: 120004.5469 - val_recon_loss: 3.0758 - val_reg_output_loss: 119696.9694 - val_recon_mean_squared_error: 3.0758 - val_reg_output_mean_squared_error: 119696.9694\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 93771.7472 - recon_loss: 1.9458 - reg_output_loss: 93577.1699 - recon_mean_squared_error: 1.9458 - reg_output_mean_squared_error: 93577.1699 - val_loss: 123772.9959 - val_recon_loss: 3.3029 - val_reg_output_loss: 123442.7050 - val_recon_mean_squared_error: 3.3029 - val_reg_output_mean_squared_error: 123442.7050\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 92775.1785 - recon_loss: 2.2003 - reg_output_loss: 92555.1521 - recon_mean_squared_error: 2.2003 - reg_output_mean_squared_error: 92555.1521 - val_loss: 130602.3497 - val_recon_loss: 1.7018 - val_reg_output_loss: 130432.1684 - val_recon_mean_squared_error: 1.7018 - val_reg_output_mean_squared_error: 130432.1684\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 92908.6575 - recon_loss: 3.0616 - reg_output_loss: 92602.4969 - recon_mean_squared_error: 3.0616 - reg_output_mean_squared_error: 92602.4969 - val_loss: 135926.4028 - val_recon_loss: 4.0138 - val_reg_output_loss: 135525.0203 - val_recon_mean_squared_error: 4.0138 - val_reg_output_mean_squared_error: 135525.0203\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 92866.2772 - recon_loss: 2.4014 - reg_output_loss: 92626.1386 - recon_mean_squared_error: 2.4014 - reg_output_mean_squared_error: 92626.1386 - val_loss: 143715.0541 - val_recon_loss: 17.2415 - val_reg_output_loss: 141990.8997 - val_recon_mean_squared_error: 17.2415 - val_reg_output_mean_squared_error: 141990.8997\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 92791.6698 - recon_loss: 2.7211 - reg_output_loss: 92519.5593 - recon_mean_squared_error: 2.7211 - reg_output_mean_squared_error: 92519.5593 - val_loss: 150850.2853 - val_recon_loss: 24.9131 - val_reg_output_loss: 148358.9716 - val_recon_mean_squared_error: 24.9131 - val_reg_output_mean_squared_error: 148358.9716\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 91777.3559 - recon_loss: 2.1490 - reg_output_loss: 91562.4575 - recon_mean_squared_error: 2.1490 - reg_output_mean_squared_error: 91562.4575 - val_loss: 154548.2766 - val_recon_loss: 3.3921 - val_reg_output_loss: 154209.0659 - val_recon_mean_squared_error: 3.3921 - val_reg_output_mean_squared_error: 154209.0659\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 92084.1849 - recon_loss: 2.1220 - reg_output_loss: 91871.9799 - recon_mean_squared_error: 2.1220 - reg_output_mean_squared_error: 91871.9799 - val_loss: 162347.6150 - val_recon_loss: 3.0112 - val_reg_output_loss: 162046.4931 - val_recon_mean_squared_error: 3.0112 - val_reg_output_mean_squared_error: 162046.4931\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 92293.5361 - recon_loss: 1.8506 - reg_output_loss: 92108.4717 - recon_mean_squared_error: 1.8506 - reg_output_mean_squared_error: 92108.4717 - val_loss: 169231.8387 - val_recon_loss: 4.8557 - val_reg_output_loss: 168746.2706 - val_recon_mean_squared_error: 4.8557 - val_reg_output_mean_squared_error: 168746.2706\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 92275.6481 - recon_loss: 2.1047 - reg_output_loss: 92065.1818 - recon_mean_squared_error: 2.1047 - reg_output_mean_squared_error: 92065.1818 - val_loss: 176122.8988 - val_recon_loss: 6.0015 - val_reg_output_loss: 175522.7506 - val_recon_mean_squared_error: 6.0015 - val_reg_output_mean_squared_error: 175522.7506\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 91599.5699 - recon_loss: 2.2242 - reg_output_loss: 91377.1550 - recon_mean_squared_error: 2.2242 - reg_output_mean_squared_error: 91377.1550 - val_loss: 184720.8969 - val_recon_loss: 2.0853 - val_reg_output_loss: 184512.3700 - val_recon_mean_squared_error: 2.0853 - val_reg_output_mean_squared_error: 184512.3700\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91489.0742 - recon_loss: 2.1139 - reg_output_loss: 91277.6829 - recon_mean_squared_error: 2.1139 - reg_output_mean_squared_error: 91277.6829 - val_loss: 192628.3306 - val_recon_loss: 6.0516 - val_reg_output_loss: 192023.1663 - val_recon_mean_squared_error: 6.0516 - val_reg_output_mean_squared_error: 192023.1663\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 92462.6365 - recon_loss: 2.2685 - reg_output_loss: 92235.7883 - recon_mean_squared_error: 2.2685 - reg_output_mean_squared_error: 92235.7883 - val_loss: 196147.6125 - val_recon_loss: 9.0313 - val_reg_output_loss: 195244.4788 - val_recon_mean_squared_error: 9.0313 - val_reg_output_mean_squared_error: 195244.4788\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 91940.9225 - recon_loss: 2.8751 - reg_output_loss: 91653.4115 - recon_mean_squared_error: 2.8751 - reg_output_mean_squared_error: 91653.4115 - val_loss: 201116.6050 - val_recon_loss: 1.4833 - val_reg_output_loss: 200968.2700 - val_recon_mean_squared_error: 1.4833 - val_reg_output_mean_squared_error: 200968.2700\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 91545.3901 - recon_loss: 2.2854 - reg_output_loss: 91316.8513 - recon_mean_squared_error: 2.2854 - reg_output_mean_squared_error: 91316.8513 - val_loss: 208728.6706 - val_recon_loss: 4.0169 - val_reg_output_loss: 208326.9838 - val_recon_mean_squared_error: 4.0169 - val_reg_output_mean_squared_error: 208326.9838\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91486.5537 - recon_loss: 2.4560 - reg_output_loss: 91240.9508 - recon_mean_squared_error: 2.4560 - reg_output_mean_squared_error: 91240.9508 - val_loss: 215055.9519 - val_recon_loss: 15.3509 - val_reg_output_loss: 213520.8619 - val_recon_mean_squared_error: 15.3509 - val_reg_output_mean_squared_error: 213520.8619\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 91376.8705 - recon_loss: 2.5521 - reg_output_loss: 91121.6616 - recon_mean_squared_error: 2.5521 - reg_output_mean_squared_error: 91121.6616 - val_loss: 218908.6206 - val_recon_loss: 1.2744 - val_reg_output_loss: 218781.1875 - val_recon_mean_squared_error: 1.2744 - val_reg_output_mean_squared_error: 218781.1875\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 92390.7133 - recon_loss: 2.8882 - reg_output_loss: 92101.8946 - recon_mean_squared_error: 2.8882 - reg_output_mean_squared_error: 92101.8946 - val_loss: 227109.1806 - val_recon_loss: 9.4371 - val_reg_output_loss: 226165.4744 - val_recon_mean_squared_error: 9.4371 - val_reg_output_mean_squared_error: 226165.4744\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91095.4751 - recon_loss: 2.1122 - reg_output_loss: 90884.2516 - recon_mean_squared_error: 2.1122 - reg_output_mean_squared_error: 90884.2516 - val_loss: 234689.1694 - val_recon_loss: 2.4277 - val_reg_output_loss: 234446.4075 - val_recon_mean_squared_error: 2.4277 - val_reg_output_mean_squared_error: 234446.4075\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 92342.1568 - recon_loss: 1.9940 - reg_output_loss: 92142.7541 - recon_mean_squared_error: 1.9940 - reg_output_mean_squared_error: 92142.7541 - val_loss: 237975.8238 - val_recon_loss: 40.8390 - val_reg_output_loss: 233891.9237 - val_recon_mean_squared_error: 40.8390 - val_reg_output_mean_squared_error: 233891.9237\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 91912.3029 - recon_loss: 2.2135 - reg_output_loss: 91690.9538 - recon_mean_squared_error: 2.2135 - reg_output_mean_squared_error: 91690.9538 - val_loss: 239658.1169 - val_recon_loss: 2.6318 - val_reg_output_loss: 239394.9337 - val_recon_mean_squared_error: 2.6318 - val_reg_output_mean_squared_error: 239394.9337\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91231.7677 - recon_loss: 2.6131 - reg_output_loss: 90970.4527 - recon_mean_squared_error: 2.6131 - reg_output_mean_squared_error: 90970.4527 - val_loss: 246010.0494 - val_recon_loss: 1.4079 - val_reg_output_loss: 245869.2550 - val_recon_mean_squared_error: 1.4079 - val_reg_output_mean_squared_error: 245869.2550\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 91391.1710 - recon_loss: 2.1783 - reg_output_loss: 91173.3371 - recon_mean_squared_error: 2.1783 - reg_output_mean_squared_error: 91173.3371 - val_loss: 257145.5344 - val_recon_loss: 2.6692 - val_reg_output_loss: 256878.6112 - val_recon_mean_squared_error: 2.6692 - val_reg_output_mean_squared_error: 256878.6112\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91295.3094 - recon_loss: 2.4939 - reg_output_loss: 91045.9181 - recon_mean_squared_error: 2.4939 - reg_output_mean_squared_error: 91045.9181 - val_loss: 255968.7019 - val_recon_loss: 1.4188 - val_reg_output_loss: 255826.8156 - val_recon_mean_squared_error: 1.4188 - val_reg_output_mean_squared_error: 255826.8156\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 207us/step - loss: 90907.6285 - recon_loss: 1.9344 - reg_output_loss: 90714.1874 - recon_mean_squared_error: 1.9344 - reg_output_mean_squared_error: 90714.1874 - val_loss: 266599.3212 - val_recon_loss: 8.8203 - val_reg_output_loss: 265717.2938 - val_recon_mean_squared_error: 8.8203 - val_reg_output_mean_squared_error: 265717.2938\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91185.9965 - recon_loss: 2.4393 - reg_output_loss: 90942.0685 - recon_mean_squared_error: 2.4393 - reg_output_mean_squared_error: 90942.0685 - val_loss: 267500.0750 - val_recon_loss: 2.5274 - val_reg_output_loss: 267247.3262 - val_recon_mean_squared_error: 2.5274 - val_reg_output_mean_squared_error: 267247.3262\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 91676.0272 - recon_loss: 2.9080 - reg_output_loss: 91385.2275 - recon_mean_squared_error: 2.9080 - reg_output_mean_squared_error: 91385.2275 - val_loss: 265252.9725 - val_recon_loss: 2.6793 - val_reg_output_loss: 264985.0475 - val_recon_mean_squared_error: 2.6793 - val_reg_output_mean_squared_error: 264985.0475\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 90610.8897 - recon_loss: 2.2414 - reg_output_loss: 90386.7496 - recon_mean_squared_error: 2.2414 - reg_output_mean_squared_error: 90386.7496 - val_loss: 267303.0988 - val_recon_loss: 1.7511 - val_reg_output_loss: 267127.9838 - val_recon_mean_squared_error: 1.7511 - val_reg_output_mean_squared_error: 267127.9838\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 90796.7554 - recon_loss: 2.3696 - reg_output_loss: 90559.7926 - recon_mean_squared_error: 2.3696 - reg_output_mean_squared_error: 90559.7926 - val_loss: 274273.0363 - val_recon_loss: 3.6309 - val_reg_output_loss: 273909.9462 - val_recon_mean_squared_error: 3.6309 - val_reg_output_mean_squared_error: 273909.9462\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 90866.5979 - recon_loss: 2.1284 - reg_output_loss: 90653.7617 - recon_mean_squared_error: 2.1284 - reg_output_mean_squared_error: 90653.7617 - val_loss: 281090.4800 - val_recon_loss: 1.7491 - val_reg_output_loss: 280915.5737 - val_recon_mean_squared_error: 1.7491 - val_reg_output_mean_squared_error: 280915.5737\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 91100.8985 - recon_loss: 3.2120 - reg_output_loss: 90779.7026 - recon_mean_squared_error: 3.2120 - reg_output_mean_squared_error: 90779.7026 - val_loss: 288063.9062 - val_recon_loss: 2.9784 - val_reg_output_loss: 287766.0712 - val_recon_mean_squared_error: 2.9784 - val_reg_output_mean_squared_error: 287766.0712\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90142.6265 - recon_loss: 1.9478 - reg_output_loss: 89947.8480 - recon_mean_squared_error: 1.9478 - reg_output_mean_squared_error: 89947.8480 - val_loss: 291990.0588 - val_recon_loss: 2.2288 - val_reg_output_loss: 291767.1850 - val_recon_mean_squared_error: 2.2288 - val_reg_output_mean_squared_error: 291767.1850\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 89976.7889 - recon_loss: 1.9945 - reg_output_loss: 89777.3400 - recon_mean_squared_error: 1.9945 - reg_output_mean_squared_error: 89777.3400 - val_loss: 295071.3337 - val_recon_loss: 7.0679 - val_reg_output_loss: 294364.5463 - val_recon_mean_squared_error: 7.0679 - val_reg_output_mean_squared_error: 294364.5463\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90882.1322 - recon_loss: 2.1456 - reg_output_loss: 90667.5732 - recon_mean_squared_error: 2.1456 - reg_output_mean_squared_error: 90667.5732 - val_loss: 298992.7562 - val_recon_loss: 1.6066 - val_reg_output_loss: 298832.0975 - val_recon_mean_squared_error: 1.6066 - val_reg_output_mean_squared_error: 298832.0975\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 90646.0339 - recon_loss: 1.8024 - reg_output_loss: 90465.7960 - recon_mean_squared_error: 1.8024 - reg_output_mean_squared_error: 90465.7960 - val_loss: 302510.2150 - val_recon_loss: 9.1040 - val_reg_output_loss: 301599.8125 - val_recon_mean_squared_error: 9.1040 - val_reg_output_mean_squared_error: 301599.8125\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 89894.1871 - recon_loss: 2.0346 - reg_output_loss: 89690.7295 - recon_mean_squared_error: 2.0346 - reg_output_mean_squared_error: 89690.7295 - val_loss: 306528.4275 - val_recon_loss: 7.9483 - val_reg_output_loss: 305733.6038 - val_recon_mean_squared_error: 7.9483 - val_reg_output_mean_squared_error: 305733.6038\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90295.8628 - recon_loss: 2.0966 - reg_output_loss: 90086.2047 - recon_mean_squared_error: 2.0966 - reg_output_mean_squared_error: 90086.2047 - val_loss: 309017.9012 - val_recon_loss: 1.2725 - val_reg_output_loss: 308890.6588 - val_recon_mean_squared_error: 1.2725 - val_reg_output_mean_squared_error: 308890.6588\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 89556.3161 - recon_loss: 1.7787 - reg_output_loss: 89378.4428 - recon_mean_squared_error: 1.7787 - reg_output_mean_squared_error: 89378.4428 - val_loss: 318021.4500 - val_recon_loss: 21.2376 - val_reg_output_loss: 315897.6863 - val_recon_mean_squared_error: 21.2376 - val_reg_output_mean_squared_error: 315897.6863\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 90624.1102 - recon_loss: 2.4687 - reg_output_loss: 90377.2433 - recon_mean_squared_error: 2.4687 - reg_output_mean_squared_error: 90377.2433 - val_loss: 316087.1925 - val_recon_loss: 1.7281 - val_reg_output_loss: 315914.3850 - val_recon_mean_squared_error: 1.7281 - val_reg_output_mean_squared_error: 315914.3850\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90941.8877 - recon_loss: 1.7262 - reg_output_loss: 90769.2642 - recon_mean_squared_error: 1.7262 - reg_output_mean_squared_error: 90769.2642 - val_loss: 318451.1163 - val_recon_loss: 1.2750 - val_reg_output_loss: 318323.6163 - val_recon_mean_squared_error: 1.2750 - val_reg_output_mean_squared_error: 318323.6163\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90488.5257 - recon_loss: 2.0642 - reg_output_loss: 90282.1016 - recon_mean_squared_error: 2.0642 - reg_output_mean_squared_error: 90282.1016 - val_loss: 315247.6475 - val_recon_loss: 1.9667 - val_reg_output_loss: 315050.9775 - val_recon_mean_squared_error: 1.9667 - val_reg_output_mean_squared_error: 315050.9775\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 90179.0532 - recon_loss: 1.8475 - reg_output_loss: 89994.3084 - recon_mean_squared_error: 1.8475 - reg_output_mean_squared_error: 89994.3084 - val_loss: 323289.6625 - val_recon_loss: 1.3544 - val_reg_output_loss: 323154.2275 - val_recon_mean_squared_error: 1.3544 - val_reg_output_mean_squared_error: 323154.2275\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 90320.3442 - recon_loss: 2.2443 - reg_output_loss: 90095.9141 - recon_mean_squared_error: 2.2443 - reg_output_mean_squared_error: 90095.9141 - val_loss: 317451.5938 - val_recon_loss: 1.2393 - val_reg_output_loss: 317327.6625 - val_recon_mean_squared_error: 1.2393 - val_reg_output_mean_squared_error: 317327.6625\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 91466.3003 - recon_loss: 1.6909 - reg_output_loss: 91297.2101 - recon_mean_squared_error: 1.6909 - reg_output_mean_squared_error: 91297.2101 - val_loss: 314086.5250 - val_recon_loss: 7.2403 - val_reg_output_loss: 313362.4925 - val_recon_mean_squared_error: 7.2403 - val_reg_output_mean_squared_error: 313362.4925\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 89420.7782 - recon_loss: 1.6640 - reg_output_loss: 89254.3779 - recon_mean_squared_error: 1.6640 - reg_output_mean_squared_error: 89254.3779 - val_loss: 322467.1387 - val_recon_loss: 2.1363 - val_reg_output_loss: 322253.5137 - val_recon_mean_squared_error: 2.1363 - val_reg_output_mean_squared_error: 322253.5137\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90969.2402 - recon_loss: 1.5203 - reg_output_loss: 90817.2149 - recon_mean_squared_error: 1.5203 - reg_output_mean_squared_error: 90817.2149 - val_loss: 315170.0875 - val_recon_loss: 8.7982 - val_reg_output_loss: 314290.2700 - val_recon_mean_squared_error: 8.7982 - val_reg_output_mean_squared_error: 314290.2700\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90791.3099 - recon_loss: 1.8728 - reg_output_loss: 90604.0312 - recon_mean_squared_error: 1.8728 - reg_output_mean_squared_error: 90604.0312 - val_loss: 318034.6675 - val_recon_loss: 1.7399 - val_reg_output_loss: 317860.6763 - val_recon_mean_squared_error: 1.7399 - val_reg_output_mean_squared_error: 317860.6763\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 90958.6080 - recon_loss: 2.1497 - reg_output_loss: 90743.6401 - recon_mean_squared_error: 2.1497 - reg_output_mean_squared_error: 90743.6401 - val_loss: 318735.1412 - val_recon_loss: 2.0899 - val_reg_output_loss: 318526.1525 - val_recon_mean_squared_error: 2.0899 - val_reg_output_mean_squared_error: 318526.1525\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 90908.1855 - recon_loss: 1.8967 - reg_output_loss: 90718.5197 - recon_mean_squared_error: 1.8967 - reg_output_mean_squared_error: 90718.5197 - val_loss: 314447.5025 - val_recon_loss: 1.3164 - val_reg_output_loss: 314315.8538 - val_recon_mean_squared_error: 1.3164 - val_reg_output_mean_squared_error: 314315.8538\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90607.9016 - recon_loss: 1.5609 - reg_output_loss: 90451.8066 - recon_mean_squared_error: 1.5609 - reg_output_mean_squared_error: 90451.8066 - val_loss: 317015.8337 - val_recon_loss: 1.4590 - val_reg_output_loss: 316869.9375 - val_recon_mean_squared_error: 1.4590 - val_reg_output_mean_squared_error: 316869.9375\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 89920.5569 - recon_loss: 1.8579 - reg_output_loss: 89734.7633 - recon_mean_squared_error: 1.8579 - reg_output_mean_squared_error: 89734.7633 - val_loss: 319157.4738 - val_recon_loss: 1.2827 - val_reg_output_loss: 319029.2137 - val_recon_mean_squared_error: 1.2827 - val_reg_output_mean_squared_error: 319029.2137\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 90013.5897 - recon_loss: 1.4926 - reg_output_loss: 89864.3259 - recon_mean_squared_error: 1.4926 - reg_output_mean_squared_error: 89864.3259 - val_loss: 324833.4550 - val_recon_loss: 1.3209 - val_reg_output_loss: 324701.3663 - val_recon_mean_squared_error: 1.3209 - val_reg_output_mean_squared_error: 324701.3663\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 89932.5773 - recon_loss: 1.5322 - reg_output_loss: 89779.3567 - recon_mean_squared_error: 1.5322 - reg_output_mean_squared_error: 89779.3567 - val_loss: 326850.5475 - val_recon_loss: 17.4472 - val_reg_output_loss: 325105.8275 - val_recon_mean_squared_error: 17.4472 - val_reg_output_mean_squared_error: 325105.8275\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 88997.3961 - recon_loss: 2.2754 - reg_output_loss: 88769.8570 - recon_mean_squared_error: 2.2754 - reg_output_mean_squared_error: 88769.8570 - val_loss: 329010.8275 - val_recon_loss: 1.3085 - val_reg_output_loss: 328879.9788 - val_recon_mean_squared_error: 1.3085 - val_reg_output_mean_squared_error: 328879.9788\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90472.5350 - recon_loss: 1.5737 - reg_output_loss: 90315.1687 - recon_mean_squared_error: 1.5737 - reg_output_mean_squared_error: 90315.1687 - val_loss: 331836.6537 - val_recon_loss: 1.1806 - val_reg_output_loss: 331718.5975 - val_recon_mean_squared_error: 1.1806 - val_reg_output_mean_squared_error: 331718.5975\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 90431.5794 - recon_loss: 1.4402 - reg_output_loss: 90287.5592 - recon_mean_squared_error: 1.4402 - reg_output_mean_squared_error: 90287.5592 - val_loss: 327504.9738 - val_recon_loss: 30.2075 - val_reg_output_loss: 324484.2238 - val_recon_mean_squared_error: 30.2075 - val_reg_output_mean_squared_error: 324484.2238\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 91065.3570 - recon_loss: 1.9749 - reg_output_loss: 90867.8701 - recon_mean_squared_error: 1.9749 - reg_output_mean_squared_error: 90867.8701 - val_loss: 323934.0938 - val_recon_loss: 2.3175 - val_reg_output_loss: 323702.3475 - val_recon_mean_squared_error: 2.3175 - val_reg_output_mean_squared_error: 323702.3475\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 88993.7705 - recon_loss: 1.6130 - reg_output_loss: 88832.4651 - recon_mean_squared_error: 1.6130 - reg_output_mean_squared_error: 88832.4651 - val_loss: 325354.7338 - val_recon_loss: 1.9387 - val_reg_output_loss: 325160.8675 - val_recon_mean_squared_error: 1.9387 - val_reg_output_mean_squared_error: 325160.8675\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 90490.8821 - recon_loss: 1.6267 - reg_output_loss: 90328.2166 - recon_mean_squared_error: 1.6267 - reg_output_mean_squared_error: 90328.2166 - val_loss: 328567.8850 - val_recon_loss: 9.2224 - val_reg_output_loss: 327645.6387 - val_recon_mean_squared_error: 9.2224 - val_reg_output_mean_squared_error: 327645.6387\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 89071.1862 - recon_loss: 1.6004 - reg_output_loss: 88911.1426 - recon_mean_squared_error: 1.6004 - reg_output_mean_squared_error: 88911.1426 - val_loss: 329623.1850 - val_recon_loss: 1.2403 - val_reg_output_loss: 329499.1600 - val_recon_mean_squared_error: 1.2403 - val_reg_output_mean_squared_error: 329499.1600\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 90855.2626 - recon_loss: 1.6764 - reg_output_loss: 90687.6199 - recon_mean_squared_error: 1.6764 - reg_output_mean_squared_error: 90687.6199 - val_loss: 326121.9487 - val_recon_loss: 9.9216 - val_reg_output_loss: 325129.7850 - val_recon_mean_squared_error: 9.9216 - val_reg_output_mean_squared_error: 325129.7850\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 89129.9209 - recon_loss: 1.5866 - reg_output_loss: 88971.2617 - recon_mean_squared_error: 1.5866 - reg_output_mean_squared_error: 88971.2617 - val_loss: 327836.5275 - val_recon_loss: 14.0332 - val_reg_output_loss: 326433.2125 - val_recon_mean_squared_error: 14.0332 - val_reg_output_mean_squared_error: 326433.2125\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 89539.9395 - recon_loss: 1.9910 - reg_output_loss: 89340.8390 - recon_mean_squared_error: 1.9910 - reg_output_mean_squared_error: 89340.8390 - val_loss: 326453.5112 - val_recon_loss: 8.8650 - val_reg_output_loss: 325567.0025 - val_recon_mean_squared_error: 8.8650 - val_reg_output_mean_squared_error: 325567.0025\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 89388.3384 - recon_loss: 1.5863 - reg_output_loss: 89229.7126 - recon_mean_squared_error: 1.5863 - reg_output_mean_squared_error: 89229.7126 - val_loss: 327801.8000 - val_recon_loss: 1.2575 - val_reg_output_loss: 327676.0550 - val_recon_mean_squared_error: 1.2575 - val_reg_output_mean_squared_error: 327676.0550\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88786.7768 - recon_loss: 1.3501 - reg_output_loss: 88651.7634 - recon_mean_squared_error: 1.3501 - reg_output_mean_squared_error: 88651.7634 - val_loss: 337819.7500 - val_recon_loss: 1.4680 - val_reg_output_loss: 337672.9450 - val_recon_mean_squared_error: 1.4680 - val_reg_output_mean_squared_error: 337672.9450\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 89141.4115 - recon_loss: 1.6165 - reg_output_loss: 88979.7568 - recon_mean_squared_error: 1.6165 - reg_output_mean_squared_error: 88979.7568 - val_loss: 333554.3475 - val_recon_loss: 4.8279 - val_reg_output_loss: 333071.5538 - val_recon_mean_squared_error: 4.8279 - val_reg_output_mean_squared_error: 333071.5538\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 89162.2845 - recon_loss: 1.5212 - reg_output_loss: 89010.1627 - recon_mean_squared_error: 1.5212 - reg_output_mean_squared_error: 89010.1627 - val_loss: 337802.1700 - val_recon_loss: 2.9815 - val_reg_output_loss: 337504.0237 - val_recon_mean_squared_error: 2.9815 - val_reg_output_mean_squared_error: 337504.0237\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 89369.9189 - recon_loss: 1.6894 - reg_output_loss: 89200.9761 - recon_mean_squared_error: 1.6894 - reg_output_mean_squared_error: 89200.9761 - val_loss: 342362.1937 - val_recon_loss: 1.1040 - val_reg_output_loss: 342251.7938 - val_recon_mean_squared_error: 1.1040 - val_reg_output_mean_squared_error: 342251.7938\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 89921.3938 - recon_loss: 1.4738 - reg_output_loss: 89774.0113 - recon_mean_squared_error: 1.4738 - reg_output_mean_squared_error: 89774.0113 - val_loss: 339920.2675 - val_recon_loss: 1.1374 - val_reg_output_loss: 339806.5212 - val_recon_mean_squared_error: 1.1374 - val_reg_output_mean_squared_error: 339806.5212\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 90434.6898 - recon_loss: 1.3182 - reg_output_loss: 90302.8739 - recon_mean_squared_error: 1.3182 - reg_output_mean_squared_error: 90302.8739 - val_loss: 332735.0312 - val_recon_loss: 1.0584 - val_reg_output_loss: 332629.1987 - val_recon_mean_squared_error: 1.0584 - val_reg_output_mean_squared_error: 332629.1987\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 89265.0285 - recon_loss: 1.5796 - reg_output_loss: 89107.0653 - recon_mean_squared_error: 1.5796 - reg_output_mean_squared_error: 89107.0653 - val_loss: 332577.1412 - val_recon_loss: 1.4708 - val_reg_output_loss: 332430.0650 - val_recon_mean_squared_error: 1.4708 - val_reg_output_mean_squared_error: 332430.0650\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 89112.0746 - recon_loss: 1.4984 - reg_output_loss: 88962.2305 - recon_mean_squared_error: 1.4984 - reg_output_mean_squared_error: 88962.2305 - val_loss: 330458.5862 - val_recon_loss: 6.0025 - val_reg_output_loss: 329858.3412 - val_recon_mean_squared_error: 6.0025 - val_reg_output_mean_squared_error: 329858.3412\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 89149.0835 - recon_loss: 1.4425 - reg_output_loss: 89004.8382 - recon_mean_squared_error: 1.4425 - reg_output_mean_squared_error: 89004.8382 - val_loss: 329143.3588 - val_recon_loss: 2.1359 - val_reg_output_loss: 328929.7725 - val_recon_mean_squared_error: 2.1359 - val_reg_output_mean_squared_error: 328929.7725\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88389.7828 - recon_loss: 1.7573 - reg_output_loss: 88214.0541 - recon_mean_squared_error: 1.7573 - reg_output_mean_squared_error: 88214.0541 - val_loss: 332104.8387 - val_recon_loss: 1.0355 - val_reg_output_loss: 332001.2925 - val_recon_mean_squared_error: 1.0355 - val_reg_output_mean_squared_error: 332001.2925\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 89739.7104 - recon_loss: 1.8630 - reg_output_loss: 89553.4108 - recon_mean_squared_error: 1.8630 - reg_output_mean_squared_error: 89553.4108 - val_loss: 325687.8638 - val_recon_loss: 1.5109 - val_reg_output_loss: 325536.7750 - val_recon_mean_squared_error: 1.5109 - val_reg_output_mean_squared_error: 325536.7750\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88875.3702 - recon_loss: 1.3275 - reg_output_loss: 88742.6197 - recon_mean_squared_error: 1.3275 - reg_output_mean_squared_error: 88742.6197 - val_loss: 330724.5037 - val_recon_loss: 3.1805 - val_reg_output_loss: 330406.4587 - val_recon_mean_squared_error: 3.1805 - val_reg_output_mean_squared_error: 330406.4587\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 88145.8365 - recon_loss: 1.3331 - reg_output_loss: 88012.5295 - recon_mean_squared_error: 1.3331 - reg_output_mean_squared_error: 88012.5295 - val_loss: 338578.4575 - val_recon_loss: 1.0362 - val_reg_output_loss: 338474.8350 - val_recon_mean_squared_error: 1.0362 - val_reg_output_mean_squared_error: 338474.8350\n",
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88840.1994 - recon_loss: 2.0201 - reg_output_loss: 88638.1857 - recon_mean_squared_error: 2.0201 - reg_output_mean_squared_error: 88638.1857 - val_loss: 342467.3962 - val_recon_loss: 1.4883 - val_reg_output_loss: 342318.5700 - val_recon_mean_squared_error: 1.4883 - val_reg_output_mean_squared_error: 342318.5700\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 89530.3983 - recon_loss: 1.4305 - reg_output_loss: 89387.3419 - recon_mean_squared_error: 1.4305 - reg_output_mean_squared_error: 89387.3419 - val_loss: 336235.0137 - val_recon_loss: 2.2178 - val_reg_output_loss: 336013.2275 - val_recon_mean_squared_error: 2.2178 - val_reg_output_mean_squared_error: 336013.2275\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88887.5446 - recon_loss: 1.3314 - reg_output_loss: 88754.4073 - recon_mean_squared_error: 1.3314 - reg_output_mean_squared_error: 88754.4073 - val_loss: 338870.4763 - val_recon_loss: 2.0529 - val_reg_output_loss: 338665.1900 - val_recon_mean_squared_error: 2.0529 - val_reg_output_mean_squared_error: 338665.1900\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 89005.3414 - recon_loss: 1.3282 - reg_output_loss: 88872.5205 - recon_mean_squared_error: 1.3282 - reg_output_mean_squared_error: 88872.5205 - val_loss: 341257.4537 - val_recon_loss: 2.9597 - val_reg_output_loss: 340961.4925 - val_recon_mean_squared_error: 2.9597 - val_reg_output_mean_squared_error: 340961.4925\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 88008.6108 - recon_loss: 1.3432 - reg_output_loss: 87874.2875 - recon_mean_squared_error: 1.3432 - reg_output_mean_squared_error: 87874.2875 - val_loss: 340155.1437 - val_recon_loss: 3.6493 - val_reg_output_loss: 339790.2137 - val_recon_mean_squared_error: 3.6493 - val_reg_output_mean_squared_error: 339790.2137\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 89520.0084 - recon_loss: 1.3528 - reg_output_loss: 89384.7261 - recon_mean_squared_error: 1.3528 - reg_output_mean_squared_error: 89384.7261 - val_loss: 337123.0438 - val_recon_loss: 1.3933 - val_reg_output_loss: 336983.7037 - val_recon_mean_squared_error: 1.3933 - val_reg_output_mean_squared_error: 336983.7037\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 85944.4992 - recon_loss: 1.3880 - reg_output_loss: 85805.7009 - recon_mean_squared_error: 1.3880 - reg_output_mean_squared_error: 85805.7009 - val_loss: 349622.9188 - val_recon_loss: 1.9109 - val_reg_output_loss: 349431.8287 - val_recon_mean_squared_error: 1.9109 - val_reg_output_mean_squared_error: 349431.8287\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 88866.9385 - recon_loss: 1.3493 - reg_output_loss: 88732.0043 - recon_mean_squared_error: 1.3493 - reg_output_mean_squared_error: 88732.0043 - val_loss: 351168.2075 - val_recon_loss: 1.9883 - val_reg_output_loss: 350969.3775 - val_recon_mean_squared_error: 1.9883 - val_reg_output_mean_squared_error: 350969.3775\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 87863.4344 - recon_loss: 1.4217 - reg_output_loss: 87721.2669 - recon_mean_squared_error: 1.4217 - reg_output_mean_squared_error: 87721.2669 - val_loss: 350547.4925 - val_recon_loss: 6.2578 - val_reg_output_loss: 349921.7137 - val_recon_mean_squared_error: 6.2578 - val_reg_output_mean_squared_error: 349921.7137\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 87787.3820 - recon_loss: 1.6320 - reg_output_loss: 87624.1786 - recon_mean_squared_error: 1.6320 - reg_output_mean_squared_error: 87624.1786 - val_loss: 346956.0325 - val_recon_loss: 1.3647 - val_reg_output_loss: 346819.5613 - val_recon_mean_squared_error: 1.3647 - val_reg_output_mean_squared_error: 346819.5613\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 89058.2840 - recon_loss: 1.2570 - reg_output_loss: 88932.5821 - recon_mean_squared_error: 1.2570 - reg_output_mean_squared_error: 88932.5821 - val_loss: 344485.5363 - val_recon_loss: 2.2361 - val_reg_output_loss: 344261.9250 - val_recon_mean_squared_error: 2.2361 - val_reg_output_mean_squared_error: 344261.9250\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 87268.2956 - recon_loss: 1.3300 - reg_output_loss: 87135.2973 - recon_mean_squared_error: 1.3300 - reg_output_mean_squared_error: 87135.2973 - val_loss: 344820.3975 - val_recon_loss: 1.0542 - val_reg_output_loss: 344714.9713 - val_recon_mean_squared_error: 1.0542 - val_reg_output_mean_squared_error: 344714.9713\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 88569.3092 - recon_loss: 1.4208 - reg_output_loss: 88427.2269 - recon_mean_squared_error: 1.4208 - reg_output_mean_squared_error: 88427.2269 - val_loss: 351935.9938 - val_recon_loss: 1.0285 - val_reg_output_loss: 351833.1387 - val_recon_mean_squared_error: 1.0285 - val_reg_output_mean_squared_error: 351833.1387\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88088.5266 - recon_loss: 1.4612 - reg_output_loss: 87942.4100 - recon_mean_squared_error: 1.4612 - reg_output_mean_squared_error: 87942.4100 - val_loss: 349741.7637 - val_recon_loss: 1.6415 - val_reg_output_loss: 349577.6175 - val_recon_mean_squared_error: 1.6415 - val_reg_output_mean_squared_error: 349577.6175\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 88388.2414 - recon_loss: 1.2983 - reg_output_loss: 88258.4074 - recon_mean_squared_error: 1.2983 - reg_output_mean_squared_error: 88258.4074 - val_loss: 351363.5875 - val_recon_loss: 1.0341 - val_reg_output_loss: 351260.1813 - val_recon_mean_squared_error: 1.0341 - val_reg_output_mean_squared_error: 351260.1813\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 86869.9851 - recon_loss: 1.4241 - reg_output_loss: 86727.5746 - recon_mean_squared_error: 1.4241 - reg_output_mean_squared_error: 86727.5746 - val_loss: 357245.4100 - val_recon_loss: 8.8285 - val_reg_output_loss: 356362.5650 - val_recon_mean_squared_error: 8.8285 - val_reg_output_mean_squared_error: 356362.5650\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 87072.8117 - recon_loss: 1.4511 - reg_output_loss: 86927.7016 - recon_mean_squared_error: 1.4511 - reg_output_mean_squared_error: 86927.7016 - val_loss: 363148.5275 - val_recon_loss: 1.1346 - val_reg_output_loss: 363035.0650 - val_recon_mean_squared_error: 1.1346 - val_reg_output_mean_squared_error: 363035.0650\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 88330.3464 - recon_loss: 1.2183 - reg_output_loss: 88208.5171 - recon_mean_squared_error: 1.2183 - reg_output_mean_squared_error: 88208.5171 - val_loss: 360656.1588 - val_recon_loss: 2.7167 - val_reg_output_loss: 360384.4837 - val_recon_mean_squared_error: 2.7167 - val_reg_output_mean_squared_error: 360384.4837\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 86847.3106 - recon_loss: 1.3138 - reg_output_loss: 86715.9344 - recon_mean_squared_error: 1.3138 - reg_output_mean_squared_error: 86715.9344 - val_loss: 362688.6225 - val_recon_loss: 1.0522 - val_reg_output_loss: 362583.3987 - val_recon_mean_squared_error: 1.0522 - val_reg_output_mean_squared_error: 362583.3987\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 86898.7843 - recon_loss: 1.3481 - reg_output_loss: 86763.9699 - recon_mean_squared_error: 1.3481 - reg_output_mean_squared_error: 86763.9699 - val_loss: 370006.0012 - val_recon_loss: 1.3048 - val_reg_output_loss: 369875.5275 - val_recon_mean_squared_error: 1.3048 - val_reg_output_mean_squared_error: 369875.5275\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 88394.5403 - recon_loss: 1.5105 - reg_output_loss: 88243.4894 - recon_mean_squared_error: 1.5105 - reg_output_mean_squared_error: 88243.4894 - val_loss: 364444.8200 - val_recon_loss: 1.4886 - val_reg_output_loss: 364295.9550 - val_recon_mean_squared_error: 1.4886 - val_reg_output_mean_squared_error: 364295.9550\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 87828.5801 - recon_loss: 1.4096 - reg_output_loss: 87687.6228 - recon_mean_squared_error: 1.4096 - reg_output_mean_squared_error: 87687.6228 - val_loss: 365444.1900 - val_recon_loss: 1.2280 - val_reg_output_loss: 365321.3875 - val_recon_mean_squared_error: 1.2280 - val_reg_output_mean_squared_error: 365321.3875\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 88852.9437 - recon_loss: 1.4724 - reg_output_loss: 88705.7009 - recon_mean_squared_error: 1.4724 - reg_output_mean_squared_error: 88705.7009 - val_loss: 366183.7575 - val_recon_loss: 1.9225 - val_reg_output_loss: 365991.5125 - val_recon_mean_squared_error: 1.9225 - val_reg_output_mean_squared_error: 365991.5125\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88204.3690 - recon_loss: 1.2472 - reg_output_loss: 88079.6542 - recon_mean_squared_error: 1.2472 - reg_output_mean_squared_error: 88079.6542 - val_loss: 366913.7275 - val_recon_loss: 1.3929 - val_reg_output_loss: 366774.4288 - val_recon_mean_squared_error: 1.3929 - val_reg_output_mean_squared_error: 366774.4288\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85939.2626 - recon_loss: 1.4033 - reg_output_loss: 85798.9349 - recon_mean_squared_error: 1.4033 - reg_output_mean_squared_error: 85798.9349 - val_loss: 371138.2737 - val_recon_loss: 1.4234 - val_reg_output_loss: 370995.9462 - val_recon_mean_squared_error: 1.4234 - val_reg_output_mean_squared_error: 370995.9462\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 88585.7847 - recon_loss: 1.4609 - reg_output_loss: 88439.6918 - recon_mean_squared_error: 1.4609 - reg_output_mean_squared_error: 88439.6918 - val_loss: 369556.6087 - val_recon_loss: 1.0561 - val_reg_output_loss: 369451.0000 - val_recon_mean_squared_error: 1.0561 - val_reg_output_mean_squared_error: 369451.0000\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 88684.9440 - recon_loss: 1.2496 - reg_output_loss: 88559.9786 - recon_mean_squared_error: 1.2496 - reg_output_mean_squared_error: 88559.9786 - val_loss: 370377.0338 - val_recon_loss: 1.1117 - val_reg_output_loss: 370265.8538 - val_recon_mean_squared_error: 1.1117 - val_reg_output_mean_squared_error: 370265.8538\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 87307.2327 - recon_loss: 1.3153 - reg_output_loss: 87175.7059 - recon_mean_squared_error: 1.3153 - reg_output_mean_squared_error: 87175.7059 - val_loss: 375728.1387 - val_recon_loss: 1.5660 - val_reg_output_loss: 375571.5325 - val_recon_mean_squared_error: 1.5660 - val_reg_output_mean_squared_error: 375571.5325\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88095.9924 - recon_loss: 1.3227 - reg_output_loss: 87963.7224 - recon_mean_squared_error: 1.3227 - reg_output_mean_squared_error: 87963.7224 - val_loss: 377676.4437 - val_recon_loss: 1.1257 - val_reg_output_loss: 377563.8875 - val_recon_mean_squared_error: 1.1257 - val_reg_output_mean_squared_error: 377563.8875\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 87501.2554 - recon_loss: 1.3999 - reg_output_loss: 87361.2620 - recon_mean_squared_error: 1.3999 - reg_output_mean_squared_error: 87361.2620 - val_loss: 383848.4713 - val_recon_loss: 3.4677 - val_reg_output_loss: 383501.6950 - val_recon_mean_squared_error: 3.4677 - val_reg_output_mean_squared_error: 383501.6950\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 88225.8842 - recon_loss: 1.4905 - reg_output_loss: 88076.8365 - recon_mean_squared_error: 1.4905 - reg_output_mean_squared_error: 88076.8365 - val_loss: 375227.7800 - val_recon_loss: 5.9870 - val_reg_output_loss: 374629.0875 - val_recon_mean_squared_error: 5.9870 - val_reg_output_mean_squared_error: 374629.0875\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 85916.1034 - recon_loss: 1.3540 - reg_output_loss: 85780.7038 - recon_mean_squared_error: 1.3540 - reg_output_mean_squared_error: 85780.7038 - val_loss: 380821.9863 - val_recon_loss: 1.0522 - val_reg_output_loss: 380716.7725 - val_recon_mean_squared_error: 1.0522 - val_reg_output_mean_squared_error: 380716.7725\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 88112.2100 - recon_loss: 1.2789 - reg_output_loss: 87984.3196 - recon_mean_squared_error: 1.2789 - reg_output_mean_squared_error: 87984.3196 - val_loss: 379246.4175 - val_recon_loss: 1.1885 - val_reg_output_loss: 379127.5737 - val_recon_mean_squared_error: 1.1885 - val_reg_output_mean_squared_error: 379127.5737\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 87230.8874 - recon_loss: 1.3372 - reg_output_loss: 87097.1682 - recon_mean_squared_error: 1.3372 - reg_output_mean_squared_error: 87097.1682 - val_loss: 385112.2188 - val_recon_loss: 1.9784 - val_reg_output_loss: 384914.3875 - val_recon_mean_squared_error: 1.9784 - val_reg_output_mean_squared_error: 384914.3875\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 86605.4946 - recon_loss: 1.2422 - reg_output_loss: 86481.2724 - recon_mean_squared_error: 1.2422 - reg_output_mean_squared_error: 86481.2724 - val_loss: 390520.2687 - val_recon_loss: 7.8899 - val_reg_output_loss: 389731.2850 - val_recon_mean_squared_error: 7.8899 - val_reg_output_mean_squared_error: 389731.2850\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 87426.5697 - recon_loss: 1.3195 - reg_output_loss: 87294.6207 - recon_mean_squared_error: 1.3195 - reg_output_mean_squared_error: 87294.6207 - val_loss: 395998.9813 - val_recon_loss: 1.1865 - val_reg_output_loss: 395880.3325 - val_recon_mean_squared_error: 1.1865 - val_reg_output_mean_squared_error: 395880.3325\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 88359.9514 - recon_loss: 1.2104 - reg_output_loss: 88238.9100 - recon_mean_squared_error: 1.2104 - reg_output_mean_squared_error: 88238.9100 - val_loss: 390571.1087 - val_recon_loss: 2.1825 - val_reg_output_loss: 390352.8500 - val_recon_mean_squared_error: 2.1825 - val_reg_output_mean_squared_error: 390352.8500\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 87573.2655 - recon_loss: 1.2423 - reg_output_loss: 87449.0386 - recon_mean_squared_error: 1.2423 - reg_output_mean_squared_error: 87449.0386 - val_loss: 390603.4988 - val_recon_loss: 1.2637 - val_reg_output_loss: 390477.1250 - val_recon_mean_squared_error: 1.2637 - val_reg_output_mean_squared_error: 390477.1250\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 86666.0944 - recon_loss: 1.3555 - reg_output_loss: 86530.5476 - recon_mean_squared_error: 1.3555 - reg_output_mean_squared_error: 86530.5476 - val_loss: 389313.9900 - val_recon_loss: 1.1528 - val_reg_output_loss: 389198.7025 - val_recon_mean_squared_error: 1.1528 - val_reg_output_mean_squared_error: 389198.7025\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 87214.6230 - recon_loss: 1.2182 - reg_output_loss: 87092.7986 - recon_mean_squared_error: 1.2182 - reg_output_mean_squared_error: 87092.7986 - val_loss: 390866.2900 - val_recon_loss: 7.6930 - val_reg_output_loss: 390096.9900 - val_recon_mean_squared_error: 7.6930 - val_reg_output_mean_squared_error: 390096.9900\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 85807.8197 - recon_loss: 1.3278 - reg_output_loss: 85675.0382 - recon_mean_squared_error: 1.3278 - reg_output_mean_squared_error: 85675.0382 - val_loss: 392937.1450 - val_recon_loss: 1.8619 - val_reg_output_loss: 392750.9600 - val_recon_mean_squared_error: 1.8619 - val_reg_output_mean_squared_error: 392750.9600\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 86840.3237 - recon_loss: 1.1917 - reg_output_loss: 86721.1488 - recon_mean_squared_error: 1.1917 - reg_output_mean_squared_error: 86721.1488 - val_loss: 391080.6075 - val_recon_loss: 2.6375 - val_reg_output_loss: 390816.8625 - val_recon_mean_squared_error: 2.6375 - val_reg_output_mean_squared_error: 390816.8625\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 88142.3730 - recon_loss: 1.1408 - reg_output_loss: 88028.2976 - recon_mean_squared_error: 1.1408 - reg_output_mean_squared_error: 88028.2976 - val_loss: 380732.7450 - val_recon_loss: 1.3003 - val_reg_output_loss: 380602.7200 - val_recon_mean_squared_error: 1.3003 - val_reg_output_mean_squared_error: 380602.7200\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 85788.6440 - recon_loss: 1.2208 - reg_output_loss: 85666.5630 - recon_mean_squared_error: 1.2208 - reg_output_mean_squared_error: 85666.5630 - val_loss: 388816.4538 - val_recon_loss: 1.1543 - val_reg_output_loss: 388701.0300 - val_recon_mean_squared_error: 1.1543 - val_reg_output_mean_squared_error: 388701.0300\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 86649.4031 - recon_loss: 1.4041 - reg_output_loss: 86508.9904 - recon_mean_squared_error: 1.4041 - reg_output_mean_squared_error: 86508.9904 - val_loss: 382487.1400 - val_recon_loss: 1.2420 - val_reg_output_loss: 382362.9375 - val_recon_mean_squared_error: 1.2420 - val_reg_output_mean_squared_error: 382362.9375\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 87041.3305 - recon_loss: 1.1863 - reg_output_loss: 86922.7041 - recon_mean_squared_error: 1.1863 - reg_output_mean_squared_error: 86922.7041 - val_loss: 387904.0938 - val_recon_loss: 1.4140 - val_reg_output_loss: 387762.6900 - val_recon_mean_squared_error: 1.4140 - val_reg_output_mean_squared_error: 387762.6900\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 86068.2775 - recon_loss: 1.2543 - reg_output_loss: 85942.8449 - recon_mean_squared_error: 1.2543 - reg_output_mean_squared_error: 85942.8449 - val_loss: 380536.5163 - val_recon_loss: 1.2540 - val_reg_output_loss: 380411.1200 - val_recon_mean_squared_error: 1.2540 - val_reg_output_mean_squared_error: 380411.1200\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85387.3484 - recon_loss: 1.2735 - reg_output_loss: 85259.9998 - recon_mean_squared_error: 1.2735 - reg_output_mean_squared_error: 85259.9998 - val_loss: 387961.9163 - val_recon_loss: 1.0191 - val_reg_output_loss: 387859.9950 - val_recon_mean_squared_error: 1.0191 - val_reg_output_mean_squared_error: 387859.9950\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 87326.8337 - recon_loss: 1.2177 - reg_output_loss: 87205.0583 - recon_mean_squared_error: 1.2177 - reg_output_mean_squared_error: 87205.0583 - val_loss: 392389.2463 - val_recon_loss: 1.0723 - val_reg_output_loss: 392282.0137 - val_recon_mean_squared_error: 1.0723 - val_reg_output_mean_squared_error: 392282.0137\n",
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 86378.9692 - recon_loss: 1.1331 - reg_output_loss: 86265.6598 - recon_mean_squared_error: 1.1331 - reg_output_mean_squared_error: 86265.6598 - val_loss: 394487.6250 - val_recon_loss: 1.6055 - val_reg_output_loss: 394327.0675 - val_recon_mean_squared_error: 1.6055 - val_reg_output_mean_squared_error: 394327.0675\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 86647.0367 - recon_loss: 1.3211 - reg_output_loss: 86514.9294 - recon_mean_squared_error: 1.3211 - reg_output_mean_squared_error: 86514.9294 - val_loss: 395780.4888 - val_recon_loss: 1.0168 - val_reg_output_loss: 395678.8137 - val_recon_mean_squared_error: 1.0168 - val_reg_output_mean_squared_error: 395678.8137\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85777.8552 - recon_loss: 1.3665 - reg_output_loss: 85641.2019 - recon_mean_squared_error: 1.3665 - reg_output_mean_squared_error: 85641.2019 - val_loss: 397394.6025 - val_recon_loss: 1.0979 - val_reg_output_loss: 397284.8150 - val_recon_mean_squared_error: 1.0979 - val_reg_output_mean_squared_error: 397284.8150\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 87547.8388 - recon_loss: 1.1247 - reg_output_loss: 87435.3708 - recon_mean_squared_error: 1.1247 - reg_output_mean_squared_error: 87435.3708 - val_loss: 396714.4825 - val_recon_loss: 1.4524 - val_reg_output_loss: 396569.2400 - val_recon_mean_squared_error: 1.4524 - val_reg_output_mean_squared_error: 396569.2400\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 86887.5056 - recon_loss: 1.1259 - reg_output_loss: 86774.9192 - recon_mean_squared_error: 1.1259 - reg_output_mean_squared_error: 86774.9192 - val_loss: 387119.0388 - val_recon_loss: 1.2947 - val_reg_output_loss: 386989.5712 - val_recon_mean_squared_error: 1.2947 - val_reg_output_mean_squared_error: 386989.5712\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85395.1496 - recon_loss: 1.2312 - reg_output_loss: 85272.0304 - recon_mean_squared_error: 1.2312 - reg_output_mean_squared_error: 85272.0304 - val_loss: 385158.9925 - val_recon_loss: 1.1702 - val_reg_output_loss: 385041.9675 - val_recon_mean_squared_error: 1.1702 - val_reg_output_mean_squared_error: 385041.9675\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 85174.1664 - recon_loss: 1.1167 - reg_output_loss: 85062.4908 - recon_mean_squared_error: 1.1167 - reg_output_mean_squared_error: 85062.4908 - val_loss: 384578.7587 - val_recon_loss: 1.1956 - val_reg_output_loss: 384459.2025 - val_recon_mean_squared_error: 1.1956 - val_reg_output_mean_squared_error: 384459.2025\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 86103.8308 - recon_loss: 1.2629 - reg_output_loss: 85977.5415 - recon_mean_squared_error: 1.2629 - reg_output_mean_squared_error: 85977.5415 - val_loss: 390460.3800 - val_recon_loss: 1.0452 - val_reg_output_loss: 390355.8675 - val_recon_mean_squared_error: 1.0452 - val_reg_output_mean_squared_error: 390355.8675\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 86378.8025 - recon_loss: 1.1436 - reg_output_loss: 86264.4383 - recon_mean_squared_error: 1.1436 - reg_output_mean_squared_error: 86264.4383 - val_loss: 382606.8513 - val_recon_loss: 1.2101 - val_reg_output_loss: 382485.8375 - val_recon_mean_squared_error: 1.2101 - val_reg_output_mean_squared_error: 382485.8375\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 86863.5435 - recon_loss: 1.2081 - reg_output_loss: 86742.7299 - recon_mean_squared_error: 1.2081 - reg_output_mean_squared_error: 86742.7299 - val_loss: 376439.4637 - val_recon_loss: 1.3740 - val_reg_output_loss: 376302.0588 - val_recon_mean_squared_error: 1.3740 - val_reg_output_mean_squared_error: 376302.0588\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 85931.9211 - recon_loss: 1.2015 - reg_output_loss: 85811.7689 - recon_mean_squared_error: 1.2015 - reg_output_mean_squared_error: 85811.7689 - val_loss: 379188.4225 - val_recon_loss: 1.2165 - val_reg_output_loss: 379066.7825 - val_recon_mean_squared_error: 1.2165 - val_reg_output_mean_squared_error: 379066.7825\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 86172.9247 - recon_loss: 1.2726 - reg_output_loss: 86045.6611 - recon_mean_squared_error: 1.2726 - reg_output_mean_squared_error: 86045.6611 - val_loss: 379766.0137 - val_recon_loss: 1.3727 - val_reg_output_loss: 379628.7425 - val_recon_mean_squared_error: 1.3727 - val_reg_output_mean_squared_error: 379628.7425\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 86843.8525 - recon_loss: 1.1385 - reg_output_loss: 86730.0018 - recon_mean_squared_error: 1.1385 - reg_output_mean_squared_error: 86730.0018 - val_loss: 376285.3750 - val_recon_loss: 2.2809 - val_reg_output_loss: 376057.2850 - val_recon_mean_squared_error: 2.2809 - val_reg_output_mean_squared_error: 376057.2850\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 85536.5785 - recon_loss: 1.1985 - reg_output_loss: 85416.7267 - recon_mean_squared_error: 1.1985 - reg_output_mean_squared_error: 85416.7267 - val_loss: 382355.8887 - val_recon_loss: 1.0379 - val_reg_output_loss: 382252.1000 - val_recon_mean_squared_error: 1.0379 - val_reg_output_mean_squared_error: 382252.1000\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 213us/step - loss: 84875.9994 - recon_loss: 1.1992 - reg_output_loss: 84756.0758 - recon_mean_squared_error: 1.1992 - reg_output_mean_squared_error: 84756.0758 - val_loss: 392711.8400 - val_recon_loss: 1.0675 - val_reg_output_loss: 392605.0950 - val_recon_mean_squared_error: 1.0675 - val_reg_output_mean_squared_error: 392605.0950\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 85232.2633 - recon_loss: 1.0911 - reg_output_loss: 85123.1495 - recon_mean_squared_error: 1.0911 - reg_output_mean_squared_error: 85123.1495 - val_loss: 397325.4500 - val_recon_loss: 1.9997 - val_reg_output_loss: 397125.4725 - val_recon_mean_squared_error: 1.9997 - val_reg_output_mean_squared_error: 397125.4725\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 86649.3228 - recon_loss: 1.2729 - reg_output_loss: 86522.0345 - recon_mean_squared_error: 1.2729 - reg_output_mean_squared_error: 86522.0345 - val_loss: 391116.5950 - val_recon_loss: 1.3156 - val_reg_output_loss: 390985.0425 - val_recon_mean_squared_error: 1.3156 - val_reg_output_mean_squared_error: 390985.0425\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 86412.5127 - recon_loss: 1.2599 - reg_output_loss: 86286.5252 - recon_mean_squared_error: 1.2599 - reg_output_mean_squared_error: 86286.5252 - val_loss: 392744.7750 - val_recon_loss: 1.0481 - val_reg_output_loss: 392639.9575 - val_recon_mean_squared_error: 1.0481 - val_reg_output_mean_squared_error: 392639.9575\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 86179.7201 - recon_loss: 1.1507 - reg_output_loss: 86064.6468 - recon_mean_squared_error: 1.1507 - reg_output_mean_squared_error: 86064.6468 - val_loss: 394189.1750 - val_recon_loss: 1.2116 - val_reg_output_loss: 394068.0200 - val_recon_mean_squared_error: 1.2116 - val_reg_output_mean_squared_error: 394068.0200\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 84615.4704 - recon_loss: 1.1719 - reg_output_loss: 84498.2811 - recon_mean_squared_error: 1.1719 - reg_output_mean_squared_error: 84498.2811 - val_loss: 402219.7975 - val_recon_loss: 1.0741 - val_reg_output_loss: 402112.3875 - val_recon_mean_squared_error: 1.0741 - val_reg_output_mean_squared_error: 402112.3875\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 210us/step - loss: 85681.9944 - recon_loss: 1.1920 - reg_output_loss: 85562.7981 - recon_mean_squared_error: 1.1920 - reg_output_mean_squared_error: 85562.7981 - val_loss: 398332.5875 - val_recon_loss: 1.9910 - val_reg_output_loss: 398133.4800 - val_recon_mean_squared_error: 1.9910 - val_reg_output_mean_squared_error: 398133.4800\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 84889.3617 - recon_loss: 1.1338 - reg_output_loss: 84775.9789 - recon_mean_squared_error: 1.1338 - reg_output_mean_squared_error: 84775.9789 - val_loss: 403071.8025 - val_recon_loss: 1.0400 - val_reg_output_loss: 402967.7950 - val_recon_mean_squared_error: 1.0400 - val_reg_output_mean_squared_error: 402967.7950\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85813.2167 - recon_loss: 1.1744 - reg_output_loss: 85695.7796 - recon_mean_squared_error: 1.1744 - reg_output_mean_squared_error: 85695.7796 - val_loss: 408871.2325 - val_recon_loss: 3.0059 - val_reg_output_loss: 408570.6450 - val_recon_mean_squared_error: 3.0059 - val_reg_output_mean_squared_error: 408570.6450\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 86287.9799 - recon_loss: 1.2285 - reg_output_loss: 86165.1341 - recon_mean_squared_error: 1.2285 - reg_output_mean_squared_error: 86165.1341 - val_loss: 401159.3775 - val_recon_loss: 1.0974 - val_reg_output_loss: 401049.6450 - val_recon_mean_squared_error: 1.0974 - val_reg_output_mean_squared_error: 401049.6450\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 84325.4327 - recon_loss: 1.2153 - reg_output_loss: 84203.9034 - recon_mean_squared_error: 1.2153 - reg_output_mean_squared_error: 84203.9034 - val_loss: 406613.5250 - val_recon_loss: 1.0449 - val_reg_output_loss: 406509.0350 - val_recon_mean_squared_error: 1.0449 - val_reg_output_mean_squared_error: 406509.0350\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 83736.2348 - recon_loss: 1.0966 - reg_output_loss: 83626.5733 - recon_mean_squared_error: 1.0966 - reg_output_mean_squared_error: 83626.5733 - val_loss: 411444.1400 - val_recon_loss: 1.3683 - val_reg_output_loss: 411307.2975 - val_recon_mean_squared_error: 1.3683 - val_reg_output_mean_squared_error: 411307.2975\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85806.3904 - recon_loss: 1.1481 - reg_output_loss: 85691.5838 - recon_mean_squared_error: 1.1481 - reg_output_mean_squared_error: 85691.5838 - val_loss: 408554.3275 - val_recon_loss: 1.2368 - val_reg_output_loss: 408430.6625 - val_recon_mean_squared_error: 1.2368 - val_reg_output_mean_squared_error: 408430.6625\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 84384.4318 - recon_loss: 1.1267 - reg_output_loss: 84271.7640 - recon_mean_squared_error: 1.1267 - reg_output_mean_squared_error: 84271.7640 - val_loss: 408468.2050 - val_recon_loss: 1.0313 - val_reg_output_loss: 408365.0750 - val_recon_mean_squared_error: 1.0313 - val_reg_output_mean_squared_error: 408365.0750\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 85805.6561 - recon_loss: 1.1475 - reg_output_loss: 85690.9064 - recon_mean_squared_error: 1.1475 - reg_output_mean_squared_error: 85690.9064 - val_loss: 408081.4675 - val_recon_loss: 1.0112 - val_reg_output_loss: 407980.3475 - val_recon_mean_squared_error: 1.0112 - val_reg_output_mean_squared_error: 407980.3475\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 84474.2138 - recon_loss: 1.0989 - reg_output_loss: 84364.3198 - recon_mean_squared_error: 1.0989 - reg_output_mean_squared_error: 84364.3198 - val_loss: 409474.3950 - val_recon_loss: 1.0558 - val_reg_output_loss: 409368.8125 - val_recon_mean_squared_error: 1.0558 - val_reg_output_mean_squared_error: 409368.8125\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 84821.9755 - recon_loss: 1.1065 - reg_output_loss: 84711.3208 - recon_mean_squared_error: 1.1065 - reg_output_mean_squared_error: 84711.3208 - val_loss: 409303.4625 - val_recon_loss: 1.8804 - val_reg_output_loss: 409115.4075 - val_recon_mean_squared_error: 1.8804 - val_reg_output_mean_squared_error: 409115.4075\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 85538.7741 - recon_loss: 1.3221 - reg_output_loss: 85406.5679 - recon_mean_squared_error: 1.3221 - reg_output_mean_squared_error: 85406.5679 - val_loss: 411325.3275 - val_recon_loss: 1.0427 - val_reg_output_loss: 411221.0625 - val_recon_mean_squared_error: 1.0427 - val_reg_output_mean_squared_error: 411221.0625\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83740.4479 - recon_loss: 1.1565 - reg_output_loss: 83624.8001 - recon_mean_squared_error: 1.1565 - reg_output_mean_squared_error: 83624.8001 - val_loss: 416861.1675 - val_recon_loss: 2.1404 - val_reg_output_loss: 416647.1325 - val_recon_mean_squared_error: 2.1404 - val_reg_output_mean_squared_error: 416647.1325\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 84169.6340 - recon_loss: 1.1052 - reg_output_loss: 84059.1141 - recon_mean_squared_error: 1.1052 - reg_output_mean_squared_error: 84059.1141 - val_loss: 421978.7550 - val_recon_loss: 1.1678 - val_reg_output_loss: 421861.9775 - val_recon_mean_squared_error: 1.1678 - val_reg_output_mean_squared_error: 421861.9775\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84084.3371 - recon_loss: 1.0716 - reg_output_loss: 83977.1749 - recon_mean_squared_error: 1.0716 - reg_output_mean_squared_error: 83977.1749 - val_loss: 427953.2175 - val_recon_loss: 1.0757 - val_reg_output_loss: 427845.6450 - val_recon_mean_squared_error: 1.0757 - val_reg_output_mean_squared_error: 427845.6450\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 85645.0548 - recon_loss: 1.1936 - reg_output_loss: 85525.6914 - recon_mean_squared_error: 1.1936 - reg_output_mean_squared_error: 85525.6914 - val_loss: 429520.3025 - val_recon_loss: 1.4745 - val_reg_output_loss: 429372.8525 - val_recon_mean_squared_error: 1.4745 - val_reg_output_mean_squared_error: 429372.8525\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 84502.3560 - recon_loss: 1.1277 - reg_output_loss: 84389.5851 - recon_mean_squared_error: 1.1277 - reg_output_mean_squared_error: 84389.5851 - val_loss: 428973.0425 - val_recon_loss: 1.0238 - val_reg_output_loss: 428870.6600 - val_recon_mean_squared_error: 1.0238 - val_reg_output_mean_squared_error: 428870.6600\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 83622.3536 - recon_loss: 1.0841 - reg_output_loss: 83513.9405 - recon_mean_squared_error: 1.0841 - reg_output_mean_squared_error: 83513.9405 - val_loss: 431883.4025 - val_recon_loss: 1.1727 - val_reg_output_loss: 431766.1300 - val_recon_mean_squared_error: 1.1727 - val_reg_output_mean_squared_error: 431766.1300\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 84995.7393 - recon_loss: 1.1282 - reg_output_loss: 84882.9224 - recon_mean_squared_error: 1.1282 - reg_output_mean_squared_error: 84882.9224 - val_loss: 426925.6175 - val_recon_loss: 1.0439 - val_reg_output_loss: 426821.2200 - val_recon_mean_squared_error: 1.0439 - val_reg_output_mean_squared_error: 426821.2200\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 85138.5639 - recon_loss: 1.1264 - reg_output_loss: 85025.9241 - recon_mean_squared_error: 1.1264 - reg_output_mean_squared_error: 85025.9241 - val_loss: 421679.7625 - val_recon_loss: 1.4278 - val_reg_output_loss: 421536.9800 - val_recon_mean_squared_error: 1.4278 - val_reg_output_mean_squared_error: 421536.9800\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 84384.6174 - recon_loss: 1.1749 - reg_output_loss: 84267.1239 - recon_mean_squared_error: 1.1749 - reg_output_mean_squared_error: 84267.1239 - val_loss: 419224.5175 - val_recon_loss: 1.0944 - val_reg_output_loss: 419115.0800 - val_recon_mean_squared_error: 1.0944 - val_reg_output_mean_squared_error: 419115.0800\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82735.1901 - recon_loss: 1.0942 - reg_output_loss: 82625.7703 - recon_mean_squared_error: 1.0942 - reg_output_mean_squared_error: 82625.7703 - val_loss: 429104.7900 - val_recon_loss: 2.2473 - val_reg_output_loss: 428880.0600 - val_recon_mean_squared_error: 2.2473 - val_reg_output_mean_squared_error: 428880.0600\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84076.9100 - recon_loss: 1.2639 - reg_output_loss: 83950.5243 - recon_mean_squared_error: 1.2639 - reg_output_mean_squared_error: 83950.5243 - val_loss: 424588.9000 - val_recon_loss: 1.0202 - val_reg_output_loss: 424486.8700 - val_recon_mean_squared_error: 1.0202 - val_reg_output_mean_squared_error: 424486.8700\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83205.8482 - recon_loss: 1.1118 - reg_output_loss: 83094.6659 - recon_mean_squared_error: 1.1118 - reg_output_mean_squared_error: 83094.6659 - val_loss: 428399.6050 - val_recon_loss: 1.1445 - val_reg_output_loss: 428285.1500 - val_recon_mean_squared_error: 1.1445 - val_reg_output_mean_squared_error: 428285.1500\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84218.5699 - recon_loss: 1.1256 - reg_output_loss: 84106.0064 - recon_mean_squared_error: 1.1256 - reg_output_mean_squared_error: 84106.0064 - val_loss: 422278.7700 - val_recon_loss: 1.0131 - val_reg_output_loss: 422177.4625 - val_recon_mean_squared_error: 1.0131 - val_reg_output_mean_squared_error: 422177.4625\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84201.9250 - recon_loss: 1.1336 - reg_output_loss: 84088.5661 - recon_mean_squared_error: 1.1336 - reg_output_mean_squared_error: 84088.5661 - val_loss: 422489.1825 - val_recon_loss: 1.1041 - val_reg_output_loss: 422378.7775 - val_recon_mean_squared_error: 1.1041 - val_reg_output_mean_squared_error: 422378.7775\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 84549.5040 - recon_loss: 1.1807 - reg_output_loss: 84431.4382 - recon_mean_squared_error: 1.1807 - reg_output_mean_squared_error: 84431.4382 - val_loss: 421622.3900 - val_recon_loss: 1.1833 - val_reg_output_loss: 421504.0600 - val_recon_mean_squared_error: 1.1833 - val_reg_output_mean_squared_error: 421504.0600\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 84307.7344 - recon_loss: 1.0722 - reg_output_loss: 84200.5133 - recon_mean_squared_error: 1.0722 - reg_output_mean_squared_error: 84200.5133 - val_loss: 423873.1650 - val_recon_loss: 1.4604 - val_reg_output_loss: 423727.1175 - val_recon_mean_squared_error: 1.4604 - val_reg_output_mean_squared_error: 423727.1175\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83663.9071 - recon_loss: 1.0896 - reg_output_loss: 83554.9458 - recon_mean_squared_error: 1.0896 - reg_output_mean_squared_error: 83554.9458 - val_loss: 427411.0350 - val_recon_loss: 1.4004 - val_reg_output_loss: 427270.9875 - val_recon_mean_squared_error: 1.4004 - val_reg_output_mean_squared_error: 427270.9875\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84544.5678 - recon_loss: 1.1168 - reg_output_loss: 84432.8889 - recon_mean_squared_error: 1.1168 - reg_output_mean_squared_error: 84432.8889 - val_loss: 421065.2250 - val_recon_loss: 1.2382 - val_reg_output_loss: 420941.4025 - val_recon_mean_squared_error: 1.2382 - val_reg_output_mean_squared_error: 420941.4025\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82556.7461 - recon_loss: 1.0652 - reg_output_loss: 82450.2262 - recon_mean_squared_error: 1.0652 - reg_output_mean_squared_error: 82450.2262 - val_loss: 428954.4475 - val_recon_loss: 1.0610 - val_reg_output_loss: 428848.3350 - val_recon_mean_squared_error: 1.0610 - val_reg_output_mean_squared_error: 428848.3350\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84785.6696 - recon_loss: 1.1406 - reg_output_loss: 84671.6067 - recon_mean_squared_error: 1.1406 - reg_output_mean_squared_error: 84671.6067 - val_loss: 428561.4000 - val_recon_loss: 1.0534 - val_reg_output_loss: 428456.0625 - val_recon_mean_squared_error: 1.0534 - val_reg_output_mean_squared_error: 428456.0625\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 85621.0270 - recon_loss: 1.0868 - reg_output_loss: 85512.3492 - recon_mean_squared_error: 1.0868 - reg_output_mean_squared_error: 85512.3492 - val_loss: 423753.7275 - val_recon_loss: 1.1056 - val_reg_output_loss: 423643.1650 - val_recon_mean_squared_error: 1.1056 - val_reg_output_mean_squared_error: 423643.1650\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 83808.6301 - recon_loss: 1.0979 - reg_output_loss: 83698.8393 - recon_mean_squared_error: 1.0979 - reg_output_mean_squared_error: 83698.8393 - val_loss: 421323.2900 - val_recon_loss: 1.0900 - val_reg_output_loss: 421214.3000 - val_recon_mean_squared_error: 1.0900 - val_reg_output_mean_squared_error: 421214.3000\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 81190.4936 - recon_loss: 1.1552 - reg_output_loss: 81074.9684 - recon_mean_squared_error: 1.1552 - reg_output_mean_squared_error: 81074.9684 - val_loss: 428363.1975 - val_recon_loss: 1.0308 - val_reg_output_loss: 428260.1100 - val_recon_mean_squared_error: 1.0308 - val_reg_output_mean_squared_error: 428260.1100\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82858.7721 - recon_loss: 1.1050 - reg_output_loss: 82748.2709 - recon_mean_squared_error: 1.1050 - reg_output_mean_squared_error: 82748.2709 - val_loss: 430485.4225 - val_recon_loss: 1.1029 - val_reg_output_loss: 430375.1400 - val_recon_mean_squared_error: 1.1029 - val_reg_output_mean_squared_error: 430375.1400\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84519.5392 - recon_loss: 1.0664 - reg_output_loss: 84412.8970 - recon_mean_squared_error: 1.0664 - reg_output_mean_squared_error: 84412.8970 - val_loss: 430175.1950 - val_recon_loss: 1.0600 - val_reg_output_loss: 430069.2025 - val_recon_mean_squared_error: 1.0600 - val_reg_output_mean_squared_error: 430069.2025\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 82768.2750 - recon_loss: 1.0951 - reg_output_loss: 82658.7643 - recon_mean_squared_error: 1.0951 - reg_output_mean_squared_error: 82658.7643 - val_loss: 432017.6500 - val_recon_loss: 1.3215 - val_reg_output_loss: 431885.4975 - val_recon_mean_squared_error: 1.3215 - val_reg_output_mean_squared_error: 431885.4975\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83994.8179 - recon_loss: 1.0979 - reg_output_loss: 83885.0318 - recon_mean_squared_error: 1.0979 - reg_output_mean_squared_error: 83885.0318 - val_loss: 423665.7325 - val_recon_loss: 1.0717 - val_reg_output_loss: 423558.5625 - val_recon_mean_squared_error: 1.0717 - val_reg_output_mean_squared_error: 423558.5625\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84339.1851 - recon_loss: 1.0797 - reg_output_loss: 84231.2193 - recon_mean_squared_error: 1.0797 - reg_output_mean_squared_error: 84231.2193 - val_loss: 423172.8400 - val_recon_loss: 1.0106 - val_reg_output_loss: 423071.7700 - val_recon_mean_squared_error: 1.0106 - val_reg_output_mean_squared_error: 423071.7700\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82832.3133 - recon_loss: 1.0746 - reg_output_loss: 82724.8580 - recon_mean_squared_error: 1.0746 - reg_output_mean_squared_error: 82724.8580 - val_loss: 428261.3075 - val_recon_loss: 1.0268 - val_reg_output_loss: 428158.6200 - val_recon_mean_squared_error: 1.0268 - val_reg_output_mean_squared_error: 428158.6200\n",
      "Epoch 222/500\n",
      "300/300 [==============================] - 0s 273us/step - loss: 83877.7624 - recon_loss: 1.1014 - reg_output_loss: 83767.6242 - recon_mean_squared_error: 1.1014 - reg_output_mean_squared_error: 83767.6242 - val_loss: 435686.1925 - val_recon_loss: 1.0933 - val_reg_output_loss: 435576.8575 - val_recon_mean_squared_error: 1.0933 - val_reg_output_mean_squared_error: 435576.8575\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 80911.9631 - recon_loss: 1.0816 - reg_output_loss: 80803.8003 - recon_mean_squared_error: 1.0816 - reg_output_mean_squared_error: 80803.8003 - val_loss: 446605.8600 - val_recon_loss: 1.0117 - val_reg_output_loss: 446504.6950 - val_recon_mean_squared_error: 1.0117 - val_reg_output_mean_squared_error: 446504.6950\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 82340.5498 - recon_loss: 1.0629 - reg_output_loss: 82234.2646 - recon_mean_squared_error: 1.0629 - reg_output_mean_squared_error: 82234.2646 - val_loss: 455920.0975 - val_recon_loss: 1.0430 - val_reg_output_loss: 455815.7925 - val_recon_mean_squared_error: 1.0430 - val_reg_output_mean_squared_error: 455815.7925\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 83952.8275 - recon_loss: 1.0747 - reg_output_loss: 83845.3585 - recon_mean_squared_error: 1.0747 - reg_output_mean_squared_error: 83845.3585 - val_loss: 453186.3600 - val_recon_loss: 1.2827 - val_reg_output_loss: 453058.0925 - val_recon_mean_squared_error: 1.2827 - val_reg_output_mean_squared_error: 453058.0925\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 83663.8879 - recon_loss: 1.1632 - reg_output_loss: 83547.5716 - recon_mean_squared_error: 1.1632 - reg_output_mean_squared_error: 83547.5716 - val_loss: 446971.6750 - val_recon_loss: 1.2373 - val_reg_output_loss: 446847.9575 - val_recon_mean_squared_error: 1.2373 - val_reg_output_mean_squared_error: 446847.9575\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83955.2376 - recon_loss: 1.1694 - reg_output_loss: 83838.3016 - recon_mean_squared_error: 1.1694 - reg_output_mean_squared_error: 83838.3016 - val_loss: 449317.6850 - val_recon_loss: 1.2948 - val_reg_output_loss: 449188.2100 - val_recon_mean_squared_error: 1.2948 - val_reg_output_mean_squared_error: 449188.2100\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 81941.3561 - recon_loss: 1.1091 - reg_output_loss: 81830.4447 - recon_mean_squared_error: 1.1091 - reg_output_mean_squared_error: 81830.4447 - val_loss: 451948.7200 - val_recon_loss: 1.3827 - val_reg_output_loss: 451810.4525 - val_recon_mean_squared_error: 1.3827 - val_reg_output_mean_squared_error: 451810.4525\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82654.1023 - recon_loss: 1.0486 - reg_output_loss: 82549.2392 - recon_mean_squared_error: 1.0486 - reg_output_mean_squared_error: 82549.2392 - val_loss: 459866.0625 - val_recon_loss: 1.5489 - val_reg_output_loss: 459711.1750 - val_recon_mean_squared_error: 1.5489 - val_reg_output_mean_squared_error: 459711.1750\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 83991.3246 - recon_loss: 1.1181 - reg_output_loss: 83879.5141 - recon_mean_squared_error: 1.1181 - reg_output_mean_squared_error: 83879.5141 - val_loss: 463366.2625 - val_recon_loss: 1.0567 - val_reg_output_loss: 463260.6000 - val_recon_mean_squared_error: 1.0567 - val_reg_output_mean_squared_error: 463260.6000\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 81392.9783 - recon_loss: 1.0779 - reg_output_loss: 81285.1888 - recon_mean_squared_error: 1.0779 - reg_output_mean_squared_error: 81285.1888 - val_loss: 475990.0675 - val_recon_loss: 2.1707 - val_reg_output_loss: 475773.0075 - val_recon_mean_squared_error: 2.1707 - val_reg_output_mean_squared_error: 475773.0075\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83510.8931 - recon_loss: 1.1193 - reg_output_loss: 83398.9648 - recon_mean_squared_error: 1.1193 - reg_output_mean_squared_error: 83398.9648 - val_loss: 470032.8550 - val_recon_loss: 1.0565 - val_reg_output_loss: 469927.2100 - val_recon_mean_squared_error: 1.0565 - val_reg_output_mean_squared_error: 469927.2100\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 82557.6256 - recon_loss: 1.1477 - reg_output_loss: 82442.8559 - recon_mean_squared_error: 1.1477 - reg_output_mean_squared_error: 82442.8559 - val_loss: 465617.5275 - val_recon_loss: 1.0503 - val_reg_output_loss: 465512.4900 - val_recon_mean_squared_error: 1.0503 - val_reg_output_mean_squared_error: 465512.4900\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82313.3841 - recon_loss: 1.1006 - reg_output_loss: 82203.3238 - recon_mean_squared_error: 1.1006 - reg_output_mean_squared_error: 82203.3238 - val_loss: 468731.3075 - val_recon_loss: 1.1070 - val_reg_output_loss: 468620.6050 - val_recon_mean_squared_error: 1.1070 - val_reg_output_mean_squared_error: 468620.6050\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 82174.4285 - recon_loss: 1.0593 - reg_output_loss: 82068.5032 - recon_mean_squared_error: 1.0593 - reg_output_mean_squared_error: 82068.5032 - val_loss: 473388.3325 - val_recon_loss: 1.0783 - val_reg_output_loss: 473280.4925 - val_recon_mean_squared_error: 1.0783 - val_reg_output_mean_squared_error: 473280.4925\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 83147.8051 - recon_loss: 1.1196 - reg_output_loss: 83035.8430 - recon_mean_squared_error: 1.1196 - reg_output_mean_squared_error: 83035.8430 - val_loss: 463332.9350 - val_recon_loss: 1.1032 - val_reg_output_loss: 463222.6200 - val_recon_mean_squared_error: 1.1032 - val_reg_output_mean_squared_error: 463222.6200\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 80486.5931 - recon_loss: 1.0741 - reg_output_loss: 80379.1836 - recon_mean_squared_error: 1.0741 - reg_output_mean_squared_error: 80379.1836 - val_loss: 473783.4275 - val_recon_loss: 1.1751 - val_reg_output_loss: 473665.9150 - val_recon_mean_squared_error: 1.1751 - val_reg_output_mean_squared_error: 473665.9150\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 82610.1501 - recon_loss: 1.0817 - reg_output_loss: 82501.9793 - recon_mean_squared_error: 1.0817 - reg_output_mean_squared_error: 82501.9793 - val_loss: 470339.9675 - val_recon_loss: 1.1021 - val_reg_output_loss: 470229.7600 - val_recon_mean_squared_error: 1.1021 - val_reg_output_mean_squared_error: 470229.7600\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 81743.2180 - recon_loss: 1.0706 - reg_output_loss: 81636.1593 - recon_mean_squared_error: 1.0706 - reg_output_mean_squared_error: 81636.1593 - val_loss: 468473.7225 - val_recon_loss: 1.0691 - val_reg_output_loss: 468366.8075 - val_recon_mean_squared_error: 1.0691 - val_reg_output_mean_squared_error: 468366.8075\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 80461.6226 - recon_loss: 1.0627 - reg_output_loss: 80355.3533 - recon_mean_squared_error: 1.0627 - reg_output_mean_squared_error: 80355.3533 - val_loss: 475615.4650 - val_recon_loss: 2.7517 - val_reg_output_loss: 475340.3100 - val_recon_mean_squared_error: 2.7517 - val_reg_output_mean_squared_error: 475340.3100\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 80577.6548 - recon_loss: 1.1162 - reg_output_loss: 80466.0344 - recon_mean_squared_error: 1.1162 - reg_output_mean_squared_error: 80466.0344 - val_loss: 475145.0750 - val_recon_loss: 1.0750 - val_reg_output_loss: 475037.5850 - val_recon_mean_squared_error: 1.0750 - val_reg_output_mean_squared_error: 475037.5850\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 83229.2149 - recon_loss: 1.1097 - reg_output_loss: 83118.2404 - recon_mean_squared_error: 1.1097 - reg_output_mean_squared_error: 83118.2404 - val_loss: 469273.0500 - val_recon_loss: 1.0954 - val_reg_output_loss: 469163.5000 - val_recon_mean_squared_error: 1.0954 - val_reg_output_mean_squared_error: 469163.5000\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83753.2754 - recon_loss: 1.0412 - reg_output_loss: 83649.1517 - recon_mean_squared_error: 1.0412 - reg_output_mean_squared_error: 83649.1517 - val_loss: 459754.8250 - val_recon_loss: 1.1470 - val_reg_output_loss: 459640.1225 - val_recon_mean_squared_error: 1.1470 - val_reg_output_mean_squared_error: 459640.1225\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83258.7619 - recon_loss: 1.0639 - reg_output_loss: 83152.3684 - recon_mean_squared_error: 1.0639 - reg_output_mean_squared_error: 83152.3684 - val_loss: 453722.2525 - val_recon_loss: 1.0364 - val_reg_output_loss: 453618.6075 - val_recon_mean_squared_error: 1.0364 - val_reg_output_mean_squared_error: 453618.6075\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79622.0101 - recon_loss: 1.0606 - reg_output_loss: 79515.9550 - recon_mean_squared_error: 1.0606 - reg_output_mean_squared_error: 79515.9550 - val_loss: 466145.3375 - val_recon_loss: 1.0421 - val_reg_output_loss: 466041.1225 - val_recon_mean_squared_error: 1.0421 - val_reg_output_mean_squared_error: 466041.1225\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 81345.0006 - recon_loss: 1.0437 - reg_output_loss: 81240.6278 - recon_mean_squared_error: 1.0437 - reg_output_mean_squared_error: 81240.6278 - val_loss: 469004.6775 - val_recon_loss: 1.0749 - val_reg_output_loss: 468897.1750 - val_recon_mean_squared_error: 1.0749 - val_reg_output_mean_squared_error: 468897.1750\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 81076.5333 - recon_loss: 1.0560 - reg_output_loss: 80970.9362 - recon_mean_squared_error: 1.0560 - reg_output_mean_squared_error: 80970.9362 - val_loss: 458246.2125 - val_recon_loss: 1.5229 - val_reg_output_loss: 458093.9225 - val_recon_mean_squared_error: 1.5229 - val_reg_output_mean_squared_error: 458093.9225\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 81649.1820 - recon_loss: 1.1177 - reg_output_loss: 81537.4138 - recon_mean_squared_error: 1.1177 - reg_output_mean_squared_error: 81537.4138 - val_loss: 464592.5850 - val_recon_loss: 1.0437 - val_reg_output_loss: 464488.2100 - val_recon_mean_squared_error: 1.0437 - val_reg_output_mean_squared_error: 464488.2100\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 80513.3882 - recon_loss: 1.1029 - reg_output_loss: 80403.0967 - recon_mean_squared_error: 1.1029 - reg_output_mean_squared_error: 80403.0967 - val_loss: 458195.1450 - val_recon_loss: 1.0823 - val_reg_output_loss: 458086.9125 - val_recon_mean_squared_error: 1.0823 - val_reg_output_mean_squared_error: 458086.9125\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 83598.6832 - recon_loss: 1.0526 - reg_output_loss: 83493.4193 - recon_mean_squared_error: 1.0526 - reg_output_mean_squared_error: 83493.4193 - val_loss: 458656.2625 - val_recon_loss: 1.0260 - val_reg_output_loss: 458553.6650 - val_recon_mean_squared_error: 1.0260 - val_reg_output_mean_squared_error: 458553.6650\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 81495.6510 - recon_loss: 1.0602 - reg_output_loss: 81389.6350 - recon_mean_squared_error: 1.0602 - reg_output_mean_squared_error: 81389.6350 - val_loss: 462992.7075 - val_recon_loss: 1.0535 - val_reg_output_loss: 462887.3600 - val_recon_mean_squared_error: 1.0535 - val_reg_output_mean_squared_error: 462887.3600\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 80323.1333 - recon_loss: 1.0495 - reg_output_loss: 80218.1824 - recon_mean_squared_error: 1.0495 - reg_output_mean_squared_error: 80218.1824 - val_loss: 459228.2250 - val_recon_loss: 1.1764 - val_reg_output_loss: 459110.5850 - val_recon_mean_squared_error: 1.1764 - val_reg_output_mean_squared_error: 459110.5850\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 80132.1678 - recon_loss: 1.0723 - reg_output_loss: 80024.9394 - recon_mean_squared_error: 1.0723 - reg_output_mean_squared_error: 80024.9394 - val_loss: 465672.1225 - val_recon_loss: 1.8153 - val_reg_output_loss: 465490.6000 - val_recon_mean_squared_error: 1.8153 - val_reg_output_mean_squared_error: 465490.6000\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79358.3798 - recon_loss: 1.1086 - reg_output_loss: 79247.5147 - recon_mean_squared_error: 1.1086 - reg_output_mean_squared_error: 79247.5147 - val_loss: 481276.4475 - val_recon_loss: 1.0174 - val_reg_output_loss: 481174.6975 - val_recon_mean_squared_error: 1.0174 - val_reg_output_mean_squared_error: 481174.6975\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 81165.0777 - recon_loss: 1.0430 - reg_output_loss: 81060.7768 - recon_mean_squared_error: 1.0430 - reg_output_mean_squared_error: 81060.7768 - val_loss: 484619.1725 - val_recon_loss: 1.0563 - val_reg_output_loss: 484513.5550 - val_recon_mean_squared_error: 1.0563 - val_reg_output_mean_squared_error: 484513.5550\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83661.3610 - recon_loss: 1.0508 - reg_output_loss: 83556.2847 - recon_mean_squared_error: 1.0508 - reg_output_mean_squared_error: 83556.2847 - val_loss: 466957.4425 - val_recon_loss: 1.2541 - val_reg_output_loss: 466832.0300 - val_recon_mean_squared_error: 1.2541 - val_reg_output_mean_squared_error: 466832.0300\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 81675.4161 - recon_loss: 1.0992 - reg_output_loss: 81565.4942 - recon_mean_squared_error: 1.0992 - reg_output_mean_squared_error: 81565.4942 - val_loss: 474091.3050 - val_recon_loss: 1.1357 - val_reg_output_loss: 473977.7250 - val_recon_mean_squared_error: 1.1357 - val_reg_output_mean_squared_error: 473977.7250\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 79791.5860 - recon_loss: 1.0690 - reg_output_loss: 79684.6832 - recon_mean_squared_error: 1.0690 - reg_output_mean_squared_error: 79684.6832 - val_loss: 477889.2300 - val_recon_loss: 1.3714 - val_reg_output_loss: 477752.0975 - val_recon_mean_squared_error: 1.3714 - val_reg_output_mean_squared_error: 477752.0975\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 80337.9589 - recon_loss: 1.0637 - reg_output_loss: 80231.5854 - recon_mean_squared_error: 1.0637 - reg_output_mean_squared_error: 80231.5854 - val_loss: 494204.9425 - val_recon_loss: 1.0615 - val_reg_output_loss: 494098.7925 - val_recon_mean_squared_error: 1.0615 - val_reg_output_mean_squared_error: 494098.7925\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 78994.1896 - recon_loss: 1.0588 - reg_output_loss: 78888.3125 - recon_mean_squared_error: 1.0588 - reg_output_mean_squared_error: 78888.3125 - val_loss: 504241.8475 - val_recon_loss: 1.0250 - val_reg_output_loss: 504139.3500 - val_recon_mean_squared_error: 1.0250 - val_reg_output_mean_squared_error: 504139.3500\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 79640.6235 - recon_loss: 1.0557 - reg_output_loss: 79535.0576 - recon_mean_squared_error: 1.0557 - reg_output_mean_squared_error: 79535.0576 - val_loss: 507332.6975 - val_recon_loss: 1.0737 - val_reg_output_loss: 507225.3350 - val_recon_mean_squared_error: 1.0737 - val_reg_output_mean_squared_error: 507225.3350\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83374.1273 - recon_loss: 1.0447 - reg_output_loss: 83269.6600 - recon_mean_squared_error: 1.0447 - reg_output_mean_squared_error: 83269.6600 - val_loss: 494324.1975 - val_recon_loss: 1.1964 - val_reg_output_loss: 494204.5775 - val_recon_mean_squared_error: 1.1964 - val_reg_output_mean_squared_error: 494204.5775\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 79593.4154 - recon_loss: 1.0818 - reg_output_loss: 79485.2381 - recon_mean_squared_error: 1.0818 - reg_output_mean_squared_error: 79485.2381 - val_loss: 495405.2275 - val_recon_loss: 1.7818 - val_reg_output_loss: 495227.0375 - val_recon_mean_squared_error: 1.7818 - val_reg_output_mean_squared_error: 495227.0375\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 81038.6513 - recon_loss: 1.0617 - reg_output_loss: 80932.4837 - recon_mean_squared_error: 1.0617 - reg_output_mean_squared_error: 80932.4837 - val_loss: 492648.3650 - val_recon_loss: 1.6502 - val_reg_output_loss: 492483.3600 - val_recon_mean_squared_error: 1.6502 - val_reg_output_mean_squared_error: 492483.3600\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82353.1727 - recon_loss: 1.0821 - reg_output_loss: 82244.9631 - recon_mean_squared_error: 1.0821 - reg_output_mean_squared_error: 82244.9631 - val_loss: 484779.0725 - val_recon_loss: 1.1633 - val_reg_output_loss: 484662.7475 - val_recon_mean_squared_error: 1.1633 - val_reg_output_mean_squared_error: 484662.7475\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 82826.2914 - recon_loss: 1.0729 - reg_output_loss: 82719.0005 - recon_mean_squared_error: 1.0729 - reg_output_mean_squared_error: 82719.0005 - val_loss: 478148.8475 - val_recon_loss: 1.0673 - val_reg_output_loss: 478042.1225 - val_recon_mean_squared_error: 1.0673 - val_reg_output_mean_squared_error: 478042.1225\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78257.1066 - recon_loss: 1.0461 - reg_output_loss: 78152.4984 - recon_mean_squared_error: 1.0461 - reg_output_mean_squared_error: 78152.4984 - val_loss: 492425.5750 - val_recon_loss: 1.0764 - val_reg_output_loss: 492317.9325 - val_recon_mean_squared_error: 1.0764 - val_reg_output_mean_squared_error: 492317.9325\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 79989.7736 - recon_loss: 1.0760 - reg_output_loss: 79882.1704 - recon_mean_squared_error: 1.0760 - reg_output_mean_squared_error: 79882.1704 - val_loss: 494280.5800 - val_recon_loss: 1.0083 - val_reg_output_loss: 494179.7475 - val_recon_mean_squared_error: 1.0083 - val_reg_output_mean_squared_error: 494179.7475\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 80508.6555 - recon_loss: 1.0718 - reg_output_loss: 80401.4786 - recon_mean_squared_error: 1.0718 - reg_output_mean_squared_error: 80401.4786 - val_loss: 492531.1050 - val_recon_loss: 1.0187 - val_reg_output_loss: 492429.2300 - val_recon_mean_squared_error: 1.0187 - val_reg_output_mean_squared_error: 492429.2300\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 79099.5893 - recon_loss: 1.0400 - reg_output_loss: 78995.5873 - recon_mean_squared_error: 1.0400 - reg_output_mean_squared_error: 78995.5873 - val_loss: 489473.7625 - val_recon_loss: 1.2103 - val_reg_output_loss: 489352.7400 - val_recon_mean_squared_error: 1.2103 - val_reg_output_mean_squared_error: 489352.7400\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79570.2985 - recon_loss: 1.0759 - reg_output_loss: 79462.7098 - recon_mean_squared_error: 1.0759 - reg_output_mean_squared_error: 79462.7098 - val_loss: 490795.6200 - val_recon_loss: 1.1409 - val_reg_output_loss: 490681.5300 - val_recon_mean_squared_error: 1.1409 - val_reg_output_mean_squared_error: 490681.5300\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 80056.4820 - recon_loss: 1.0491 - reg_output_loss: 79951.5722 - recon_mean_squared_error: 1.0491 - reg_output_mean_squared_error: 79951.5722 - val_loss: 502737.5575 - val_recon_loss: 1.0118 - val_reg_output_loss: 502636.3700 - val_recon_mean_squared_error: 1.0118 - val_reg_output_mean_squared_error: 502636.3700\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 80410.7390 - recon_loss: 1.0266 - reg_output_loss: 80308.0791 - recon_mean_squared_error: 1.0266 - reg_output_mean_squared_error: 80308.0791 - val_loss: 491797.0350 - val_recon_loss: 1.0603 - val_reg_output_loss: 491690.9975 - val_recon_mean_squared_error: 1.0603 - val_reg_output_mean_squared_error: 491690.9975\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 78586.8181 - recon_loss: 1.0763 - reg_output_loss: 78479.1889 - recon_mean_squared_error: 1.0763 - reg_output_mean_squared_error: 78479.1889 - val_loss: 502226.2200 - val_recon_loss: 1.4219 - val_reg_output_loss: 502084.0300 - val_recon_mean_squared_error: 1.4219 - val_reg_output_mean_squared_error: 502084.0300\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 77896.1573 - recon_loss: 1.0431 - reg_output_loss: 77791.8444 - recon_mean_squared_error: 1.0431 - reg_output_mean_squared_error: 77791.8444 - val_loss: 508598.4550 - val_recon_loss: 1.1909 - val_reg_output_loss: 508479.3625 - val_recon_mean_squared_error: 1.1909 - val_reg_output_mean_squared_error: 508479.3625\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 78720.6916 - recon_loss: 1.0762 - reg_output_loss: 78613.0689 - recon_mean_squared_error: 1.0762 - reg_output_mean_squared_error: 78613.0689 - val_loss: 502358.0675 - val_recon_loss: 1.0985 - val_reg_output_loss: 502248.2150 - val_recon_mean_squared_error: 1.0985 - val_reg_output_mean_squared_error: 502248.2150\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79464.9623 - recon_loss: 1.0527 - reg_output_loss: 79359.6891 - recon_mean_squared_error: 1.0527 - reg_output_mean_squared_error: 79359.6891 - val_loss: 503985.5300 - val_recon_loss: 1.3590 - val_reg_output_loss: 503849.6300 - val_recon_mean_squared_error: 1.3590 - val_reg_output_mean_squared_error: 503849.6300\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 79042.0652 - recon_loss: 1.0404 - reg_output_loss: 78938.0255 - recon_mean_squared_error: 1.0404 - reg_output_mean_squared_error: 78938.0255 - val_loss: 497330.2275 - val_recon_loss: 1.0250 - val_reg_output_loss: 497227.7200 - val_recon_mean_squared_error: 1.0250 - val_reg_output_mean_squared_error: 497227.7200\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 79310.8837 - recon_loss: 1.0169 - reg_output_loss: 79209.1971 - recon_mean_squared_error: 1.0169 - reg_output_mean_squared_error: 79209.1971 - val_loss: 495635.7600 - val_recon_loss: 1.1583 - val_reg_output_loss: 495519.9250 - val_recon_mean_squared_error: 1.1583 - val_reg_output_mean_squared_error: 495519.9250\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 76603.5829 - recon_loss: 1.0664 - reg_output_loss: 76496.9381 - recon_mean_squared_error: 1.0664 - reg_output_mean_squared_error: 76496.9381 - val_loss: 505079.7750 - val_recon_loss: 1.0537 - val_reg_output_loss: 504974.4125 - val_recon_mean_squared_error: 1.0537 - val_reg_output_mean_squared_error: 504974.4125\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 81531.0963 - recon_loss: 1.0753 - reg_output_loss: 81423.5708 - recon_mean_squared_error: 1.0753 - reg_output_mean_squared_error: 81423.5708 - val_loss: 497777.9625 - val_recon_loss: 1.0351 - val_reg_output_loss: 497674.4475 - val_recon_mean_squared_error: 1.0351 - val_reg_output_mean_squared_error: 497674.4475\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 78707.1907 - recon_loss: 1.0379 - reg_output_loss: 78603.4022 - recon_mean_squared_error: 1.0379 - reg_output_mean_squared_error: 78603.4022 - val_loss: 506181.6575 - val_recon_loss: 1.0241 - val_reg_output_loss: 506079.2450 - val_recon_mean_squared_error: 1.0241 - val_reg_output_mean_squared_error: 506079.2450\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 79218.4798 - recon_loss: 1.0511 - reg_output_loss: 79113.3657 - recon_mean_squared_error: 1.0511 - reg_output_mean_squared_error: 79113.3657 - val_loss: 491836.2100 - val_recon_loss: 1.0213 - val_reg_output_loss: 491734.0875 - val_recon_mean_squared_error: 1.0213 - val_reg_output_mean_squared_error: 491734.0875\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 78126.4993 - recon_loss: 1.0391 - reg_output_loss: 78022.5867 - recon_mean_squared_error: 1.0391 - reg_output_mean_squared_error: 78022.5867 - val_loss: 486037.2275 - val_recon_loss: 1.1018 - val_reg_output_loss: 485927.0375 - val_recon_mean_squared_error: 1.1018 - val_reg_output_mean_squared_error: 485927.0375\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 81161.4924 - recon_loss: 1.0312 - reg_output_loss: 81058.3709 - recon_mean_squared_error: 1.0312 - reg_output_mean_squared_error: 81058.3709 - val_loss: 477320.0925 - val_recon_loss: 1.0399 - val_reg_output_loss: 477216.1000 - val_recon_mean_squared_error: 1.0399 - val_reg_output_mean_squared_error: 477216.1000\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78739.4422 - recon_loss: 1.0505 - reg_output_loss: 78634.3933 - recon_mean_squared_error: 1.0505 - reg_output_mean_squared_error: 78634.3933 - val_loss: 476932.5375 - val_recon_loss: 1.0399 - val_reg_output_loss: 476828.5475 - val_recon_mean_squared_error: 1.0399 - val_reg_output_mean_squared_error: 476828.5475\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 77111.4662 - recon_loss: 1.0405 - reg_output_loss: 77007.4167 - recon_mean_squared_error: 1.0405 - reg_output_mean_squared_error: 77007.4167 - val_loss: 489671.7025 - val_recon_loss: 1.0151 - val_reg_output_loss: 489570.2000 - val_recon_mean_squared_error: 1.0151 - val_reg_output_mean_squared_error: 489570.2000\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79224.8238 - recon_loss: 1.0356 - reg_output_loss: 79121.2586 - recon_mean_squared_error: 1.0356 - reg_output_mean_squared_error: 79121.2586 - val_loss: 493351.1850 - val_recon_loss: 1.1489 - val_reg_output_loss: 493236.2900 - val_recon_mean_squared_error: 1.1489 - val_reg_output_mean_squared_error: 493236.2900\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 78164.8042 - recon_loss: 1.0484 - reg_output_loss: 78059.9628 - recon_mean_squared_error: 1.0484 - reg_output_mean_squared_error: 78059.9628 - val_loss: 498722.3225 - val_recon_loss: 1.0112 - val_reg_output_loss: 498621.2225 - val_recon_mean_squared_error: 1.0112 - val_reg_output_mean_squared_error: 498621.2225\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 83423.1944 - recon_loss: 1.0351 - reg_output_loss: 83319.6888 - recon_mean_squared_error: 1.0351 - reg_output_mean_squared_error: 83319.6888 - val_loss: 495737.1575 - val_recon_loss: 1.0725 - val_reg_output_loss: 495629.9200 - val_recon_mean_squared_error: 1.0725 - val_reg_output_mean_squared_error: 495629.9200\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 77020.8418 - recon_loss: 1.0760 - reg_output_loss: 76913.2391 - recon_mean_squared_error: 1.0760 - reg_output_mean_squared_error: 76913.2391 - val_loss: 497897.1875 - val_recon_loss: 1.0192 - val_reg_output_loss: 497795.2750 - val_recon_mean_squared_error: 1.0192 - val_reg_output_mean_squared_error: 497795.2750\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 78522.2130 - recon_loss: 1.0542 - reg_output_loss: 78416.7926 - recon_mean_squared_error: 1.0542 - reg_output_mean_squared_error: 78416.7926 - val_loss: 494391.4375 - val_recon_loss: 1.6587 - val_reg_output_loss: 494225.5700 - val_recon_mean_squared_error: 1.6587 - val_reg_output_mean_squared_error: 494225.5700\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 76554.9369 - recon_loss: 1.0225 - reg_output_loss: 76452.6891 - recon_mean_squared_error: 1.0225 - reg_output_mean_squared_error: 76452.6891 - val_loss: 498250.4300 - val_recon_loss: 1.1092 - val_reg_output_loss: 498139.5175 - val_recon_mean_squared_error: 1.1092 - val_reg_output_mean_squared_error: 498139.5175\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78936.9819 - recon_loss: 1.0382 - reg_output_loss: 78833.1568 - recon_mean_squared_error: 1.0382 - reg_output_mean_squared_error: 78833.1568 - val_loss: 503583.5350 - val_recon_loss: 1.3541 - val_reg_output_loss: 503448.1250 - val_recon_mean_squared_error: 1.3541 - val_reg_output_mean_squared_error: 503448.1250\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 77973.4544 - recon_loss: 1.0960 - reg_output_loss: 77863.8540 - recon_mean_squared_error: 1.0960 - reg_output_mean_squared_error: 77863.8540 - val_loss: 502452.9250 - val_recon_loss: 1.3953 - val_reg_output_loss: 502313.3900 - val_recon_mean_squared_error: 1.3953 - val_reg_output_mean_squared_error: 502313.3900\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78617.7510 - recon_loss: 1.0306 - reg_output_loss: 78514.6860 - recon_mean_squared_error: 1.0306 - reg_output_mean_squared_error: 78514.6860 - val_loss: 494950.7325 - val_recon_loss: 1.0370 - val_reg_output_loss: 494847.0400 - val_recon_mean_squared_error: 1.0370 - val_reg_output_mean_squared_error: 494847.0400\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 80515.9794 - recon_loss: 1.0569 - reg_output_loss: 80410.2849 - recon_mean_squared_error: 1.0569 - reg_output_mean_squared_error: 80410.2849 - val_loss: 481241.2150 - val_recon_loss: 1.0276 - val_reg_output_loss: 481138.4375 - val_recon_mean_squared_error: 1.0276 - val_reg_output_mean_squared_error: 481138.4375\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 80225.0492 - recon_loss: 1.0228 - reg_output_loss: 80122.7647 - recon_mean_squared_error: 1.0228 - reg_output_mean_squared_error: 80122.7647 - val_loss: 470439.8500 - val_recon_loss: 1.3758 - val_reg_output_loss: 470302.2825 - val_recon_mean_squared_error: 1.3758 - val_reg_output_mean_squared_error: 470302.2825\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 80895.2903 - recon_loss: 1.0413 - reg_output_loss: 80791.1588 - recon_mean_squared_error: 1.0413 - reg_output_mean_squared_error: 80791.1588 - val_loss: 457753.8275 - val_recon_loss: 1.0794 - val_reg_output_loss: 457645.8900 - val_recon_mean_squared_error: 1.0794 - val_reg_output_mean_squared_error: 457645.8900\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78459.7658 - recon_loss: 1.0252 - reg_output_loss: 78357.2417 - recon_mean_squared_error: 1.0252 - reg_output_mean_squared_error: 78357.2417 - val_loss: 465510.7675 - val_recon_loss: 1.0572 - val_reg_output_loss: 465405.0475 - val_recon_mean_squared_error: 1.0572 - val_reg_output_mean_squared_error: 465405.0475\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 76542.1417 - recon_loss: 1.0406 - reg_output_loss: 76438.0779 - recon_mean_squared_error: 1.0406 - reg_output_mean_squared_error: 76438.0779 - val_loss: 467351.0675 - val_recon_loss: 1.2879 - val_reg_output_loss: 467222.2675 - val_recon_mean_squared_error: 1.2879 - val_reg_output_mean_squared_error: 467222.2675\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 75835.9530 - recon_loss: 1.0475 - reg_output_loss: 75731.1989 - recon_mean_squared_error: 1.0475 - reg_output_mean_squared_error: 75731.1989 - val_loss: 474219.3900 - val_recon_loss: 1.1032 - val_reg_output_loss: 474109.0700 - val_recon_mean_squared_error: 1.1032 - val_reg_output_mean_squared_error: 474109.0700\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 80454.4083 - recon_loss: 1.0330 - reg_output_loss: 80351.1127 - recon_mean_squared_error: 1.0330 - reg_output_mean_squared_error: 80351.1127 - val_loss: 470179.3350 - val_recon_loss: 1.1987 - val_reg_output_loss: 470059.4700 - val_recon_mean_squared_error: 1.1987 - val_reg_output_mean_squared_error: 470059.4700\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 76638.1181 - recon_loss: 1.0559 - reg_output_loss: 76532.5294 - recon_mean_squared_error: 1.0559 - reg_output_mean_squared_error: 76532.5294 - val_loss: 470023.7475 - val_recon_loss: 1.0612 - val_reg_output_loss: 469917.6400 - val_recon_mean_squared_error: 1.0612 - val_reg_output_mean_squared_error: 469917.6400\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 74608.8368 - recon_loss: 1.0450 - reg_output_loss: 74504.3421 - recon_mean_squared_error: 1.0450 - reg_output_mean_squared_error: 74504.3421 - val_loss: 486624.0875 - val_recon_loss: 1.0357 - val_reg_output_loss: 486520.5225 - val_recon_mean_squared_error: 1.0357 - val_reg_output_mean_squared_error: 486520.5225\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 76589.6236 - recon_loss: 1.0178 - reg_output_loss: 76487.8433 - recon_mean_squared_error: 1.0178 - reg_output_mean_squared_error: 76487.8433 - val_loss: 481010.3000 - val_recon_loss: 1.0504 - val_reg_output_loss: 480905.2825 - val_recon_mean_squared_error: 1.0504 - val_reg_output_mean_squared_error: 480905.2825\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78527.4723 - recon_loss: 1.0390 - reg_output_loss: 78423.5750 - recon_mean_squared_error: 1.0390 - reg_output_mean_squared_error: 78423.5750 - val_loss: 477073.7425 - val_recon_loss: 1.0318 - val_reg_output_loss: 476970.5675 - val_recon_mean_squared_error: 1.0318 - val_reg_output_mean_squared_error: 476970.5675\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 74297.6397 - recon_loss: 1.0411 - reg_output_loss: 74193.5293 - recon_mean_squared_error: 1.0411 - reg_output_mean_squared_error: 74193.5293 - val_loss: 486364.3950 - val_recon_loss: 1.1965 - val_reg_output_loss: 486244.7500 - val_recon_mean_squared_error: 1.1965 - val_reg_output_mean_squared_error: 486244.7500\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 76015.3220 - recon_loss: 1.0178 - reg_output_loss: 75913.5408 - recon_mean_squared_error: 1.0178 - reg_output_mean_squared_error: 75913.5408 - val_loss: 491860.8750 - val_recon_loss: 1.0642 - val_reg_output_loss: 491754.4600 - val_recon_mean_squared_error: 1.0642 - val_reg_output_mean_squared_error: 491754.4600\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78413.4793 - recon_loss: 1.0671 - reg_output_loss: 78306.7708 - recon_mean_squared_error: 1.0671 - reg_output_mean_squared_error: 78306.7708 - val_loss: 485291.9925 - val_recon_loss: 1.1290 - val_reg_output_loss: 485179.1125 - val_recon_mean_squared_error: 1.1290 - val_reg_output_mean_squared_error: 485179.1125\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 77462.9700 - recon_loss: 1.0333 - reg_output_loss: 77359.6446 - recon_mean_squared_error: 1.0333 - reg_output_mean_squared_error: 77359.6446 - val_loss: 474640.4200 - val_recon_loss: 1.1219 - val_reg_output_loss: 474528.2225 - val_recon_mean_squared_error: 1.1219 - val_reg_output_mean_squared_error: 474528.2225\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 79630.7160 - recon_loss: 1.0605 - reg_output_loss: 79524.6683 - recon_mean_squared_error: 1.0605 - reg_output_mean_squared_error: 79524.6683 - val_loss: 467399.1400 - val_recon_loss: 1.0985 - val_reg_output_loss: 467289.2900 - val_recon_mean_squared_error: 1.0985 - val_reg_output_mean_squared_error: 467289.2900\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 75585.3779 - recon_loss: 1.0175 - reg_output_loss: 75483.6294 - recon_mean_squared_error: 1.0175 - reg_output_mean_squared_error: 75483.6294 - val_loss: 475669.4350 - val_recon_loss: 1.2895 - val_reg_output_loss: 475540.4800 - val_recon_mean_squared_error: 1.2895 - val_reg_output_mean_squared_error: 475540.4800\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 78210.2422 - recon_loss: 1.0433 - reg_output_loss: 78105.9096 - recon_mean_squared_error: 1.0433 - reg_output_mean_squared_error: 78105.9096 - val_loss: 482888.7125 - val_recon_loss: 1.0470 - val_reg_output_loss: 482784.0100 - val_recon_mean_squared_error: 1.0470 - val_reg_output_mean_squared_error: 482784.0100\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 76522.8957 - recon_loss: 1.0253 - reg_output_loss: 76420.3667 - recon_mean_squared_error: 1.0253 - reg_output_mean_squared_error: 76420.3667 - val_loss: 486346.7375 - val_recon_loss: 1.0318 - val_reg_output_loss: 486243.5500 - val_recon_mean_squared_error: 1.0318 - val_reg_output_mean_squared_error: 486243.5500\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 77338.3701 - recon_loss: 1.0423 - reg_output_loss: 77234.1353 - recon_mean_squared_error: 1.0423 - reg_output_mean_squared_error: 77234.1353 - val_loss: 477196.4675 - val_recon_loss: 1.0178 - val_reg_output_loss: 477094.6925 - val_recon_mean_squared_error: 1.0178 - val_reg_output_mean_squared_error: 477094.6925\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 77606.5917 - recon_loss: 1.0356 - reg_output_loss: 77503.0316 - recon_mean_squared_error: 1.0356 - reg_output_mean_squared_error: 77503.0316 - val_loss: 468128.4800 - val_recon_loss: 1.1369 - val_reg_output_loss: 468014.7850 - val_recon_mean_squared_error: 1.1369 - val_reg_output_mean_squared_error: 468014.7850\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 77064.1519 - recon_loss: 1.0209 - reg_output_loss: 76962.0660 - recon_mean_squared_error: 1.0209 - reg_output_mean_squared_error: 76962.0660 - val_loss: 472386.8425 - val_recon_loss: 1.0963 - val_reg_output_loss: 472277.2150 - val_recon_mean_squared_error: 1.0963 - val_reg_output_mean_squared_error: 472277.2150\n",
      "Epoch 319/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 77683.8497 - recon_loss: 1.0352 - reg_output_loss: 77580.3315 - recon_mean_squared_error: 1.0352 - reg_output_mean_squared_error: 77580.3315 - val_loss: 478671.8800 - val_recon_loss: 1.2856 - val_reg_output_loss: 478543.3300 - val_recon_mean_squared_error: 1.2856 - val_reg_output_mean_squared_error: 478543.3300\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 79266.1705 - recon_loss: 1.0625 - reg_output_loss: 79159.9232 - recon_mean_squared_error: 1.0625 - reg_output_mean_squared_error: 79159.9232 - val_loss: 471050.3575 - val_recon_loss: 1.5822 - val_reg_output_loss: 470892.1325 - val_recon_mean_squared_error: 1.5822 - val_reg_output_mean_squared_error: 470892.1325\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 78440.3439 - recon_loss: 1.0298 - reg_output_loss: 78337.3659 - recon_mean_squared_error: 1.0298 - reg_output_mean_squared_error: 78337.3659 - val_loss: 463786.1525 - val_recon_loss: 1.0426 - val_reg_output_loss: 463681.8900 - val_recon_mean_squared_error: 1.0426 - val_reg_output_mean_squared_error: 463681.8900\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 78468.8893 - recon_loss: 1.0746 - reg_output_loss: 78361.4257 - recon_mean_squared_error: 1.0746 - reg_output_mean_squared_error: 78361.4257 - val_loss: 457508.3100 - val_recon_loss: 1.0268 - val_reg_output_loss: 457405.6300 - val_recon_mean_squared_error: 1.0268 - val_reg_output_mean_squared_error: 457405.6300\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 74349.6821 - recon_loss: 1.0219 - reg_output_loss: 74247.4950 - recon_mean_squared_error: 1.0219 - reg_output_mean_squared_error: 74247.4950 - val_loss: 459578.3175 - val_recon_loss: 1.0692 - val_reg_output_loss: 459471.3975 - val_recon_mean_squared_error: 1.0692 - val_reg_output_mean_squared_error: 459471.3975\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 78521.3857 - recon_loss: 1.0238 - reg_output_loss: 78419.0067 - recon_mean_squared_error: 1.0238 - reg_output_mean_squared_error: 78419.0067 - val_loss: 451180.6550 - val_recon_loss: 1.6277 - val_reg_output_loss: 451017.8900 - val_recon_mean_squared_error: 1.6277 - val_reg_output_mean_squared_error: 451017.8900\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 80640.5963 - recon_loss: 1.0762 - reg_output_loss: 80532.9752 - recon_mean_squared_error: 1.0762 - reg_output_mean_squared_error: 80532.9752 - val_loss: 437616.2925 - val_recon_loss: 1.0285 - val_reg_output_loss: 437513.4425 - val_recon_mean_squared_error: 1.0285 - val_reg_output_mean_squared_error: 437513.4425\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 81586.3319 - recon_loss: 1.0402 - reg_output_loss: 81482.3097 - recon_mean_squared_error: 1.0402 - reg_output_mean_squared_error: 81482.3097 - val_loss: 432139.4525 - val_recon_loss: 1.0046 - val_reg_output_loss: 432038.9950 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 432038.9950\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 82808.2211 - recon_loss: 1.0172 - reg_output_loss: 82706.5021 - recon_mean_squared_error: 1.0172 - reg_output_mean_squared_error: 82706.5021 - val_loss: 424339.4575 - val_recon_loss: 1.0119 - val_reg_output_loss: 424238.2675 - val_recon_mean_squared_error: 1.0119 - val_reg_output_mean_squared_error: 424238.2675\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 75855.2706 - recon_loss: 1.0327 - reg_output_loss: 75752.0055 - recon_mean_squared_error: 1.0327 - reg_output_mean_squared_error: 75752.0055 - val_loss: 436552.6275 - val_recon_loss: 1.0920 - val_reg_output_loss: 436443.4300 - val_recon_mean_squared_error: 1.0920 - val_reg_output_mean_squared_error: 436443.4300\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 74005.6338 - recon_loss: 1.0445 - reg_output_loss: 73901.1852 - recon_mean_squared_error: 1.0445 - reg_output_mean_squared_error: 73901.1852 - val_loss: 439117.4100 - val_recon_loss: 1.0286 - val_reg_output_loss: 439014.5475 - val_recon_mean_squared_error: 1.0286 - val_reg_output_mean_squared_error: 439014.5475\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 76296.4026 - recon_loss: 1.0194 - reg_output_loss: 76194.4646 - recon_mean_squared_error: 1.0194 - reg_output_mean_squared_error: 76194.4646 - val_loss: 446534.1375 - val_recon_loss: 1.0243 - val_reg_output_loss: 446431.7125 - val_recon_mean_squared_error: 1.0243 - val_reg_output_mean_squared_error: 446431.7125\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 80901.3992 - recon_loss: 1.0146 - reg_output_loss: 80799.9355 - recon_mean_squared_error: 1.0146 - reg_output_mean_squared_error: 80799.9355 - val_loss: 439576.1225 - val_recon_loss: 1.0440 - val_reg_output_loss: 439471.7200 - val_recon_mean_squared_error: 1.0440 - val_reg_output_mean_squared_error: 439471.7200\n",
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79253.9135 - recon_loss: 1.0325 - reg_output_loss: 79150.6616 - recon_mean_squared_error: 1.0325 - reg_output_mean_squared_error: 79150.6616 - val_loss: 427881.3175 - val_recon_loss: 1.0303 - val_reg_output_loss: 427778.2850 - val_recon_mean_squared_error: 1.0303 - val_reg_output_mean_squared_error: 427778.2850\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 73541.7369 - recon_loss: 1.0265 - reg_output_loss: 73439.0901 - recon_mean_squared_error: 1.0265 - reg_output_mean_squared_error: 73439.0901 - val_loss: 440709.3250 - val_recon_loss: 1.0355 - val_reg_output_loss: 440605.7775 - val_recon_mean_squared_error: 1.0355 - val_reg_output_mean_squared_error: 440605.7775\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 78355.7808 - recon_loss: 1.0193 - reg_output_loss: 78253.8514 - recon_mean_squared_error: 1.0193 - reg_output_mean_squared_error: 78253.8514 - val_loss: 429518.1375 - val_recon_loss: 1.0151 - val_reg_output_loss: 429416.6250 - val_recon_mean_squared_error: 1.0151 - val_reg_output_mean_squared_error: 429416.6250\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 79930.6868 - recon_loss: 1.0277 - reg_output_loss: 79827.9151 - recon_mean_squared_error: 1.0277 - reg_output_mean_squared_error: 79827.9151 - val_loss: 424138.5500 - val_recon_loss: 1.0721 - val_reg_output_loss: 424031.3500 - val_recon_mean_squared_error: 1.0721 - val_reg_output_mean_squared_error: 424031.3500\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 78227.4566 - recon_loss: 1.0248 - reg_output_loss: 78124.9822 - recon_mean_squared_error: 1.0248 - reg_output_mean_squared_error: 78124.9822 - val_loss: 428935.1825 - val_recon_loss: 1.0368 - val_reg_output_loss: 428831.5050 - val_recon_mean_squared_error: 1.0368 - val_reg_output_mean_squared_error: 428831.5050\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 76014.8360 - recon_loss: 1.0187 - reg_output_loss: 75912.9680 - recon_mean_squared_error: 1.0187 - reg_output_mean_squared_error: 75912.9680 - val_loss: 432375.1675 - val_recon_loss: 1.0474 - val_reg_output_loss: 432270.4325 - val_recon_mean_squared_error: 1.0474 - val_reg_output_mean_squared_error: 432270.4325\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 78401.3608 - recon_loss: 1.0183 - reg_output_loss: 78299.5324 - recon_mean_squared_error: 1.0183 - reg_output_mean_squared_error: 78299.5324 - val_loss: 424336.3025 - val_recon_loss: 1.0279 - val_reg_output_loss: 424233.5025 - val_recon_mean_squared_error: 1.0279 - val_reg_output_mean_squared_error: 424233.5025\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 75235.7986 - recon_loss: 1.0283 - reg_output_loss: 75132.9728 - recon_mean_squared_error: 1.0283 - reg_output_mean_squared_error: 75132.9728 - val_loss: 427706.8875 - val_recon_loss: 1.0164 - val_reg_output_loss: 427605.2550 - val_recon_mean_squared_error: 1.0164 - val_reg_output_mean_squared_error: 427605.2550\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79858.6833 - recon_loss: 1.0260 - reg_output_loss: 79756.0885 - recon_mean_squared_error: 1.0260 - reg_output_mean_squared_error: 79756.0885 - val_loss: 414293.2425 - val_recon_loss: 1.1846 - val_reg_output_loss: 414174.7775 - val_recon_mean_squared_error: 1.1846 - val_reg_output_mean_squared_error: 414174.7775\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 76723.7547 - recon_loss: 1.0155 - reg_output_loss: 76622.2043 - recon_mean_squared_error: 1.0155 - reg_output_mean_squared_error: 76622.2043 - val_loss: 409622.5450 - val_recon_loss: 1.0325 - val_reg_output_loss: 409519.2950 - val_recon_mean_squared_error: 1.0325 - val_reg_output_mean_squared_error: 409519.2950\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 83656.5714 - recon_loss: 1.0277 - reg_output_loss: 83553.8018 - recon_mean_squared_error: 1.0277 - reg_output_mean_squared_error: 83553.8018 - val_loss: 383836.9150 - val_recon_loss: 1.0143 - val_reg_output_loss: 383735.4750 - val_recon_mean_squared_error: 1.0143 - val_reg_output_mean_squared_error: 383735.4750\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 76927.9602 - recon_loss: 1.0249 - reg_output_loss: 76825.4671 - recon_mean_squared_error: 1.0249 - reg_output_mean_squared_error: 76825.4671 - val_loss: 378972.4263 - val_recon_loss: 1.0296 - val_reg_output_loss: 378869.4662 - val_recon_mean_squared_error: 1.0296 - val_reg_output_mean_squared_error: 378869.4662\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 82686.6574 - recon_loss: 1.0110 - reg_output_loss: 82585.5518 - recon_mean_squared_error: 1.0110 - reg_output_mean_squared_error: 82585.5518 - val_loss: 371276.1500 - val_recon_loss: 1.0351 - val_reg_output_loss: 371172.6437 - val_recon_mean_squared_error: 1.0351 - val_reg_output_mean_squared_error: 371172.6437\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 80598.1687 - recon_loss: 1.0275 - reg_output_loss: 80495.4190 - recon_mean_squared_error: 1.0275 - reg_output_mean_squared_error: 80495.4190 - val_loss: 362396.0325 - val_recon_loss: 1.0703 - val_reg_output_loss: 362289.0100 - val_recon_mean_squared_error: 1.0703 - val_reg_output_mean_squared_error: 362289.0100\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 77639.1239 - recon_loss: 1.0166 - reg_output_loss: 77537.4620 - recon_mean_squared_error: 1.0166 - reg_output_mean_squared_error: 77537.4620 - val_loss: 357168.9338 - val_recon_loss: 1.0463 - val_reg_output_loss: 357064.3025 - val_recon_mean_squared_error: 1.0463 - val_reg_output_mean_squared_error: 357064.3025\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 80162.1518 - recon_loss: 1.0061 - reg_output_loss: 80061.5467 - recon_mean_squared_error: 1.0061 - reg_output_mean_squared_error: 80061.5467 - val_loss: 348823.5625 - val_recon_loss: 1.0323 - val_reg_output_loss: 348720.3275 - val_recon_mean_squared_error: 1.0323 - val_reg_output_mean_squared_error: 348720.3275\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 76075.8126 - recon_loss: 1.0218 - reg_output_loss: 75973.6334 - recon_mean_squared_error: 1.0218 - reg_output_mean_squared_error: 75973.6334 - val_loss: 354198.3275 - val_recon_loss: 1.0047 - val_reg_output_loss: 354097.8700 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 354097.8700\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 217us/step - loss: 84771.7468 - recon_loss: 1.0286 - reg_output_loss: 84668.8850 - recon_mean_squared_error: 1.0286 - reg_output_mean_squared_error: 84668.8850 - val_loss: 337329.9050 - val_recon_loss: 1.0173 - val_reg_output_loss: 337228.1788 - val_recon_mean_squared_error: 1.0173 - val_reg_output_mean_squared_error: 337228.1788\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 77537.4426 - recon_loss: 1.0198 - reg_output_loss: 77435.4694 - recon_mean_squared_error: 1.0198 - reg_output_mean_squared_error: 77435.4694 - val_loss: 339209.1562 - val_recon_loss: 1.0667 - val_reg_output_loss: 339102.4738 - val_recon_mean_squared_error: 1.0667 - val_reg_output_mean_squared_error: 339102.4738\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 82044.8890 - recon_loss: 1.0279 - reg_output_loss: 81942.1030 - recon_mean_squared_error: 1.0279 - reg_output_mean_squared_error: 81942.1030 - val_loss: 333311.3862 - val_recon_loss: 1.0108 - val_reg_output_loss: 333210.3050 - val_recon_mean_squared_error: 1.0108 - val_reg_output_mean_squared_error: 333210.3050\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 80912.0791 - recon_loss: 1.0231 - reg_output_loss: 80809.7659 - recon_mean_squared_error: 1.0231 - reg_output_mean_squared_error: 80809.7659 - val_loss: 326617.9363 - val_recon_loss: 1.0102 - val_reg_output_loss: 326516.9200 - val_recon_mean_squared_error: 1.0102 - val_reg_output_mean_squared_error: 326516.9200\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 280us/step - loss: 75085.4592 - recon_loss: 1.0121 - reg_output_loss: 74984.2530 - recon_mean_squared_error: 1.0121 - reg_output_mean_squared_error: 74984.2530 - val_loss: 335177.9925 - val_recon_loss: 1.0193 - val_reg_output_loss: 335076.0725 - val_recon_mean_squared_error: 1.0193 - val_reg_output_mean_squared_error: 335076.0725\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 80815.6005 - recon_loss: 1.0195 - reg_output_loss: 80713.6525 - recon_mean_squared_error: 1.0195 - reg_output_mean_squared_error: 80713.6525 - val_loss: 332841.3725 - val_recon_loss: 1.0273 - val_reg_output_loss: 332738.6412 - val_recon_mean_squared_error: 1.0273 - val_reg_output_mean_squared_error: 332738.6412\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 78323.8572 - recon_loss: 1.0147 - reg_output_loss: 78222.3846 - recon_mean_squared_error: 1.0147 - reg_output_mean_squared_error: 78222.3846 - val_loss: 336962.4050 - val_recon_loss: 1.0441 - val_reg_output_loss: 336857.9888 - val_recon_mean_squared_error: 1.0441 - val_reg_output_mean_squared_error: 336857.9888\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 220us/step - loss: 85338.2682 - recon_loss: 1.0145 - reg_output_loss: 85236.8150 - recon_mean_squared_error: 1.0145 - reg_output_mean_squared_error: 85236.8150 - val_loss: 319716.7825 - val_recon_loss: 1.0669 - val_reg_output_loss: 319610.0975 - val_recon_mean_squared_error: 1.0669 - val_reg_output_mean_squared_error: 319610.0975\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 82066.5113 - recon_loss: 1.0322 - reg_output_loss: 81963.2932 - recon_mean_squared_error: 1.0322 - reg_output_mean_squared_error: 81963.2932 - val_loss: 314811.1462 - val_recon_loss: 1.0063 - val_reg_output_loss: 314710.5175 - val_recon_mean_squared_error: 1.0063 - val_reg_output_mean_squared_error: 314710.5175\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 77682.0777 - recon_loss: 1.0204 - reg_output_loss: 77580.0427 - recon_mean_squared_error: 1.0204 - reg_output_mean_squared_error: 77580.0427 - val_loss: 317191.0900 - val_recon_loss: 1.0507 - val_reg_output_loss: 317086.0100 - val_recon_mean_squared_error: 1.0507 - val_reg_output_mean_squared_error: 317086.0100\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 81754.8788 - recon_loss: 1.0124 - reg_output_loss: 81653.6351 - recon_mean_squared_error: 1.0124 - reg_output_mean_squared_error: 81653.6351 - val_loss: 312933.7188 - val_recon_loss: 1.0152 - val_reg_output_loss: 312832.1900 - val_recon_mean_squared_error: 1.0152 - val_reg_output_mean_squared_error: 312832.1900\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - 0s 280us/step - loss: 86741.6081 - recon_loss: 1.0156 - reg_output_loss: 86640.0494 - recon_mean_squared_error: 1.0156 - reg_output_mean_squared_error: 86640.0494 - val_loss: 302301.2500 - val_recon_loss: 1.1710 - val_reg_output_loss: 302184.1550 - val_recon_mean_squared_error: 1.1710 - val_reg_output_mean_squared_error: 302184.1550\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 80588.1867 - recon_loss: 1.0170 - reg_output_loss: 80486.4852 - recon_mean_squared_error: 1.0170 - reg_output_mean_squared_error: 80486.4852 - val_loss: 298669.3625 - val_recon_loss: 1.0098 - val_reg_output_loss: 298568.3775 - val_recon_mean_squared_error: 1.0098 - val_reg_output_mean_squared_error: 298568.3775\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 79908.6953 - recon_loss: 1.0149 - reg_output_loss: 79807.2053 - recon_mean_squared_error: 1.0149 - reg_output_mean_squared_error: 79807.2053 - val_loss: 299123.6038 - val_recon_loss: 1.0235 - val_reg_output_loss: 299021.2575 - val_recon_mean_squared_error: 1.0235 - val_reg_output_mean_squared_error: 299021.2575\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 83829.6557 - recon_loss: 1.0219 - reg_output_loss: 83727.4675 - recon_mean_squared_error: 1.0219 - reg_output_mean_squared_error: 83727.4675 - val_loss: 294335.4075 - val_recon_loss: 1.0508 - val_reg_output_loss: 294230.3312 - val_recon_mean_squared_error: 1.0508 - val_reg_output_mean_squared_error: 294230.3312\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 77734.9508 - recon_loss: 1.0134 - reg_output_loss: 77633.6131 - recon_mean_squared_error: 1.0134 - reg_output_mean_squared_error: 77633.6131 - val_loss: 293527.8663 - val_recon_loss: 1.0239 - val_reg_output_loss: 293425.4788 - val_recon_mean_squared_error: 1.0239 - val_reg_output_mean_squared_error: 293425.4788\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 81652.3266 - recon_loss: 1.0132 - reg_output_loss: 81551.0073 - recon_mean_squared_error: 1.0132 - reg_output_mean_squared_error: 81551.0073 - val_loss: 283568.0988 - val_recon_loss: 1.0218 - val_reg_output_loss: 283465.9225 - val_recon_mean_squared_error: 1.0218 - val_reg_output_mean_squared_error: 283465.9225\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 290us/step - loss: 78654.4478 - recon_loss: 1.0086 - reg_output_loss: 78553.5847 - recon_mean_squared_error: 1.0086 - reg_output_mean_squared_error: 78553.5847 - val_loss: 289048.3412 - val_recon_loss: 1.0162 - val_reg_output_loss: 288946.7162 - val_recon_mean_squared_error: 1.0162 - val_reg_output_mean_squared_error: 288946.7162\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 82956.9111 - recon_loss: 1.0154 - reg_output_loss: 82855.3720 - recon_mean_squared_error: 1.0154 - reg_output_mean_squared_error: 82855.3720 - val_loss: 284968.6088 - val_recon_loss: 1.1013 - val_reg_output_loss: 284858.4825 - val_recon_mean_squared_error: 1.1013 - val_reg_output_mean_squared_error: 284858.4825\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 83176.9817 - recon_loss: 1.0169 - reg_output_loss: 83075.2867 - recon_mean_squared_error: 1.0169 - reg_output_mean_squared_error: 83075.2867 - val_loss: 279240.6912 - val_recon_loss: 1.0641 - val_reg_output_loss: 279134.2812 - val_recon_mean_squared_error: 1.0641 - val_reg_output_mean_squared_error: 279134.2812\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 260us/step - loss: 78383.5505 - recon_loss: 1.0188 - reg_output_loss: 78281.6743 - recon_mean_squared_error: 1.0188 - reg_output_mean_squared_error: 78281.6743 - val_loss: 277658.1312 - val_recon_loss: 1.0223 - val_reg_output_loss: 277555.9025 - val_recon_mean_squared_error: 1.0223 - val_reg_output_mean_squared_error: 277555.9025\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 79877.3746 - recon_loss: 1.0096 - reg_output_loss: 79776.4142 - recon_mean_squared_error: 1.0096 - reg_output_mean_squared_error: 79776.4142 - val_loss: 278479.2500 - val_recon_loss: 1.0289 - val_reg_output_loss: 278376.3600 - val_recon_mean_squared_error: 1.0289 - val_reg_output_mean_squared_error: 278376.3600\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 81428.6270 - recon_loss: 1.0286 - reg_output_loss: 81325.7634 - recon_mean_squared_error: 1.0286 - reg_output_mean_squared_error: 81325.7634 - val_loss: 274321.7950 - val_recon_loss: 1.0029 - val_reg_output_loss: 274221.5050 - val_recon_mean_squared_error: 1.0029 - val_reg_output_mean_squared_error: 274221.5050\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 293us/step - loss: 83630.5392 - recon_loss: 1.0100 - reg_output_loss: 83529.5431 - recon_mean_squared_error: 1.0100 - reg_output_mean_squared_error: 83529.5431 - val_loss: 266434.8725 - val_recon_loss: 1.0266 - val_reg_output_loss: 266332.2150 - val_recon_mean_squared_error: 1.0266 - val_reg_output_mean_squared_error: 266332.2150\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 75625.3780 - recon_loss: 1.0128 - reg_output_loss: 75524.1004 - recon_mean_squared_error: 1.0128 - reg_output_mean_squared_error: 75524.1004 - val_loss: 270337.4888 - val_recon_loss: 1.0293 - val_reg_output_loss: 270234.5625 - val_recon_mean_squared_error: 1.0293 - val_reg_output_mean_squared_error: 270234.5625\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 78808.9401 - recon_loss: 1.0132 - reg_output_loss: 78707.6154 - recon_mean_squared_error: 1.0132 - reg_output_mean_squared_error: 78707.6154 - val_loss: 274037.1188 - val_recon_loss: 1.0124 - val_reg_output_loss: 273935.8800 - val_recon_mean_squared_error: 1.0124 - val_reg_output_mean_squared_error: 273935.8800\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 82822.5732 - recon_loss: 1.0112 - reg_output_loss: 82721.4543 - recon_mean_squared_error: 1.0112 - reg_output_mean_squared_error: 82721.4543 - val_loss: 268083.1275 - val_recon_loss: 1.0461 - val_reg_output_loss: 267978.5225 - val_recon_mean_squared_error: 1.0461 - val_reg_output_mean_squared_error: 267978.5225\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 267us/step - loss: 75710.4871 - recon_loss: 1.0207 - reg_output_loss: 75608.4151 - recon_mean_squared_error: 1.0207 - reg_output_mean_squared_error: 75608.4151 - val_loss: 266066.9500 - val_recon_loss: 1.0149 - val_reg_output_loss: 265965.4587 - val_recon_mean_squared_error: 1.0149 - val_reg_output_mean_squared_error: 265965.4587\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 280us/step - loss: 80545.3842 - recon_loss: 1.0096 - reg_output_loss: 80444.4278 - recon_mean_squared_error: 1.0096 - reg_output_mean_squared_error: 80444.4278 - val_loss: 257725.3612 - val_recon_loss: 1.0137 - val_reg_output_loss: 257623.9925 - val_recon_mean_squared_error: 1.0137 - val_reg_output_mean_squared_error: 257623.9925\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 81049.2416 - recon_loss: 1.0153 - reg_output_loss: 80947.7133 - recon_mean_squared_error: 1.0153 - reg_output_mean_squared_error: 80947.7133 - val_loss: 255139.8287 - val_recon_loss: 1.0206 - val_reg_output_loss: 255037.7650 - val_recon_mean_squared_error: 1.0206 - val_reg_output_mean_squared_error: 255037.7650\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 270us/step - loss: 82709.4411 - recon_loss: 1.0061 - reg_output_loss: 82608.8291 - recon_mean_squared_error: 1.0061 - reg_output_mean_squared_error: 82608.8291 - val_loss: 249556.8950 - val_recon_loss: 1.0166 - val_reg_output_loss: 249455.2400 - val_recon_mean_squared_error: 1.0166 - val_reg_output_mean_squared_error: 249455.2400\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - 0s 287us/step - loss: 81719.0631 - recon_loss: 1.0074 - reg_output_loss: 81618.3232 - recon_mean_squared_error: 1.0074 - reg_output_mean_squared_error: 81618.3232 - val_loss: 252411.0162 - val_recon_loss: 1.0068 - val_reg_output_loss: 252310.3412 - val_recon_mean_squared_error: 1.0068 - val_reg_output_mean_squared_error: 252310.3412\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 83990.3477 - recon_loss: 1.0140 - reg_output_loss: 83888.9483 - recon_mean_squared_error: 1.0140 - reg_output_mean_squared_error: 83888.9483 - val_loss: 245845.6338 - val_recon_loss: 1.0082 - val_reg_output_loss: 245744.8213 - val_recon_mean_squared_error: 1.0082 - val_reg_output_mean_squared_error: 245744.8213\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 260us/step - loss: 75512.8516 - recon_loss: 1.0238 - reg_output_loss: 75410.4680 - recon_mean_squared_error: 1.0238 - reg_output_mean_squared_error: 75410.4680 - val_loss: 247851.6663 - val_recon_loss: 1.1193 - val_reg_output_loss: 247739.7412 - val_recon_mean_squared_error: 1.1193 - val_reg_output_mean_squared_error: 247739.7412\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 79690.4003 - recon_loss: 1.0109 - reg_output_loss: 79589.3059 - recon_mean_squared_error: 1.0109 - reg_output_mean_squared_error: 79589.3059 - val_loss: 244312.3275 - val_recon_loss: 1.0097 - val_reg_output_loss: 244211.3550 - val_recon_mean_squared_error: 1.0097 - val_reg_output_mean_squared_error: 244211.3550\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 82686.4941 - recon_loss: 1.0074 - reg_output_loss: 82585.7557 - recon_mean_squared_error: 1.0074 - reg_output_mean_squared_error: 82585.7557 - val_loss: 237494.4475 - val_recon_loss: 1.0344 - val_reg_output_loss: 237391.0125 - val_recon_mean_squared_error: 1.0344 - val_reg_output_mean_squared_error: 237391.0125\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 81266.7505 - recon_loss: 1.0172 - reg_output_loss: 81165.0335 - recon_mean_squared_error: 1.0172 - reg_output_mean_squared_error: 81165.0335 - val_loss: 234590.5225 - val_recon_loss: 1.0489 - val_reg_output_loss: 234485.6275 - val_recon_mean_squared_error: 1.0489 - val_reg_output_mean_squared_error: 234485.6275\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 84158.2250 - recon_loss: 1.0086 - reg_output_loss: 84057.3681 - recon_mean_squared_error: 1.0086 - reg_output_mean_squared_error: 84057.3681 - val_loss: 225906.2812 - val_recon_loss: 1.0101 - val_reg_output_loss: 225805.2687 - val_recon_mean_squared_error: 1.0101 - val_reg_output_mean_squared_error: 225805.2687\n",
      "Epoch 387/500\n",
      "300/300 [==============================] - 0s 260us/step - loss: 80793.6580 - recon_loss: 1.0135 - reg_output_loss: 80692.3052 - recon_mean_squared_error: 1.0135 - reg_output_mean_squared_error: 80692.3052 - val_loss: 228818.1600 - val_recon_loss: 1.0758 - val_reg_output_loss: 228710.5787 - val_recon_mean_squared_error: 1.0758 - val_reg_output_mean_squared_error: 228710.5787\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 280us/step - loss: 84730.0938 - recon_loss: 1.0109 - reg_output_loss: 84629.0064 - recon_mean_squared_error: 1.0109 - reg_output_mean_squared_error: 84629.0064 - val_loss: 219918.4300 - val_recon_loss: 1.0046 - val_reg_output_loss: 219817.9619 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 219817.9619\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 80054.8628 - recon_loss: 1.0090 - reg_output_loss: 79953.9660 - recon_mean_squared_error: 1.0090 - reg_output_mean_squared_error: 79953.9660 - val_loss: 221865.8200 - val_recon_loss: 1.2939 - val_reg_output_loss: 221736.4287 - val_recon_mean_squared_error: 1.2939 - val_reg_output_mean_squared_error: 221736.4287\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 80146.2499 - recon_loss: 1.0104 - reg_output_loss: 80045.2125 - recon_mean_squared_error: 1.0104 - reg_output_mean_squared_error: 80045.2125 - val_loss: 220905.9738 - val_recon_loss: 1.0373 - val_reg_output_loss: 220802.2444 - val_recon_mean_squared_error: 1.0373 - val_reg_output_mean_squared_error: 220802.2444\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 78864.7566 - recon_loss: 1.0069 - reg_output_loss: 78764.0693 - recon_mean_squared_error: 1.0069 - reg_output_mean_squared_error: 78764.0693 - val_loss: 223395.9731 - val_recon_loss: 1.0168 - val_reg_output_loss: 223294.3012 - val_recon_mean_squared_error: 1.0168 - val_reg_output_mean_squared_error: 223294.3012\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 260us/step - loss: 85181.4836 - recon_loss: 1.0122 - reg_output_loss: 85080.2679 - recon_mean_squared_error: 1.0122 - reg_output_mean_squared_error: 85080.2679 - val_loss: 217489.2963 - val_recon_loss: 1.0081 - val_reg_output_loss: 217388.4819 - val_recon_mean_squared_error: 1.0081 - val_reg_output_mean_squared_error: 217388.4819\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 83780.9600 - recon_loss: 1.0067 - reg_output_loss: 83680.2939 - recon_mean_squared_error: 1.0067 - reg_output_mean_squared_error: 83680.2939 - val_loss: 210666.6644 - val_recon_loss: 1.0136 - val_reg_output_loss: 210565.3062 - val_recon_mean_squared_error: 1.0136 - val_reg_output_mean_squared_error: 210565.3062\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 78656.0758 - recon_loss: 1.0061 - reg_output_loss: 78555.4698 - recon_mean_squared_error: 1.0061 - reg_output_mean_squared_error: 78555.4698 - val_loss: 211546.9700 - val_recon_loss: 1.0200 - val_reg_output_loss: 211444.9706 - val_recon_mean_squared_error: 1.0200 - val_reg_output_mean_squared_error: 211444.9706\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 79421.6903 - recon_loss: 1.0064 - reg_output_loss: 79321.0493 - recon_mean_squared_error: 1.0064 - reg_output_mean_squared_error: 79321.0493 - val_loss: 212541.8375 - val_recon_loss: 1.0586 - val_reg_output_loss: 212435.9813 - val_recon_mean_squared_error: 1.0586 - val_reg_output_mean_squared_error: 212435.9813\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 86960.3549 - recon_loss: 1.0079 - reg_output_loss: 86859.5618 - recon_mean_squared_error: 1.0079 - reg_output_mean_squared_error: 86859.5618 - val_loss: 206309.5731 - val_recon_loss: 1.0047 - val_reg_output_loss: 206209.1075 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 206209.1075\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 83521.3276 - recon_loss: 1.0101 - reg_output_loss: 83420.3199 - recon_mean_squared_error: 1.0101 - reg_output_mean_squared_error: 83420.3199 - val_loss: 203728.6694 - val_recon_loss: 1.1976 - val_reg_output_loss: 203608.9081 - val_recon_mean_squared_error: 1.1976 - val_reg_output_mean_squared_error: 203608.9081\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 79692.4942 - recon_loss: 1.0440 - reg_output_loss: 79588.0987 - recon_mean_squared_error: 1.0440 - reg_output_mean_squared_error: 79588.0987 - val_loss: 204305.4856 - val_recon_loss: 1.0090 - val_reg_output_loss: 204204.5850 - val_recon_mean_squared_error: 1.0090 - val_reg_output_mean_squared_error: 204204.5850\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 82926.9618 - recon_loss: 1.0034 - reg_output_loss: 82826.6180 - recon_mean_squared_error: 1.0034 - reg_output_mean_squared_error: 82826.6180 - val_loss: 200159.7131 - val_recon_loss: 1.0041 - val_reg_output_loss: 200059.3087 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 200059.3087\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 79938.1365 - recon_loss: 1.0092 - reg_output_loss: 79837.2169 - recon_mean_squared_error: 1.0092 - reg_output_mean_squared_error: 79837.2169 - val_loss: 196144.2931 - val_recon_loss: 1.0034 - val_reg_output_loss: 196043.9550 - val_recon_mean_squared_error: 1.0034 - val_reg_output_mean_squared_error: 196043.9550\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 83080.9831 - recon_loss: 1.0022 - reg_output_loss: 82980.7623 - recon_mean_squared_error: 1.0022 - reg_output_mean_squared_error: 82980.7623 - val_loss: 194967.6700 - val_recon_loss: 1.0018 - val_reg_output_loss: 194867.4869 - val_recon_mean_squared_error: 1.0018 - val_reg_output_mean_squared_error: 194867.4869\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 84684.1024 - recon_loss: 1.0081 - reg_output_loss: 84583.2929 - recon_mean_squared_error: 1.0081 - reg_output_mean_squared_error: 84583.2929 - val_loss: 187109.5350 - val_recon_loss: 1.0090 - val_reg_output_loss: 187008.6406 - val_recon_mean_squared_error: 1.0090 - val_reg_output_mean_squared_error: 187008.6406\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 82736.7600 - recon_loss: 1.0073 - reg_output_loss: 82636.0311 - recon_mean_squared_error: 1.0073 - reg_output_mean_squared_error: 82636.0311 - val_loss: 182899.4844 - val_recon_loss: 1.0047 - val_reg_output_loss: 182799.0075 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 182799.0075\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 82192.6958 - recon_loss: 1.0075 - reg_output_loss: 82091.9481 - recon_mean_squared_error: 1.0075 - reg_output_mean_squared_error: 82091.9481 - val_loss: 184387.1137 - val_recon_loss: 1.0028 - val_reg_output_loss: 184286.8363 - val_recon_mean_squared_error: 1.0028 - val_reg_output_mean_squared_error: 184286.8363\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 86633.0467 - recon_loss: 1.0062 - reg_output_loss: 86532.4267 - recon_mean_squared_error: 1.0062 - reg_output_mean_squared_error: 86532.4267 - val_loss: 179462.5400 - val_recon_loss: 1.0086 - val_reg_output_loss: 179361.6762 - val_recon_mean_squared_error: 1.0086 - val_reg_output_mean_squared_error: 179361.6762\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 86939.0446 - recon_loss: 1.0128 - reg_output_loss: 86837.7634 - recon_mean_squared_error: 1.0128 - reg_output_mean_squared_error: 86837.7634 - val_loss: 173742.9337 - val_recon_loss: 1.0036 - val_reg_output_loss: 173642.5725 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 173642.5725\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 82891.0629 - recon_loss: 1.0026 - reg_output_loss: 82790.8058 - recon_mean_squared_error: 1.0026 - reg_output_mean_squared_error: 82790.8058 - val_loss: 176599.7738 - val_recon_loss: 1.0054 - val_reg_output_loss: 176499.2350 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 176499.2350\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 277us/step - loss: 84156.3046 - recon_loss: 1.0057 - reg_output_loss: 84055.7365 - recon_mean_squared_error: 1.0057 - reg_output_mean_squared_error: 84055.7365 - val_loss: 172635.4306 - val_recon_loss: 1.0109 - val_reg_output_loss: 172534.3444 - val_recon_mean_squared_error: 1.0109 - val_reg_output_mean_squared_error: 172534.3444\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 81686.0739 - recon_loss: 1.0101 - reg_output_loss: 81585.0622 - recon_mean_squared_error: 1.0101 - reg_output_mean_squared_error: 81585.0622 - val_loss: 174288.6263 - val_recon_loss: 1.0387 - val_reg_output_loss: 174184.7550 - val_recon_mean_squared_error: 1.0387 - val_reg_output_mean_squared_error: 174184.7550\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 82099.7074 - recon_loss: 1.0093 - reg_output_loss: 81998.7745 - recon_mean_squared_error: 1.0093 - reg_output_mean_squared_error: 81998.7745 - val_loss: 171455.5438 - val_recon_loss: 1.0042 - val_reg_output_loss: 171355.1219 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 171355.1219\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 86050.6236 - recon_loss: 1.0058 - reg_output_loss: 85950.0403 - recon_mean_squared_error: 1.0058 - reg_output_mean_squared_error: 85950.0403 - val_loss: 165904.0750 - val_recon_loss: 1.0145 - val_reg_output_loss: 165802.6200 - val_recon_mean_squared_error: 1.0145 - val_reg_output_mean_squared_error: 165802.6200\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 87580.8440 - recon_loss: 1.0137 - reg_output_loss: 87479.4695 - recon_mean_squared_error: 1.0137 - reg_output_mean_squared_error: 87479.4695 - val_loss: 163154.7369 - val_recon_loss: 1.0065 - val_reg_output_loss: 163054.0875 - val_recon_mean_squared_error: 1.0065 - val_reg_output_mean_squared_error: 163054.0875\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 83370.3844 - recon_loss: 1.0037 - reg_output_loss: 83270.0119 - recon_mean_squared_error: 1.0037 - reg_output_mean_squared_error: 83270.0119 - val_loss: 163310.2913 - val_recon_loss: 1.0044 - val_reg_output_loss: 163209.8500 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 163209.8500\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 84281.3065 - recon_loss: 1.0053 - reg_output_loss: 84180.7779 - recon_mean_squared_error: 1.0053 - reg_output_mean_squared_error: 84180.7779 - val_loss: 161794.1112 - val_recon_loss: 1.0025 - val_reg_output_loss: 161693.8575 - val_recon_mean_squared_error: 1.0025 - val_reg_output_mean_squared_error: 161693.8575\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 91412.9706 - recon_loss: 1.0113 - reg_output_loss: 91311.8409 - recon_mean_squared_error: 1.0113 - reg_output_mean_squared_error: 91311.8409 - val_loss: 152306.6331 - val_recon_loss: 1.0024 - val_reg_output_loss: 152206.3975 - val_recon_mean_squared_error: 1.0024 - val_reg_output_mean_squared_error: 152206.3975\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 86355.3479 - recon_loss: 1.0039 - reg_output_loss: 86254.9628 - recon_mean_squared_error: 1.0039 - reg_output_mean_squared_error: 86254.9628 - val_loss: 149698.4028 - val_recon_loss: 1.0018 - val_reg_output_loss: 149598.2188 - val_recon_mean_squared_error: 1.0018 - val_reg_output_mean_squared_error: 149598.2188\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 86497.3015 - recon_loss: 1.0044 - reg_output_loss: 86396.8609 - recon_mean_squared_error: 1.0044 - reg_output_mean_squared_error: 86396.8609 - val_loss: 146158.8053 - val_recon_loss: 1.0175 - val_reg_output_loss: 146057.0512 - val_recon_mean_squared_error: 1.0175 - val_reg_output_mean_squared_error: 146057.0512\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 267us/step - loss: 84384.5491 - recon_loss: 1.0032 - reg_output_loss: 84284.2338 - recon_mean_squared_error: 1.0032 - reg_output_mean_squared_error: 84284.2338 - val_loss: 145185.2825 - val_recon_loss: 1.0132 - val_reg_output_loss: 145083.9650 - val_recon_mean_squared_error: 1.0132 - val_reg_output_mean_squared_error: 145083.9650\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 83938.4951 - recon_loss: 1.0059 - reg_output_loss: 83837.9042 - recon_mean_squared_error: 1.0059 - reg_output_mean_squared_error: 83837.9042 - val_loss: 143187.8184 - val_recon_loss: 1.0027 - val_reg_output_loss: 143087.5431 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 143087.5431\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 81772.3651 - recon_loss: 1.0036 - reg_output_loss: 81672.0033 - recon_mean_squared_error: 1.0036 - reg_output_mean_squared_error: 81672.0033 - val_loss: 145187.8950 - val_recon_loss: 1.0028 - val_reg_output_loss: 145087.6091 - val_recon_mean_squared_error: 1.0028 - val_reg_output_mean_squared_error: 145087.6091\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 86254.2989 - recon_loss: 1.0079 - reg_output_loss: 86153.5059 - recon_mean_squared_error: 1.0079 - reg_output_mean_squared_error: 86153.5059 - val_loss: 143068.0688 - val_recon_loss: 1.0035 - val_reg_output_loss: 142967.7100 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 142967.7100\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 80321.0387 - recon_loss: 1.0214 - reg_output_loss: 80218.8954 - recon_mean_squared_error: 1.0214 - reg_output_mean_squared_error: 80218.8954 - val_loss: 144735.2619 - val_recon_loss: 1.0024 - val_reg_output_loss: 144635.0225 - val_recon_mean_squared_error: 1.0024 - val_reg_output_mean_squared_error: 144635.0225\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 84135.9571 - recon_loss: 1.0017 - reg_output_loss: 84035.7871 - recon_mean_squared_error: 1.0017 - reg_output_mean_squared_error: 84035.7871 - val_loss: 144541.5378 - val_recon_loss: 1.0024 - val_reg_output_loss: 144441.2969 - val_recon_mean_squared_error: 1.0024 - val_reg_output_mean_squared_error: 144441.2969\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 88366.7712 - recon_loss: 1.0019 - reg_output_loss: 88266.5831 - recon_mean_squared_error: 1.0019 - reg_output_mean_squared_error: 88266.5831 - val_loss: 142077.6703 - val_recon_loss: 1.0109 - val_reg_output_loss: 141976.5778 - val_recon_mean_squared_error: 1.0109 - val_reg_output_mean_squared_error: 141976.5778\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 82772.0601 - recon_loss: 1.0029 - reg_output_loss: 82671.7658 - recon_mean_squared_error: 1.0029 - reg_output_mean_squared_error: 82671.7658 - val_loss: 139623.5666 - val_recon_loss: 1.0064 - val_reg_output_loss: 139522.9272 - val_recon_mean_squared_error: 1.0064 - val_reg_output_mean_squared_error: 139522.9272\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 317us/step - loss: 86945.9315 - recon_loss: 1.0049 - reg_output_loss: 86845.4385 - recon_mean_squared_error: 1.0049 - reg_output_mean_squared_error: 86845.4385 - val_loss: 137741.4634 - val_recon_loss: 1.0021 - val_reg_output_loss: 137641.2531 - val_recon_mean_squared_error: 1.0021 - val_reg_output_mean_squared_error: 137641.2531\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 79524.5109 - recon_loss: 1.0044 - reg_output_loss: 79424.0667 - recon_mean_squared_error: 1.0044 - reg_output_mean_squared_error: 79424.0667 - val_loss: 139754.2322 - val_recon_loss: 1.0023 - val_reg_output_loss: 139653.9956 - val_recon_mean_squared_error: 1.0023 - val_reg_output_mean_squared_error: 139653.9956\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 84114.7512 - recon_loss: 1.0065 - reg_output_loss: 84014.0979 - recon_mean_squared_error: 1.0065 - reg_output_mean_squared_error: 84014.0979 - val_loss: 141133.7475 - val_recon_loss: 1.0058 - val_reg_output_loss: 141033.1669 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 141033.1669\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 89832.3550 - recon_loss: 1.0048 - reg_output_loss: 89731.8723 - recon_mean_squared_error: 1.0048 - reg_output_mean_squared_error: 89731.8723 - val_loss: 138032.2888 - val_recon_loss: 1.0016 - val_reg_output_loss: 137932.1237 - val_recon_mean_squared_error: 1.0016 - val_reg_output_mean_squared_error: 137932.1237\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 84845.1310 - recon_loss: 1.0060 - reg_output_loss: 84744.5341 - recon_mean_squared_error: 1.0060 - reg_output_mean_squared_error: 84744.5341 - val_loss: 136070.6775 - val_recon_loss: 1.0097 - val_reg_output_loss: 135969.7087 - val_recon_mean_squared_error: 1.0097 - val_reg_output_mean_squared_error: 135969.7087\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 93454.3092 - recon_loss: 1.0053 - reg_output_loss: 93353.7768 - recon_mean_squared_error: 1.0053 - reg_output_mean_squared_error: 93353.7768 - val_loss: 131238.9062 - val_recon_loss: 1.0164 - val_reg_output_loss: 131137.2641 - val_recon_mean_squared_error: 1.0164 - val_reg_output_mean_squared_error: 131137.2641\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 83414.3267 - recon_loss: 1.0034 - reg_output_loss: 83313.9885 - recon_mean_squared_error: 1.0034 - reg_output_mean_squared_error: 83313.9885 - val_loss: 131528.8953 - val_recon_loss: 1.0036 - val_reg_output_loss: 131428.5381 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 131428.5381\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 82469.9189 - recon_loss: 1.0025 - reg_output_loss: 82369.6649 - recon_mean_squared_error: 1.0025 - reg_output_mean_squared_error: 82369.6649 - val_loss: 131514.0281 - val_recon_loss: 1.0021 - val_reg_output_loss: 131413.8188 - val_recon_mean_squared_error: 1.0021 - val_reg_output_mean_squared_error: 131413.8188\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 82500.7803 - recon_loss: 1.0224 - reg_output_loss: 82398.5425 - recon_mean_squared_error: 1.0224 - reg_output_mean_squared_error: 82398.5425 - val_loss: 132356.6266 - val_recon_loss: 1.0027 - val_reg_output_loss: 132256.3606 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 132256.3606\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 260us/step - loss: 83673.9767 - recon_loss: 1.0024 - reg_output_loss: 83573.7321 - recon_mean_squared_error: 1.0024 - reg_output_mean_squared_error: 83573.7321 - val_loss: 132726.6184 - val_recon_loss: 1.0023 - val_reg_output_loss: 132626.3888 - val_recon_mean_squared_error: 1.0023 - val_reg_output_mean_squared_error: 132626.3888\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 86596.5176 - recon_loss: 1.0006 - reg_output_loss: 86496.4589 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 86496.4589 - val_loss: 130663.7797 - val_recon_loss: 1.0032 - val_reg_output_loss: 130563.4566 - val_recon_mean_squared_error: 1.0032 - val_reg_output_mean_squared_error: 130563.4566\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 84642.4191 - recon_loss: 1.0051 - reg_output_loss: 84541.9059 - recon_mean_squared_error: 1.0051 - reg_output_mean_squared_error: 84541.9059 - val_loss: 129516.8556 - val_recon_loss: 1.0034 - val_reg_output_loss: 129416.5213 - val_recon_mean_squared_error: 1.0034 - val_reg_output_mean_squared_error: 129416.5213\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 81127.3831 - recon_loss: 1.0051 - reg_output_loss: 81026.8751 - recon_mean_squared_error: 1.0051 - reg_output_mean_squared_error: 81026.8751 - val_loss: 128815.2278 - val_recon_loss: 1.0083 - val_reg_output_loss: 128714.4031 - val_recon_mean_squared_error: 1.0083 - val_reg_output_mean_squared_error: 128714.4031\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 88652.4889 - recon_loss: 1.0034 - reg_output_loss: 88552.1486 - recon_mean_squared_error: 1.0034 - reg_output_mean_squared_error: 88552.1486 - val_loss: 126039.9278 - val_recon_loss: 1.0042 - val_reg_output_loss: 125939.5075 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 125939.5075\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 86498.5421 - recon_loss: 1.0050 - reg_output_loss: 86398.0471 - recon_mean_squared_error: 1.0050 - reg_output_mean_squared_error: 86398.0471 - val_loss: 124136.3066 - val_recon_loss: 1.0040 - val_reg_output_loss: 124035.9131 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 124035.9131\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 89126.9279 - recon_loss: 1.0011 - reg_output_loss: 89026.8167 - recon_mean_squared_error: 1.0011 - reg_output_mean_squared_error: 89026.8167 - val_loss: 122131.5709 - val_recon_loss: 1.0068 - val_reg_output_loss: 122030.8878 - val_recon_mean_squared_error: 1.0068 - val_reg_output_mean_squared_error: 122030.8878\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 84655.8895 - recon_loss: 1.0045 - reg_output_loss: 84555.4409 - recon_mean_squared_error: 1.0045 - reg_output_mean_squared_error: 84555.4409 - val_loss: 121906.2859 - val_recon_loss: 1.0019 - val_reg_output_loss: 121806.1013 - val_recon_mean_squared_error: 1.0019 - val_reg_output_mean_squared_error: 121806.1013\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 78538.4065 - recon_loss: 1.0055 - reg_output_loss: 78437.8553 - recon_mean_squared_error: 1.0055 - reg_output_mean_squared_error: 78437.8553 - val_loss: 122323.9072 - val_recon_loss: 1.0022 - val_reg_output_loss: 122223.6825 - val_recon_mean_squared_error: 1.0022 - val_reg_output_mean_squared_error: 122223.6825\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 85234.2639 - recon_loss: 1.0038 - reg_output_loss: 85133.8858 - recon_mean_squared_error: 1.0038 - reg_output_mean_squared_error: 85133.8858 - val_loss: 120104.3256 - val_recon_loss: 1.0172 - val_reg_output_loss: 120002.6025 - val_recon_mean_squared_error: 1.0172 - val_reg_output_mean_squared_error: 120002.6025\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 80897.8241 - recon_loss: 1.0133 - reg_output_loss: 80796.4908 - recon_mean_squared_error: 1.0133 - reg_output_mean_squared_error: 80796.4908 - val_loss: 120707.5769 - val_recon_loss: 1.0031 - val_reg_output_loss: 120607.2653 - val_recon_mean_squared_error: 1.0031 - val_reg_output_mean_squared_error: 120607.2653\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 260us/step - loss: 81873.4604 - recon_loss: 1.0024 - reg_output_loss: 81773.2206 - recon_mean_squared_error: 1.0024 - reg_output_mean_squared_error: 81773.2206 - val_loss: 121041.3441 - val_recon_loss: 1.0032 - val_reg_output_loss: 120941.0203 - val_recon_mean_squared_error: 1.0032 - val_reg_output_mean_squared_error: 120941.0203\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 87664.4170 - recon_loss: 1.0009 - reg_output_loss: 87564.3264 - recon_mean_squared_error: 1.0009 - reg_output_mean_squared_error: 87564.3264 - val_loss: 120137.1753 - val_recon_loss: 1.0035 - val_reg_output_loss: 120036.8219 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 120036.8219\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 84471.3709 - recon_loss: 1.0030 - reg_output_loss: 84371.0678 - recon_mean_squared_error: 1.0030 - reg_output_mean_squared_error: 84371.0678 - val_loss: 120158.4822 - val_recon_loss: 1.0029 - val_reg_output_loss: 120058.1925 - val_recon_mean_squared_error: 1.0029 - val_reg_output_mean_squared_error: 120058.1925\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 267us/step - loss: 83659.2672 - recon_loss: 1.0024 - reg_output_loss: 83559.0237 - recon_mean_squared_error: 1.0024 - reg_output_mean_squared_error: 83559.0237 - val_loss: 119082.7956 - val_recon_loss: 1.0028 - val_reg_output_loss: 118982.5209 - val_recon_mean_squared_error: 1.0028 - val_reg_output_mean_squared_error: 118982.5209\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 88077.3846 - recon_loss: 1.0031 - reg_output_loss: 87977.0741 - recon_mean_squared_error: 1.0031 - reg_output_mean_squared_error: 87977.0741 - val_loss: 117356.8675 - val_recon_loss: 1.0025 - val_reg_output_loss: 117256.6169 - val_recon_mean_squared_error: 1.0025 - val_reg_output_mean_squared_error: 117256.6169\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 84903.7469 - recon_loss: 1.0049 - reg_output_loss: 84803.2554 - recon_mean_squared_error: 1.0049 - reg_output_mean_squared_error: 84803.2554 - val_loss: 116159.8684 - val_recon_loss: 1.0046 - val_reg_output_loss: 116059.4056 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 116059.4056\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 83264.9110 - recon_loss: 1.0037 - reg_output_loss: 83164.5457 - recon_mean_squared_error: 1.0037 - reg_output_mean_squared_error: 83164.5457 - val_loss: 115449.5928 - val_recon_loss: 1.0024 - val_reg_output_loss: 115349.3516 - val_recon_mean_squared_error: 1.0024 - val_reg_output_mean_squared_error: 115349.3516\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 85555.1266 - recon_loss: 1.0015 - reg_output_loss: 85454.9779 - recon_mean_squared_error: 1.0015 - reg_output_mean_squared_error: 85454.9779 - val_loss: 115583.9791 - val_recon_loss: 1.0027 - val_reg_output_loss: 115483.7063 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 115483.7063\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 86159.5770 - recon_loss: 1.0051 - reg_output_loss: 86059.0664 - recon_mean_squared_error: 1.0051 - reg_output_mean_squared_error: 86059.0664 - val_loss: 114940.0956 - val_recon_loss: 1.0055 - val_reg_output_loss: 114839.5497 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 114839.5497\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 83936.5681 - recon_loss: 1.0039 - reg_output_loss: 83836.1740 - recon_mean_squared_error: 1.0039 - reg_output_mean_squared_error: 83836.1740 - val_loss: 114691.8781 - val_recon_loss: 1.0022 - val_reg_output_loss: 114591.6550 - val_recon_mean_squared_error: 1.0022 - val_reg_output_mean_squared_error: 114591.6550\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 297us/step - loss: 85891.0542 - recon_loss: 1.0023 - reg_output_loss: 85790.8255 - recon_mean_squared_error: 1.0023 - reg_output_mean_squared_error: 85790.8255 - val_loss: 113055.8591 - val_recon_loss: 1.0038 - val_reg_output_loss: 112955.4809 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 112955.4809\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 81608.5401 - recon_loss: 1.0028 - reg_output_loss: 81508.2653 - recon_mean_squared_error: 1.0028 - reg_output_mean_squared_error: 81508.2653 - val_loss: 114297.5638 - val_recon_loss: 1.0021 - val_reg_output_loss: 114197.3525 - val_recon_mean_squared_error: 1.0021 - val_reg_output_mean_squared_error: 114197.3525\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 227us/step - loss: 88296.6192 - recon_loss: 1.0016 - reg_output_loss: 88196.4621 - recon_mean_squared_error: 1.0016 - reg_output_mean_squared_error: 88196.4621 - val_loss: 112617.2463 - val_recon_loss: 1.0009 - val_reg_output_loss: 112517.1609 - val_recon_mean_squared_error: 1.0009 - val_reg_output_mean_squared_error: 112517.1609\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 81734.1505 - recon_loss: 1.0017 - reg_output_loss: 81633.9808 - recon_mean_squared_error: 1.0017 - reg_output_mean_squared_error: 81633.9808 - val_loss: 113009.0103 - val_recon_loss: 1.0043 - val_reg_output_loss: 112908.5825 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 112908.5825\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 87043.7234 - recon_loss: 1.0065 - reg_output_loss: 86943.0684 - recon_mean_squared_error: 1.0065 - reg_output_mean_squared_error: 86943.0684 - val_loss: 111999.1400 - val_recon_loss: 1.0022 - val_reg_output_loss: 111898.9169 - val_recon_mean_squared_error: 1.0022 - val_reg_output_mean_squared_error: 111898.9169\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 83862.5599 - recon_loss: 1.0006 - reg_output_loss: 83762.5017 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 83762.5017 - val_loss: 111343.2069 - val_recon_loss: 1.0052 - val_reg_output_loss: 111242.6878 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 111242.6878\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 84656.4644 - recon_loss: 1.0021 - reg_output_loss: 84556.2558 - recon_mean_squared_error: 1.0021 - reg_output_mean_squared_error: 84556.2558 - val_loss: 112213.7531 - val_recon_loss: 1.0022 - val_reg_output_loss: 112113.5363 - val_recon_mean_squared_error: 1.0022 - val_reg_output_mean_squared_error: 112113.5363\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 85074.8108 - recon_loss: 1.0035 - reg_output_loss: 84974.4632 - recon_mean_squared_error: 1.0035 - reg_output_mean_squared_error: 84974.4632 - val_loss: 112277.2569 - val_recon_loss: 1.0029 - val_reg_output_loss: 112176.9612 - val_recon_mean_squared_error: 1.0029 - val_reg_output_mean_squared_error: 112176.9612\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - 0s 223us/step - loss: 82003.3353 - recon_loss: 1.0014 - reg_output_loss: 81903.1979 - recon_mean_squared_error: 1.0014 - reg_output_mean_squared_error: 81903.1979 - val_loss: 113610.9922 - val_recon_loss: 1.0083 - val_reg_output_loss: 113510.1662 - val_recon_mean_squared_error: 1.0083 - val_reg_output_mean_squared_error: 113510.1662\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 283us/step - loss: 84731.7018 - recon_loss: 1.0029 - reg_output_loss: 84631.4130 - recon_mean_squared_error: 1.0029 - reg_output_mean_squared_error: 84631.4130 - val_loss: 113181.9659 - val_recon_loss: 1.0040 - val_reg_output_loss: 113081.5684 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 113081.5684\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 85352.3811 - recon_loss: 1.0020 - reg_output_loss: 85252.1859 - recon_mean_squared_error: 1.0020 - reg_output_mean_squared_error: 85252.1859 - val_loss: 111893.3375 - val_recon_loss: 1.0025 - val_reg_output_loss: 111793.0903 - val_recon_mean_squared_error: 1.0025 - val_reg_output_mean_squared_error: 111793.0903\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 82426.2902 - recon_loss: 1.0052 - reg_output_loss: 82325.7714 - recon_mean_squared_error: 1.0052 - reg_output_mean_squared_error: 82325.7714 - val_loss: 112154.7116 - val_recon_loss: 1.0053 - val_reg_output_loss: 112054.1791 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 112054.1791\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 80242.7536 - recon_loss: 1.0018 - reg_output_loss: 80142.5757 - recon_mean_squared_error: 1.0018 - reg_output_mean_squared_error: 80142.5757 - val_loss: 111854.6469 - val_recon_loss: 1.0027 - val_reg_output_loss: 111754.3719 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 111754.3719\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 85257.6384 - recon_loss: 1.0015 - reg_output_loss: 85157.4866 - recon_mean_squared_error: 1.0015 - reg_output_mean_squared_error: 85157.4866 - val_loss: 110675.5919 - val_recon_loss: 1.0035 - val_reg_output_loss: 110575.2450 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 110575.2450\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 85801.6421 - recon_loss: 1.0019 - reg_output_loss: 85701.4559 - recon_mean_squared_error: 1.0019 - reg_output_mean_squared_error: 85701.4559 - val_loss: 110480.0731 - val_recon_loss: 1.0039 - val_reg_output_loss: 110379.6847 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 110379.6847\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 270us/step - loss: 85593.0767 - recon_loss: 1.0033 - reg_output_loss: 85492.7421 - recon_mean_squared_error: 1.0033 - reg_output_mean_squared_error: 85492.7421 - val_loss: 110627.9931 - val_recon_loss: 1.0039 - val_reg_output_loss: 110527.6078 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 110527.6078\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 230us/step - loss: 82924.4239 - recon_loss: 1.0011 - reg_output_loss: 82824.3103 - recon_mean_squared_error: 1.0011 - reg_output_mean_squared_error: 82824.3103 - val_loss: 109949.2334 - val_recon_loss: 1.0027 - val_reg_output_loss: 109848.9600 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 109848.9600\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 82929.9617 - recon_loss: 1.0026 - reg_output_loss: 82829.6998 - recon_mean_squared_error: 1.0026 - reg_output_mean_squared_error: 82829.6998 - val_loss: 110085.4544 - val_recon_loss: 1.0025 - val_reg_output_loss: 109985.2000 - val_recon_mean_squared_error: 1.0025 - val_reg_output_mean_squared_error: 109985.2000\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 89989.3266 - recon_loss: 1.0014 - reg_output_loss: 89889.1866 - recon_mean_squared_error: 1.0014 - reg_output_mean_squared_error: 89889.1866 - val_loss: 108396.5995 - val_recon_loss: 1.0014 - val_reg_output_loss: 108296.4566 - val_recon_mean_squared_error: 1.0014 - val_reg_output_mean_squared_error: 108296.4566\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 250us/step - loss: 81169.6183 - recon_loss: 1.0020 - reg_output_loss: 81069.4161 - recon_mean_squared_error: 1.0020 - reg_output_mean_squared_error: 81069.4161 - val_loss: 108647.3064 - val_recon_loss: 1.0265 - val_reg_output_loss: 108544.6533 - val_recon_mean_squared_error: 1.0265 - val_reg_output_mean_squared_error: 108544.6533\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 89816.8046 - recon_loss: 1.0055 - reg_output_loss: 89716.2588 - recon_mean_squared_error: 1.0055 - reg_output_mean_squared_error: 89716.2588 - val_loss: 107194.1720 - val_recon_loss: 1.0021 - val_reg_output_loss: 107093.9595 - val_recon_mean_squared_error: 1.0021 - val_reg_output_mean_squared_error: 107093.9595\n",
      "Epoch 477/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 85103.8670 - recon_loss: 1.0003 - reg_output_loss: 85003.8405 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 85003.8405 - val_loss: 106817.0533 - val_recon_loss: 1.0027 - val_reg_output_loss: 106716.7883 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 106716.7883\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 243us/step - loss: 79193.2720 - recon_loss: 1.0015 - reg_output_loss: 79093.1192 - recon_mean_squared_error: 1.0015 - reg_output_mean_squared_error: 79093.1192 - val_loss: 107951.4725 - val_recon_loss: 1.0010 - val_reg_output_loss: 107851.3717 - val_recon_mean_squared_error: 1.0010 - val_reg_output_mean_squared_error: 107851.3717\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 84790.7679 - recon_loss: 1.0006 - reg_output_loss: 84690.7066 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 84690.7066 - val_loss: 107596.7070 - val_recon_loss: 1.0039 - val_reg_output_loss: 107496.3172 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 107496.3172\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 247us/step - loss: 81305.0499 - recon_loss: 1.0011 - reg_output_loss: 81204.9359 - recon_mean_squared_error: 1.0011 - reg_output_mean_squared_error: 81204.9359 - val_loss: 108162.8128 - val_recon_loss: 1.0019 - val_reg_output_loss: 108062.6231 - val_recon_mean_squared_error: 1.0019 - val_reg_output_mean_squared_error: 108062.6231\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 237us/step - loss: 88549.5066 - recon_loss: 1.0091 - reg_output_loss: 88448.5966 - recon_mean_squared_error: 1.0091 - reg_output_mean_squared_error: 88448.5966 - val_loss: 105621.7120 - val_recon_loss: 1.0044 - val_reg_output_loss: 105521.2711 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 105521.2711\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 80210.7920 - recon_loss: 1.0013 - reg_output_loss: 80110.6578 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 80110.6578 - val_loss: 105562.3211 - val_recon_loss: 1.0039 - val_reg_output_loss: 105461.9322 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 105461.9322\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 253us/step - loss: 83286.1632 - recon_loss: 1.0006 - reg_output_loss: 83186.1010 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 83186.1010 - val_loss: 105855.8433 - val_recon_loss: 1.0029 - val_reg_output_loss: 105755.5528 - val_recon_mean_squared_error: 1.0029 - val_reg_output_mean_squared_error: 105755.5528\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 283us/step - loss: 83717.4478 - recon_loss: 1.0007 - reg_output_loss: 83617.3751 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 83617.3751 - val_loss: 105903.9356 - val_recon_loss: 1.0050 - val_reg_output_loss: 105803.4380 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 105803.4380\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 280us/step - loss: 80145.5146 - recon_loss: 1.0013 - reg_output_loss: 80045.3843 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 80045.3843 - val_loss: 106497.1773 - val_recon_loss: 1.0026 - val_reg_output_loss: 106396.9169 - val_recon_mean_squared_error: 1.0026 - val_reg_output_mean_squared_error: 106396.9169\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 273us/step - loss: 85182.4273 - recon_loss: 1.0042 - reg_output_loss: 85082.0064 - recon_mean_squared_error: 1.0042 - reg_output_mean_squared_error: 85082.0064 - val_loss: 105759.8355 - val_recon_loss: 1.0024 - val_reg_output_loss: 105659.5963 - val_recon_mean_squared_error: 1.0024 - val_reg_output_mean_squared_error: 105659.5963\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 277us/step - loss: 91577.1284 - recon_loss: 1.0023 - reg_output_loss: 91476.9042 - recon_mean_squared_error: 1.0023 - reg_output_mean_squared_error: 91476.9042 - val_loss: 104215.9628 - val_recon_loss: 1.0030 - val_reg_output_loss: 104115.6595 - val_recon_mean_squared_error: 1.0030 - val_reg_output_mean_squared_error: 104115.6595\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 240us/step - loss: 83323.1542 - recon_loss: 1.0007 - reg_output_loss: 83223.0821 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 83223.0821 - val_loss: 103885.3327 - val_recon_loss: 1.0027 - val_reg_output_loss: 103785.0627 - val_recon_mean_squared_error: 1.0027 - val_reg_output_mean_squared_error: 103785.0627\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 82956.9994 - recon_loss: 1.0012 - reg_output_loss: 82856.8794 - recon_mean_squared_error: 1.0012 - reg_output_mean_squared_error: 82856.8794 - val_loss: 104295.4527 - val_recon_loss: 1.0017 - val_reg_output_loss: 104195.2820 - val_recon_mean_squared_error: 1.0017 - val_reg_output_mean_squared_error: 104195.2820\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 233us/step - loss: 84980.6250 - recon_loss: 1.0019 - reg_output_loss: 84880.4342 - recon_mean_squared_error: 1.0019 - reg_output_mean_squared_error: 84880.4342 - val_loss: 103426.2894 - val_recon_loss: 1.0063 - val_reg_output_loss: 103325.6647 - val_recon_mean_squared_error: 1.0063 - val_reg_output_mean_squared_error: 103325.6647\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 267us/step - loss: 87646.8748 - recon_loss: 1.0030 - reg_output_loss: 87546.5791 - recon_mean_squared_error: 1.0030 - reg_output_mean_squared_error: 87546.5791 - val_loss: 102331.0500 - val_recon_loss: 1.0021 - val_reg_output_loss: 102230.8359 - val_recon_mean_squared_error: 1.0021 - val_reg_output_mean_squared_error: 102230.8359\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 263us/step - loss: 82124.9805 - recon_loss: 1.0013 - reg_output_loss: 82024.8449 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 82024.8449 - val_loss: 102929.5094 - val_recon_loss: 1.0026 - val_reg_output_loss: 102829.2552 - val_recon_mean_squared_error: 1.0026 - val_reg_output_mean_squared_error: 102829.2552\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 267us/step - loss: 85240.8545 - recon_loss: 1.0012 - reg_output_loss: 85140.7293 - recon_mean_squared_error: 1.0012 - reg_output_mean_squared_error: 85140.7293 - val_loss: 101672.2183 - val_recon_loss: 1.0018 - val_reg_output_loss: 101572.0375 - val_recon_mean_squared_error: 1.0018 - val_reg_output_mean_squared_error: 101572.0375\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 88388.5199 - recon_loss: 1.0001 - reg_output_loss: 88288.5121 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 88288.5121 - val_loss: 100889.8459 - val_recon_loss: 1.0025 - val_reg_output_loss: 100789.5959 - val_recon_mean_squared_error: 1.0025 - val_reg_output_mean_squared_error: 100789.5959\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 323us/step - loss: 82253.6260 - recon_loss: 1.0059 - reg_output_loss: 82153.0387 - recon_mean_squared_error: 1.0059 - reg_output_mean_squared_error: 82153.0387 - val_loss: 101484.7548 - val_recon_loss: 1.0058 - val_reg_output_loss: 101384.1752 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 101384.1752\n",
      "Epoch 496/500\n",
      "300/300 [==============================] - 0s 267us/step - loss: 81911.1246 - recon_loss: 1.0015 - reg_output_loss: 81810.9756 - recon_mean_squared_error: 1.0015 - reg_output_mean_squared_error: 81810.9756 - val_loss: 101707.1588 - val_recon_loss: 1.0031 - val_reg_output_loss: 101606.8444 - val_recon_mean_squared_error: 1.0031 - val_reg_output_mean_squared_error: 101606.8444\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 290us/step - loss: 84210.0049 - recon_loss: 1.0012 - reg_output_loss: 84109.8883 - recon_mean_squared_error: 1.0012 - reg_output_mean_squared_error: 84109.8883 - val_loss: 101595.8181 - val_recon_loss: 1.0039 - val_reg_output_loss: 101495.4253 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 101495.4253\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 257us/step - loss: 80349.5498 - recon_loss: 1.0009 - reg_output_loss: 80249.4605 - recon_mean_squared_error: 1.0009 - reg_output_mean_squared_error: 80249.4605 - val_loss: 102940.0808 - val_recon_loss: 1.0028 - val_reg_output_loss: 102839.7986 - val_recon_mean_squared_error: 1.0028 - val_reg_output_mean_squared_error: 102839.7986\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 297us/step - loss: 82465.1260 - recon_loss: 1.0006 - reg_output_loss: 82365.0691 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 82365.0691 - val_loss: 103772.0331 - val_recon_loss: 1.0026 - val_reg_output_loss: 103671.7734 - val_recon_mean_squared_error: 1.0026 - val_reg_output_mean_squared_error: 103671.7734\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 283us/step - loss: 85886.8332 - recon_loss: 1.0016 - reg_output_loss: 85786.6695 - recon_mean_squared_error: 1.0016 - reg_output_mean_squared_error: 85786.6695 - val_loss: 102659.5425 - val_recon_loss: 1.0031 - val_reg_output_loss: 102559.2309 - val_recon_mean_squared_error: 1.0031 - val_reg_output_mean_squared_error: 102559.2309\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"recon\": X_train, \"reg_output\": y_train},\n",
    "    validation_data=(X_valid, {\"recon\": X_valid, \"reg_output\": y_valid}),\n",
    "    epochs=hps[\"num_epochs\"],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Now I'll generate learning curves with `plotly`.  These are good for logging with `mlflow` or other similar experiment tracking libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recon_loss</th>\n",
       "      <th>val_reg_output_loss</th>\n",
       "      <th>val_recon_mean_squared_error</th>\n",
       "      <th>val_reg_output_mean_squared_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>recon_loss</th>\n",
       "      <th>reg_output_loss</th>\n",
       "      <th>recon_mean_squared_error</th>\n",
       "      <th>reg_output_mean_squared_error</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86327.676406</td>\n",
       "      <td>1.233706</td>\n",
       "      <td>86204.305156</td>\n",
       "      <td>1.233706</td>\n",
       "      <td>86204.305156</td>\n",
       "      <td>97668.227292</td>\n",
       "      <td>1.001812</td>\n",
       "      <td>97568.044792</td>\n",
       "      <td>1.001812</td>\n",
       "      <td>97568.044792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86331.005469</td>\n",
       "      <td>1.351861</td>\n",
       "      <td>86195.819375</td>\n",
       "      <td>1.351861</td>\n",
       "      <td>86195.819375</td>\n",
       "      <td>97659.173906</td>\n",
       "      <td>1.003305</td>\n",
       "      <td>97558.843385</td>\n",
       "      <td>1.003305</td>\n",
       "      <td>97558.843385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86392.361719</td>\n",
       "      <td>2.114701</td>\n",
       "      <td>86180.892344</td>\n",
       "      <td>2.114701</td>\n",
       "      <td>86180.892344</td>\n",
       "      <td>97650.913125</td>\n",
       "      <td>1.005332</td>\n",
       "      <td>97550.380885</td>\n",
       "      <td>1.005332</td>\n",
       "      <td>97550.380885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86299.638281</td>\n",
       "      <td>1.375389</td>\n",
       "      <td>86162.100156</td>\n",
       "      <td>1.375389</td>\n",
       "      <td>86162.100156</td>\n",
       "      <td>97638.557865</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>97537.517812</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>97537.517812</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86263.851875</td>\n",
       "      <td>1.238314</td>\n",
       "      <td>86140.020937</td>\n",
       "      <td>1.238314</td>\n",
       "      <td>86140.020937</td>\n",
       "      <td>97622.903333</td>\n",
       "      <td>1.016711</td>\n",
       "      <td>97521.232917</td>\n",
       "      <td>1.016711</td>\n",
       "      <td>97521.232917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>101707.158750</td>\n",
       "      <td>1.003143</td>\n",
       "      <td>101606.844375</td>\n",
       "      <td>1.003143</td>\n",
       "      <td>101606.844375</td>\n",
       "      <td>81911.124583</td>\n",
       "      <td>1.001488</td>\n",
       "      <td>81810.975625</td>\n",
       "      <td>1.001488</td>\n",
       "      <td>81810.975625</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>101595.818125</td>\n",
       "      <td>1.003940</td>\n",
       "      <td>101495.425312</td>\n",
       "      <td>1.003940</td>\n",
       "      <td>101495.425312</td>\n",
       "      <td>84210.004896</td>\n",
       "      <td>1.001169</td>\n",
       "      <td>84109.888333</td>\n",
       "      <td>1.001169</td>\n",
       "      <td>84109.888333</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>102940.080781</td>\n",
       "      <td>1.002808</td>\n",
       "      <td>102839.798594</td>\n",
       "      <td>1.002808</td>\n",
       "      <td>102839.798594</td>\n",
       "      <td>80349.549792</td>\n",
       "      <td>1.000879</td>\n",
       "      <td>80249.460521</td>\n",
       "      <td>1.000879</td>\n",
       "      <td>80249.460521</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>103772.033125</td>\n",
       "      <td>1.002582</td>\n",
       "      <td>103671.773438</td>\n",
       "      <td>1.002582</td>\n",
       "      <td>103671.773438</td>\n",
       "      <td>82465.125990</td>\n",
       "      <td>1.000567</td>\n",
       "      <td>82365.069115</td>\n",
       "      <td>1.000567</td>\n",
       "      <td>82365.069115</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>102659.542500</td>\n",
       "      <td>1.003094</td>\n",
       "      <td>102559.230938</td>\n",
       "      <td>1.003094</td>\n",
       "      <td>102559.230938</td>\n",
       "      <td>85886.833229</td>\n",
       "      <td>1.001624</td>\n",
       "      <td>85786.669479</td>\n",
       "      <td>1.001624</td>\n",
       "      <td>85786.669479</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          val_loss  val_recon_loss  val_reg_output_loss  \\\n",
       "0     86327.676406        1.233706         86204.305156   \n",
       "1     86331.005469        1.351861         86195.819375   \n",
       "2     86392.361719        2.114701         86180.892344   \n",
       "3     86299.638281        1.375389         86162.100156   \n",
       "4     86263.851875        1.238314         86140.020937   \n",
       "..             ...             ...                  ...   \n",
       "495  101707.158750        1.003143        101606.844375   \n",
       "496  101595.818125        1.003940        101495.425312   \n",
       "497  102940.080781        1.002808        102839.798594   \n",
       "498  103772.033125        1.002582        103671.773438   \n",
       "499  102659.542500        1.003094        102559.230938   \n",
       "\n",
       "     val_recon_mean_squared_error  val_reg_output_mean_squared_error  \\\n",
       "0                        1.233706                       86204.305156   \n",
       "1                        1.351861                       86195.819375   \n",
       "2                        2.114701                       86180.892344   \n",
       "3                        1.375389                       86162.100156   \n",
       "4                        1.238314                       86140.020937   \n",
       "..                            ...                                ...   \n",
       "495                      1.003143                      101606.844375   \n",
       "496                      1.003940                      101495.425312   \n",
       "497                      1.002808                      102839.798594   \n",
       "498                      1.002582                      103671.773438   \n",
       "499                      1.003094                      102559.230938   \n",
       "\n",
       "             loss  recon_loss  reg_output_loss  recon_mean_squared_error  \\\n",
       "0    97668.227292    1.001812     97568.044792                  1.001812   \n",
       "1    97659.173906    1.003305     97558.843385                  1.003305   \n",
       "2    97650.913125    1.005332     97550.380885                  1.005332   \n",
       "3    97638.557865    1.010385     97537.517812                  1.010385   \n",
       "4    97622.903333    1.016711     97521.232917                  1.016711   \n",
       "..            ...         ...              ...                       ...   \n",
       "495  81911.124583    1.001488     81810.975625                  1.001488   \n",
       "496  84210.004896    1.001169     84109.888333                  1.001169   \n",
       "497  80349.549792    1.000879     80249.460521                  1.000879   \n",
       "498  82465.125990    1.000567     82365.069115                  1.000567   \n",
       "499  85886.833229    1.001624     85786.669479                  1.001624   \n",
       "\n",
       "     reg_output_mean_squared_error  step  \n",
       "0                     97568.044792     0  \n",
       "1                     97558.843385     1  \n",
       "2                     97550.380885     2  \n",
       "3                     97537.517812     3  \n",
       "4                     97521.232917     4  \n",
       "..                             ...   ...  \n",
       "495                   81810.975625   495  \n",
       "496                   84109.888333   496  \n",
       "497                   80249.460521   497  \n",
       "498                   82365.069115   498  \n",
       "499                   85786.669479   499  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df[\"step\"] = hist_df.index\n",
    "\n",
    "plot_df = hist_df.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"step\",\n",
    "        \"loss\",\n",
    "        \"val_loss\",\n",
    "        \"reg_output_loss\",\n",
    "        \"val_reg_output_loss\",\n",
    "        \"recon_loss\",\n",
    "        \"val_recon_loss\",\n",
    "    ],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_long = pd.melt(\n",
    "    plot_df, id_vars=\"step\", var_name=\"type\", value_name=\"loss_value\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "type=loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "loss",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          97668.22729166667,
          97659.17390625,
          97650.913125,
          97638.55786458333,
          97622.90333333334,
          97608.26333333334,
          97596.35875,
          97552.72177083333,
          97514.97385416667,
          97491.35947916667,
          97421.41947916667,
          97405.630625,
          97286.473125,
          97154.95791666667,
          97183.3153125,
          97114.69979166667,
          96913.94479166667,
          96898.25385416667,
          96566.03197916667,
          96424.48375,
          96392.98875,
          95994.7428125,
          96113.49302083334,
          95865.50052083333,
          95618.28645833333,
          95183.96072916666,
          95374.94083333333,
          94779.67395833334,
          94831.24854166666,
          94522.5290625,
          94497.24166666667,
          94221.45364583333,
          93968.33057291666,
          93776.59083333334,
          93578.38875,
          93771.7471875,
          92775.17854166667,
          92908.6575,
          92866.2771875,
          92791.66984375,
          91777.3559375,
          92084.18489583333,
          92293.53614583334,
          92275.648125,
          91599.56989583334,
          91489.07416666667,
          92462.63645833333,
          91940.9225,
          91545.39005208333,
          91486.55375,
          91376.87052083333,
          92390.71333333333,
          91095.47505208333,
          92342.15677083333,
          91912.30291666667,
          91231.76770833334,
          91391.17104166666,
          91295.309375,
          90907.62854166667,
          91185.99645833333,
          91676.0271875,
          90610.8896875,
          90796.75541666667,
          90866.59791666667,
          91100.89854166667,
          90142.62645833334,
          89976.78885416666,
          90882.1321875,
          90646.03385416667,
          89894.18708333334,
          90295.8628125,
          89556.31614583333,
          90624.11020833334,
          90941.88765625,
          90488.52572916666,
          90179.05322916666,
          90320.34416666666,
          91466.3003125,
          89420.77817708334,
          90969.24015625,
          90791.30989583333,
          90958.60802083333,
          90908.18552083333,
          90607.9015625,
          89920.556875,
          90013.5896875,
          89932.57729166666,
          88997.39609375,
          90472.535,
          90431.579375,
          91065.35703125,
          88993.77052083334,
          90490.88208333333,
          89071.18625,
          90855.26260416667,
          89129.9209375,
          89539.93947916667,
          89388.3384375,
          88786.77677083333,
          89141.41145833333,
          89162.28453125,
          89369.91890625,
          89921.39375,
          90434.68979166666,
          89265.02854166667,
          89112.07463541666,
          89149.08354166667,
          88389.7828125,
          89739.71041666667,
          88875.37020833333,
          88145.83645833333,
          88840.199375,
          89530.39833333333,
          88887.54458333334,
          89005.34135416667,
          88008.61083333334,
          89520.0084375,
          85944.49916666666,
          88866.93854166666,
          87863.434375,
          87787.38197916666,
          89058.28401041667,
          87268.295625,
          88569.30916666667,
          88088.5265625,
          88388.24135416666,
          86869.98510416667,
          87072.81166666666,
          88330.34640625,
          86847.310625,
          86898.78427083333,
          88394.54026041667,
          87828.58010416667,
          88852.94375,
          88204.36901041666,
          85939.26260416667,
          88585.7846875,
          88684.94395833333,
          87307.23270833334,
          88095.99239583334,
          87501.25541666667,
          88225.88416666667,
          85916.1034375,
          88112.21,
          87230.88739583333,
          86605.49458333333,
          87426.5696875,
          88359.95135416667,
          87573.26552083333,
          86666.094375,
          87214.62302083333,
          85807.8196875,
          86840.32369791667,
          88142.37302083333,
          85788.64395833333,
          86649.40307291667,
          87041.33052083333,
          86068.2775,
          85387.3484375,
          87326.83375,
          86378.96916666666,
          86647.03666666667,
          85777.85520833333,
          87547.83875,
          86887.505625,
          85395.14958333333,
          85174.16635416666,
          86103.83083333333,
          86378.8025,
          86863.54354166667,
          85931.92114583333,
          86172.9246875,
          86843.8525,
          85536.57854166666,
          84875.999375,
          85232.26333333334,
          86649.3228125,
          86412.51270833334,
          86179.72010416667,
          84615.47041666666,
          85681.994375,
          84889.36166666666,
          85813.21666666666,
          86287.97989583333,
          84325.43270833333,
          83736.23479166666,
          85806.39036458333,
          84384.43182291667,
          85805.65614583333,
          84474.21375,
          84821.97552083334,
          85538.7740625,
          83740.44791666667,
          84169.63395833333,
          84084.33708333333,
          85645.05479166667,
          84502.35598958333,
          83622.35364583334,
          84995.73927083334,
          85138.56385416667,
          84384.61739583334,
          82735.19013020833,
          84076.91,
          83205.84822916667,
          84218.56989583334,
          84201.925,
          84549.50395833333,
          84307.734375,
          83663.90708333334,
          84544.5678125,
          82556.74614583333,
          84785.66958333334,
          85621.02703125,
          83808.63010416667,
          81190.49364583334,
          82858.77208333333,
          84519.53916666667,
          82768.275,
          83994.81791666667,
          84339.18510416667,
          82832.31333333334,
          83877.76239583333,
          80911.963125,
          82340.54979166666,
          83952.8275,
          83663.88791666667,
          83955.23760416667,
          81941.35614583333,
          82654.10229166667,
          83991.32458333333,
          81392.97833333333,
          83510.893125,
          82557.625625,
          82313.38411458333,
          82174.42854166667,
          83147.80510416666,
          80486.593125,
          82610.15010416666,
          81743.21802083333,
          80461.62260416667,
          80577.65484375,
          83229.214921875,
          83753.27541666667,
          83258.76192708334,
          79622.01010416666,
          81345.000625,
          81076.53333333334,
          81649.18197916666,
          80513.38822916667,
          83598.68322916667,
          81495.65104166667,
          80323.13333333333,
          80132.16776041666,
          79358.37979166667,
          81165.07770833334,
          83661.36104166666,
          81675.41614583334,
          79791.58604166667,
          80337.95885416666,
          78994.18958333334,
          79640.62354166666,
          83374.12729166666,
          79593.41541666667,
          81038.65130208334,
          82353.17270833334,
          82826.29135416666,
          78257.1065625,
          79989.77364583334,
          80508.65552083333,
          79099.58927083333,
          79570.29854166666,
          80056.48197916667,
          80410.73903645833,
          78586.818125,
          77896.15734375,
          78720.6915625,
          79464.962265625,
          79042.06520833333,
          79310.88369791667,
          76603.58291666667,
          81531.09630208333,
          78707.19067708333,
          79218.47979166667,
          78126.49927083333,
          81161.49239583334,
          78739.44223958334,
          77111.46625,
          79224.82375,
          78164.80421875,
          83423.194375,
          77020.84177083333,
          78522.21302083334,
          76554.936875,
          78936.981875,
          77973.454375,
          78617.75104166666,
          80515.979375,
          80225.04916666666,
          80895.2903125,
          78459.76583333334,
          76542.14166666666,
          75835.95302083333,
          80454.40833333334,
          76638.118125,
          74608.83682291667,
          76589.62364583333,
          78527.47229166667,
          74297.6396875,
          76015.32197916666,
          78413.47927083333,
          77462.97,
          79630.71604166667,
          75585.37786458334,
          78210.2421875,
          76522.89572916667,
          77338.37010416666,
          77606.59166666666,
          77064.151875,
          77683.8496875,
          79266.17052083333,
          78440.34385416667,
          78468.88927083333,
          74349.68213541666,
          78521.38572916666,
          80640.59630208333,
          81586.33192708333,
          82808.22109375,
          75855.270625,
          74005.63380208334,
          76296.40260416667,
          80901.39916666667,
          79253.91354166667,
          73541.736875,
          78355.78083333334,
          79930.68677083333,
          78227.4565625,
          76014.83604166667,
          78401.36083333334,
          75235.79864583333,
          79858.68333333333,
          76723.7546875,
          83656.57135416666,
          76927.96020833333,
          82686.65739583333,
          80598.16869791667,
          77639.12385416667,
          80162.15177083333,
          76075.81260416667,
          84771.74677083333,
          77537.44260416667,
          82044.88895833334,
          80912.0790625,
          75085.45916666667,
          80815.60052083334,
          78323.8571875,
          85338.26817708333,
          82066.51125,
          77682.07770833334,
          81754.87875,
          86741.608125,
          80588.18666666666,
          79908.6953125,
          83829.65572916667,
          77734.95078125,
          81652.3265625,
          78654.4478125,
          82956.91114583334,
          83176.98166666667,
          78383.55052083333,
          79877.37463541667,
          81428.62697916667,
          83630.53921875,
          75625.37799479166,
          78808.94010416667,
          82822.57322916666,
          75710.48708333333,
          80545.38416666667,
          81049.2415625,
          82709.44114583333,
          81719.063125,
          83990.34770833333,
          75512.85158854167,
          79690.4003125,
          82686.4940625,
          81266.75046875,
          84158.225,
          80793.658046875,
          84730.09375,
          80054.8628125,
          80146.24989583333,
          78864.7565625,
          85181.48364583333,
          83780.96,
          78656.07583333334,
          79421.6903125,
          86960.35489583333,
          83521.32760416667,
          79692.49421875,
          82926.96177083334,
          79938.13645833333,
          83080.983125,
          84684.10239583334,
          82736.76,
          82192.69583333333,
          86633.04669270833,
          86939.04463541666,
          82891.06291666666,
          84156.30458333333,
          81686.07385416667,
          82099.70739583333,
          86050.62364583333,
          87580.84401041667,
          83370.384375,
          84281.30645833333,
          91412.970625,
          86355.34791666667,
          86497.30145833333,
          84384.54911458334,
          83938.49510416666,
          81772.36510416666,
          86254.29885416667,
          80321.03875,
          84135.95708333333,
          88366.77125,
          82772.06005208334,
          86945.93145833333,
          79524.51088541666,
          84114.75119791667,
          89832.355,
          84845.13104166667,
          93454.30916666667,
          83414.32666666666,
          82469.91885416667,
          82500.7803125,
          83673.97674479167,
          86596.51760416667,
          84642.4190625,
          81127.383125,
          88652.48885416667,
          86498.54208333333,
          89126.92786458334,
          84655.88953125,
          78538.40645833334,
          85234.26385416667,
          80897.8240625,
          81873.46041666667,
          87664.41697916666,
          84471.3709375,
          83659.2671875,
          88077.38458333333,
          84903.746875,
          83264.91104166667,
          85555.1265625,
          86159.57697916667,
          83936.568125,
          85891.05416666667,
          81608.54005208334,
          88296.61916666667,
          81734.15052083334,
          87043.7234375,
          83862.55989583333,
          84656.464375,
          85074.81083333334,
          82003.3353125,
          84731.70177083333,
          85352.38114583334,
          82426.29020833333,
          80242.75364583333,
          85257.63838541666,
          85801.64208333334,
          85593.07666666666,
          82924.42385416667,
          82929.96166666667,
          89989.3265625,
          81169.61833333333,
          89816.80458333333,
          85103.86697916666,
          79193.27197916666,
          84790.76791666666,
          81305.04989583333,
          88549.5065625,
          80210.79197916666,
          83286.16322916666,
          83717.4478125,
          80145.51458333334,
          85182.42729166667,
          91577.1284375,
          83323.15416666666,
          82956.999375,
          84980.625,
          87646.87479166666,
          82124.98052083333,
          85240.85447916666,
          88388.51989583333,
          82253.62604166666,
          81911.12458333334,
          84210.00489583334,
          80349.54979166666,
          82465.12598958334,
          85886.83322916667
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=val_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "val_loss",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "val_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          86327.67640625,
          86331.00546875,
          86392.36171875,
          86299.63828125,
          86263.851875,
          86272.22046875,
          86208.4978125,
          86144.02015625,
          86078.0959375,
          86096.53296875,
          85989.27171875,
          85947.62484375,
          85889.8953125,
          85825.621875,
          85816.123125,
          85790.14828125,
          85863.47390625,
          85956.2796875,
          86107.34140625,
          86751.05125,
          86705.44234375,
          87492.35921875,
          88058.2996875,
          89269.194375,
          90673.615625,
          91966.30171875,
          93816.63921875,
          95603.5115625,
          97969.6340625,
          100887.009375,
          104461.4515625,
          108715.51515625,
          111668.1140625,
          116170.54125,
          120004.546875,
          123772.9959375,
          130602.3496875,
          135926.4028125,
          143715.0540625,
          150850.2853125,
          154548.2765625,
          162347.615,
          169231.83875,
          176122.89875,
          184720.896875,
          192628.330625,
          196147.6125,
          201116.605,
          208728.670625,
          215055.951875,
          218908.620625,
          227109.180625,
          234689.169375,
          237975.82375,
          239658.116875,
          246010.049375,
          257145.534375,
          255968.701875,
          266599.32125,
          267500.075,
          265252.9725,
          267303.09875,
          274273.03625,
          281090.48,
          288063.90625,
          291990.05875,
          295071.33375,
          298992.75625,
          302510.215,
          306528.4275,
          309017.90125,
          318021.45,
          316087.1925,
          318451.11625,
          315247.6475,
          323289.6625,
          317451.59375,
          314086.525,
          322467.13875,
          315170.0875,
          318034.6675,
          318735.14125,
          314447.5025,
          317015.83375,
          319157.47375,
          324833.455,
          326850.5475,
          329010.8275,
          331836.65375,
          327504.97375,
          323934.09375,
          325354.73375,
          328567.885,
          329623.185,
          326121.94875,
          327836.5275,
          326453.51125,
          327801.8,
          337819.75,
          333554.3475,
          337802.17,
          342362.19375,
          339920.2675,
          332735.03125,
          332577.14125,
          330458.58625,
          329143.35875,
          332104.83875,
          325687.86375,
          330724.50375,
          338578.4575,
          342467.39625,
          336235.01375,
          338870.47625,
          341257.45375,
          340155.14375,
          337123.04375,
          349622.91875,
          351168.2075,
          350547.4925,
          346956.0325,
          344485.53625,
          344820.3975,
          351935.99375,
          349741.76375,
          351363.5875,
          357245.41,
          363148.5275,
          360656.15875,
          362688.6225,
          370006.00125,
          364444.82,
          365444.19,
          366183.7575,
          366913.7275,
          371138.27375,
          369556.60875,
          370377.03375,
          375728.13875,
          377676.44375,
          383848.47125,
          375227.78,
          380821.98625,
          379246.4175,
          385112.21875,
          390520.26875,
          395998.98125,
          390571.10875,
          390603.49875,
          389313.99,
          390866.29,
          392937.145,
          391080.6075,
          380732.745,
          388816.45375,
          382487.14,
          387904.09375,
          380536.51625,
          387961.91625,
          392389.24625,
          394487.625,
          395780.48875,
          397394.6025,
          396714.4825,
          387119.03875,
          385158.9925,
          384578.75875,
          390460.38,
          382606.85125,
          376439.46375,
          379188.4225,
          379766.01375,
          376285.375,
          382355.88875,
          392711.84,
          397325.45,
          391116.595,
          392744.775,
          394189.175,
          402219.7975,
          398332.5875,
          403071.8025,
          408871.2325,
          401159.3775,
          406613.525,
          411444.14,
          408554.3275,
          408468.205,
          408081.4675,
          409474.395,
          409303.4625,
          411325.3275,
          416861.1675,
          421978.755,
          427953.2175,
          429520.3025,
          428973.0425,
          431883.4025,
          426925.6175,
          421679.7625,
          419224.5175,
          429104.79,
          424588.9,
          428399.605,
          422278.77,
          422489.1825,
          421622.39,
          423873.165,
          427411.035,
          421065.225,
          428954.4475,
          428561.4,
          423753.7275,
          421323.29,
          428363.1975,
          430485.4225,
          430175.195,
          432017.65,
          423665.7325,
          423172.84,
          428261.3075,
          435686.1925,
          446605.86,
          455920.0975,
          453186.36,
          446971.675,
          449317.685,
          451948.72,
          459866.0625,
          463366.2625,
          475990.0675,
          470032.855,
          465617.5275,
          468731.3075,
          473388.3325,
          463332.935,
          473783.4275,
          470339.9675,
          468473.7225,
          475615.465,
          475145.075,
          469273.05,
          459754.825,
          453722.2525,
          466145.3375,
          469004.6775,
          458246.2125,
          464592.585,
          458195.145,
          458656.2625,
          462992.7075,
          459228.225,
          465672.1225,
          481276.4475,
          484619.1725,
          466957.4425,
          474091.305,
          477889.23,
          494204.9425,
          504241.8475,
          507332.6975,
          494324.1975,
          495405.2275,
          492648.365,
          484779.0725,
          478148.8475,
          492425.575,
          494280.58,
          492531.105,
          489473.7625,
          490795.62,
          502737.5575,
          491797.035,
          502226.22,
          508598.455,
          502358.0675,
          503985.53,
          497330.2275,
          495635.76,
          505079.775,
          497777.9625,
          506181.6575,
          491836.21,
          486037.2275,
          477320.0925,
          476932.5375,
          489671.7025,
          493351.185,
          498722.3225,
          495737.1575,
          497897.1875,
          494391.4375,
          498250.43,
          503583.535,
          502452.925,
          494950.7325,
          481241.215,
          470439.85,
          457753.8275,
          465510.7675,
          467351.0675,
          474219.39,
          470179.335,
          470023.7475,
          486624.0875,
          481010.3,
          477073.7425,
          486364.395,
          491860.875,
          485291.9925,
          474640.42,
          467399.14,
          475669.435,
          482888.7125,
          486346.7375,
          477196.4675,
          468128.48,
          472386.8425,
          478671.88,
          471050.3575,
          463786.1525,
          457508.31,
          459578.3175,
          451180.655,
          437616.2925,
          432139.4525,
          424339.4575,
          436552.6275,
          439117.41,
          446534.1375,
          439576.1225,
          427881.3175,
          440709.325,
          429518.1375,
          424138.55,
          428935.1825,
          432375.1675,
          424336.3025,
          427706.8875,
          414293.2425,
          409622.545,
          383836.915,
          378972.42625,
          371276.15,
          362396.0325,
          357168.93375,
          348823.5625,
          354198.3275,
          337329.905,
          339209.15625,
          333311.38625,
          326617.93625,
          335177.9925,
          332841.3725,
          336962.405,
          319716.7825,
          314811.14625,
          317191.09,
          312933.71875,
          302301.25,
          298669.3625,
          299123.60375,
          294335.4075,
          293527.86625,
          283568.09875,
          289048.34125,
          284968.60875,
          279240.69125,
          277658.13125,
          278479.25,
          274321.795,
          266434.8725,
          270337.48875,
          274037.11875,
          268083.1275,
          266066.95,
          257725.36125,
          255139.82875,
          249556.895,
          252411.01625,
          245845.63375,
          247851.66625,
          244312.3275,
          237494.4475,
          234590.5225,
          225906.28125,
          228818.16,
          219918.43,
          221865.82,
          220905.97375,
          223395.973125,
          217489.29625,
          210666.664375,
          211546.97,
          212541.8375,
          206309.573125,
          203728.669375,
          204305.485625,
          200159.713125,
          196144.293125,
          194967.67,
          187109.535,
          182899.484375,
          184387.11375,
          179462.54,
          173742.93375,
          176599.77375,
          172635.430625,
          174288.62625,
          171455.54375,
          165904.075,
          163154.736875,
          163310.29125,
          161794.11125,
          152306.633125,
          149698.4028125,
          146158.8053125,
          145185.2825,
          143187.8184375,
          145187.895,
          143068.06875,
          144735.261875,
          144541.5378125,
          142077.6703125,
          139623.5665625,
          137741.4634375,
          139754.2321875,
          141133.7475,
          138032.28875,
          136070.6775,
          131238.90625,
          131528.8953125,
          131514.028125,
          132356.6265625,
          132726.6184375,
          130663.7796875,
          129516.855625,
          128815.2278125,
          126039.9278125,
          124136.3065625,
          122131.5709375,
          121906.2859375,
          122323.9071875,
          120104.325625,
          120707.576875,
          121041.3440625,
          120137.1753125,
          120158.4821875,
          119082.795625,
          117356.8675,
          116159.8684375,
          115449.5928125,
          115583.9790625,
          114940.095625,
          114691.878125,
          113055.8590625,
          114297.56375,
          112617.24625,
          113009.0103125,
          111999.14,
          111343.206875,
          112213.753125,
          112277.256875,
          113610.9921875,
          113181.9659375,
          111893.3375,
          112154.7115625,
          111854.646875,
          110675.591875,
          110480.073125,
          110627.993125,
          109949.2334375,
          110085.454375,
          108396.59953125,
          108647.30640625,
          107194.17203125,
          106817.05328125,
          107951.4725,
          107596.70703125,
          108162.8128125,
          105621.71203125,
          105562.32109375,
          105855.84328125,
          105903.935625,
          106497.17734375,
          105759.83546875,
          104215.9628125,
          103885.33265625,
          104295.45265625,
          103426.289375,
          102331.05,
          102929.509375,
          101672.21828125,
          100889.8459375,
          101484.75484375,
          101707.15875,
          101595.818125,
          102940.08078125,
          103772.033125,
          102659.5425
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=reg_output_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "reg_output_loss",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "reg_output_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          97568.04479166666,
          97558.84338541667,
          97550.38088541667,
          97537.5178125,
          97521.23291666666,
          97506.75833333333,
          97494.028125,
          97449.8859375,
          97411.53885416666,
          97385.46197916666,
          97313.70416666666,
          97298.18375,
          97175.55083333333,
          97043.18927083333,
          97070.87473958333,
          96998.35177083334,
          96795.2715625,
          96771.63125,
          96446.21302083334,
          96293.12802083333,
          96261.20489583333,
          95860.08416666667,
          95960.26645833334,
          95726.17239583333,
          95457.3565625,
          95023.24854166666,
          95219.86895833333,
          94604.73291666666,
          94661.64885416666,
          94330.8140625,
          94317.9146875,
          94044.2334375,
          93739.05463541667,
          93569.0790625,
          93401.37177083333,
          93577.16994791667,
          92555.15208333333,
          92602.496875,
          92626.13864583333,
          92519.55932291667,
          91562.4575,
          91871.97989583333,
          92108.47171875,
          92065.18177083334,
          91377.155,
          91277.68291666667,
          92235.78828125,
          91653.41145833333,
          91316.85130208333,
          91240.95083333334,
          91121.6615625,
          92101.89458333333,
          90884.25161458334,
          92142.7540625,
          91690.95375,
          90970.45270833334,
          91173.33708333333,
          91045.918125,
          90714.18739583333,
          90942.06854166667,
          91385.2275,
          90386.74963541667,
          90559.79260416667,
          90653.76166666667,
          90779.70260416667,
          89947.84802083333,
          89777.34,
          90667.57317708334,
          90465.79604166666,
          89690.72947916666,
          90086.2046875,
          89378.4428125,
          90377.24333333333,
          90769.26416666666,
          90282.1015625,
          89994.3084375,
          90095.9140625,
          91297.21010416666,
          89254.37791666666,
          90817.21494791667,
          90604.03125,
          90743.64010416667,
          90718.5196875,
          90451.8065625,
          89734.76333333334,
          89864.3259375,
          89779.35666666667,
          88769.85703125,
          90315.16875,
          90287.55916666667,
          90867.87005208334,
          88832.46510416667,
          90328.2165625,
          88911.14260416667,
          90687.61989583333,
          88971.26166666667,
          89340.83895833333,
          89229.71255208334,
          88651.7634375,
          88979.75677083334,
          89010.16265625,
          89200.97609375,
          89774.01125,
          90302.87385416667,
          89107.06526041667,
          88962.23046875,
          89004.83822916666,
          88214.0540625,
          89553.41083333333,
          88742.6196875,
          88012.52947916667,
          88638.18572916667,
          89387.341875,
          88754.40729166666,
          88872.52052083334,
          87874.2875,
          89384.72614583334,
          85805.7009375,
          88732.00427083333,
          87721.266875,
          87624.17864583334,
          88932.58208333333,
          87135.29729166666,
          88427.226875,
          87942.41,
          88258.40739583333,
          86727.57458333333,
          86927.7015625,
          88208.51708333334,
          86715.93442708334,
          86763.96989583333,
          88243.48942708333,
          87687.6228125,
          88705.7009375,
          88079.65416666666,
          85798.93489583333,
          88439.69177083333,
          88559.97864583334,
          87175.7059375,
          87963.72239583333,
          87361.26197916667,
          88076.83645833333,
          85780.70375,
          87984.31958333333,
          87097.16817708334,
          86481.27239583334,
          87294.62072916667,
          88238.91,
          87449.03859375,
          86530.54760416667,
          87092.79859375,
          85675.03822916666,
          86721.14875,
          88028.29760416667,
          85666.56302083333,
          86508.99041666667,
          86922.7040625,
          85942.84489583333,
          85259.99979166666,
          87205.05833333333,
          86265.65979166667,
          86514.92942708333,
          85641.201875,
          87435.37083333333,
          86774.91916666667,
          85272.03041666666,
          85062.49083333333,
          85977.54145833333,
          86264.43833333334,
          86742.72989583333,
          85811.76885416667,
          86045.66114583334,
          86730.00177083333,
          85416.72666666667,
          84756.07583333334,
          85123.14947916666,
          86522.03447916667,
          86286.52520833333,
          86064.64677083334,
          84498.28114583333,
          85562.798125,
          84775.97885416666,
          85695.77963541666,
          86165.1340625,
          84203.9034375,
          83626.57333333333,
          85691.58380208333,
          84271.76395833334,
          85690.90635416667,
          84364.31979166667,
          84711.32083333333,
          85406.56791666667,
          83624.80010416667,
          84059.1140625,
          83977.17489583333,
          85525.69135416667,
          84389.58505208333,
          83513.94052083333,
          84882.92239583333,
          85025.9240625,
          84267.12385416667,
          82625.77033854167,
          83950.52427083334,
          83094.6659375,
          84106.00635416666,
          84088.56614583333,
          84431.43822916667,
          84200.51328125,
          83554.94583333333,
          84432.88890625,
          82450.22625,
          84671.60666666667,
          85512.34921875,
          83698.83927083333,
          81074.9684375,
          82748.2709375,
          84412.89697916666,
          82658.76432291667,
          83885.03177083333,
          84231.21927083333,
          82724.85802083333,
          83767.62416666666,
          80803.8003125,
          82234.26458333334,
          83845.35854166666,
          83547.5715625,
          83838.3015625,
          81830.4446875,
          82549.23916666667,
          83879.5140625,
          81285.18875,
          83398.96479166667,
          82442.8559375,
          82203.32380208334,
          82068.50322916667,
          83035.84302083333,
          80379.18364583333,
          82501.97927083333,
          81636.15927083333,
          80355.35333333333,
          80466.034375,
          83118.240390625,
          83649.15166666667,
          83152.36838541667,
          79515.955,
          81240.6278125,
          80970.93625,
          81537.41380208333,
          80403.09666666666,
          83493.41927083333,
          81389.635,
          80218.18239583333,
          80024.93942708333,
          79247.5146875,
          81060.77677083333,
          83556.2846875,
          81565.49416666667,
          79684.68322916667,
          80231.58541666667,
          78888.3125,
          79535.05760416666,
          83269.66,
          79485.238125,
          80932.48375,
          82244.963125,
          82719.00052083333,
          78152.4984375,
          79882.17041666666,
          80401.47864583334,
          78995.58729166667,
          79462.70979166667,
          79951.5721875,
          80308.07908854166,
          78479.18890625,
          77791.84442708333,
          78613.06885416666,
          79359.6890625,
          78938.02552083334,
          79209.19708333333,
          76496.938125,
          81423.57078125,
          78603.40223958333,
          79113.36572916666,
          78022.58666666667,
          81058.3709375,
          78634.39333333333,
          77007.41666666667,
          79121.25864583334,
          78059.96276041666,
          83319.68875,
          76913.23911458334,
          78416.79260416667,
          76452.6890625,
          78833.15677083333,
          77863.85395833333,
          78514.68604166666,
          80410.28489583333,
          80122.7646875,
          80791.15875,
          78357.24166666667,
          76438.07791666666,
          75731.19890625,
          80351.11270833333,
          76532.529375,
          74504.34213541666,
          76487.84333333334,
          78423.575,
          74193.52927083333,
          75913.54078125,
          78306.77078125,
          77359.64463541667,
          79524.66833333333,
          75483.629375,
          78105.90958333333,
          76420.36666666667,
          77234.1353125,
          77503.0315625,
          76962.06604166667,
          77580.33145833333,
          79159.92322916667,
          78337.3659375,
          78361.42572916667,
          74247.495,
          78419.00666666667,
          80532.97515625,
          81482.3096875,
          82706.50208333334,
          75752.00546875,
          73901.18515625,
          76194.46458333333,
          80799.93552083333,
          79150.6615625,
          73439.09005208334,
          78253.85135416666,
          79827.91510416666,
          78124.9821875,
          75912.96802083333,
          78299.53239583333,
          75132.9728125,
          79756.08848958333,
          76622.20427083333,
          83553.80177083334,
          76825.46708333334,
          82585.55177083334,
          80495.41901041666,
          77537.46197916666,
          80061.54671875,
          75973.6334375,
          84668.885,
          77435.469375,
          81942.10296875,
          80809.7659375,
          74984.25302083333,
          80713.6525,
          78222.38463541666,
          85236.815,
          81963.29322916667,
          77580.04270833333,
          81653.63505208334,
          86640.049375,
          80486.48520833334,
          79807.2053125,
          83727.4675,
          77633.61307291666,
          81551.00729166667,
          78553.5846875,
          82855.37197916667,
          83075.28666666667,
          78281.67427083333,
          79776.41416666667,
          81325.7634375,
          83529.54307291667,
          75524.10041666667,
          78707.61541666667,
          82721.45427083333,
          75608.41510416666,
          80444.4278125,
          80947.71333333333,
          82608.82911458334,
          81618.32322916666,
          83888.94833333333,
          75410.46799479167,
          79589.3059375,
          82585.75572916666,
          81165.03354166666,
          84057.368125,
          80692.30518229166,
          84629.00635416666,
          79953.96604166667,
          80045.2125,
          78764.06927083334,
          85080.26791666666,
          83680.29390625,
          78555.46979166666,
          79321.04927083333,
          86859.56177083333,
          83420.31989583334,
          79588.09869791666,
          82826.61802083334,
          79837.216875,
          82980.76229166667,
          84583.29291666667,
          82636.03114583333,
          82091.948125,
          86532.42666666667,
          86837.76338541666,
          82790.80583333333,
          84055.73645833334,
          81585.0621875,
          81998.77453125,
          85950.0403125,
          87479.46953125,
          83270.011875,
          84180.77791666667,
          91311.8409375,
          86254.9628125,
          86396.8609375,
          84284.23380208333,
          83837.90421875,
          81672.00333333333,
          86153.5059375,
          80218.89541666667,
          84035.78708333333,
          88266.583125,
          82671.76583333334,
          86845.43854166666,
          79424.06671875,
          84014.09786458334,
          89731.87229166667,
          84744.5340625,
          93353.77677083333,
          83313.98854166667,
          82369.66489583334,
          82398.5425,
          83573.73208333334,
          86496.45885416666,
          84541.9059375,
          81026.87510416667,
          88552.14864583334,
          86398.04708333334,
          89026.81671875,
          84555.44088541667,
          78437.8553125,
          85133.88583333333,
          80796.49083333333,
          81773.220625,
          87564.32635416667,
          84371.0678125,
          83559.02369791667,
          87977.0740625,
          84803.25541666667,
          83164.54572916667,
          85454.97791666667,
          86059.06635416667,
          83836.17395833334,
          85790.82552083333,
          81508.2653125,
          88196.46208333333,
          81633.98083333333,
          86943.0684375,
          83762.50166666666,
          84556.25583333333,
          84974.46322916666,
          81903.19791666667,
          84631.41302083334,
          85252.1859375,
          82325.77135416666,
          80142.57572916667,
          85157.48661458334,
          85701.4559375,
          85492.74208333333,
          82824.3103125,
          82829.69979166667,
          89889.1865625,
          81069.41614583334,
          89716.25875,
          85003.84052083333,
          79093.11916666667,
          84690.7065625,
          81204.9359375,
          88448.5965625,
          80110.6578125,
          83186.10098958333,
          83617.37510416667,
          80045.38427083334,
          85082.00635416666,
          91476.90416666666,
          83223.08208333333,
          82856.879375,
          84880.43416666667,
          87546.5790625,
          82024.84489583333,
          85140.72927083333,
          88288.51213541666,
          82153.03869791667,
          81810.975625,
          84109.88833333334,
          80249.46052083334,
          82365.06911458333,
          85786.66947916667
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=val_reg_output_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "val_reg_output_loss",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "val_reg_output_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          86204.30515625,
          86195.819375,
          86180.89234375,
          86162.10015625,
          86140.0209375,
          86110.73625,
          86076.69421875,
          86024.464375,
          85946.38015625,
          85897.75125,
          85845.6475,
          85786.8540625,
          85722.2696875,
          85665.2925,
          85627.74609375,
          85629.3559375,
          85664.7196875,
          85732.8190625,
          85923.17796875,
          86156.02640625,
          86545.0178125,
          87259.9328125,
          87900.296875,
          88802.89484375,
          90166.751875,
          91775.3490625,
          93631.3984375,
          95438.77015625,
          97392.6503125,
          100496.78296875,
          104108.14375,
          107743.53515625,
          111464.431875,
          116021.8203125,
          119696.969375,
          123442.705,
          130432.1684375,
          135525.0203125,
          141990.8996875,
          148358.9715625,
          154209.0659375,
          162046.493125,
          168746.270625,
          175522.750625,
          184512.37,
          192023.16625,
          195244.47875,
          200968.27,
          208326.98375,
          213520.861875,
          218781.1875,
          226165.474375,
          234446.4075,
          233891.92375,
          239394.93375,
          245869.255,
          256878.61125,
          255826.815625,
          265717.29375,
          267247.32625,
          264985.0475,
          267127.98375,
          273909.94625,
          280915.57375,
          287766.07125,
          291767.185,
          294364.54625,
          298832.0975,
          301599.8125,
          305733.60375,
          308890.65875,
          315897.68625,
          315914.385,
          318323.61625,
          315050.9775,
          323154.2275,
          317327.6625,
          313362.4925,
          322253.51375,
          314290.27,
          317860.67625,
          318526.1525,
          314315.85375,
          316869.9375,
          319029.21375,
          324701.36625,
          325105.8275,
          328879.97875,
          331718.5975,
          324484.22375,
          323702.3475,
          325160.8675,
          327645.63875,
          329499.16,
          325129.785,
          326433.2125,
          325567.0025,
          327676.055,
          337672.945,
          333071.55375,
          337504.02375,
          342251.79375,
          339806.52125,
          332629.19875,
          332430.065,
          329858.34125,
          328929.7725,
          332001.2925,
          325536.775,
          330406.45875,
          338474.835,
          342318.57,
          336013.2275,
          338665.19,
          340961.4925,
          339790.21375,
          336983.70375,
          349431.82875,
          350969.3775,
          349921.71375,
          346819.56125,
          344261.925,
          344714.97125,
          351833.13875,
          349577.6175,
          351260.18125,
          356362.565,
          363035.065,
          360384.48375,
          362583.39875,
          369875.5275,
          364295.955,
          365321.3875,
          365991.5125,
          366774.42875,
          370995.94625,
          369451,
          370265.85375,
          375571.5325,
          377563.8875,
          383501.695,
          374629.0875,
          380716.7725,
          379127.57375,
          384914.3875,
          389731.285,
          395880.3325,
          390352.85,
          390477.125,
          389198.7025,
          390096.99,
          392750.96,
          390816.8625,
          380602.72,
          388701.03,
          382362.9375,
          387762.69,
          380411.12,
          387859.995,
          392282.01375,
          394327.0675,
          395678.81375,
          397284.815,
          396569.24,
          386989.57125,
          385041.9675,
          384459.2025,
          390355.8675,
          382485.8375,
          376302.05875,
          379066.7825,
          379628.7425,
          376057.285,
          382252.1,
          392605.095,
          397125.4725,
          390985.0425,
          392639.9575,
          394068.02,
          402112.3875,
          398133.48,
          402967.795,
          408570.645,
          401049.645,
          406509.035,
          411307.2975,
          408430.6625,
          408365.075,
          407980.3475,
          409368.8125,
          409115.4075,
          411221.0625,
          416647.1325,
          421861.9775,
          427845.645,
          429372.8525,
          428870.66,
          431766.13,
          426821.22,
          421536.98,
          419115.08,
          428880.06,
          424486.87,
          428285.15,
          422177.4625,
          422378.7775,
          421504.06,
          423727.1175,
          427270.9875,
          420941.4025,
          428848.335,
          428456.0625,
          423643.165,
          421214.3,
          428260.11,
          430375.14,
          430069.2025,
          431885.4975,
          423558.5625,
          423071.77,
          428158.62,
          435576.8575,
          446504.695,
          455815.7925,
          453058.0925,
          446847.9575,
          449188.21,
          451810.4525,
          459711.175,
          463260.6,
          475773.0075,
          469927.21,
          465512.49,
          468620.605,
          473280.4925,
          463222.62,
          473665.915,
          470229.76,
          468366.8075,
          475340.31,
          475037.585,
          469163.5,
          459640.1225,
          453618.6075,
          466041.1225,
          468897.175,
          458093.9225,
          464488.21,
          458086.9125,
          458553.665,
          462887.36,
          459110.585,
          465490.6,
          481174.6975,
          484513.555,
          466832.03,
          473977.725,
          477752.0975,
          494098.7925,
          504139.35,
          507225.335,
          494204.5775,
          495227.0375,
          492483.36,
          484662.7475,
          478042.1225,
          492317.9325,
          494179.7475,
          492429.23,
          489352.74,
          490681.53,
          502636.37,
          491690.9975,
          502084.03,
          508479.3625,
          502248.215,
          503849.63,
          497227.72,
          495519.925,
          504974.4125,
          497674.4475,
          506079.245,
          491734.0875,
          485927.0375,
          477216.1,
          476828.5475,
          489570.2,
          493236.29,
          498621.2225,
          495629.92,
          497795.275,
          494225.57,
          498139.5175,
          503448.125,
          502313.39,
          494847.04,
          481138.4375,
          470302.2825,
          457645.89,
          465405.0475,
          467222.2675,
          474109.07,
          470059.47,
          469917.64,
          486520.5225,
          480905.2825,
          476970.5675,
          486244.75,
          491754.46,
          485179.1125,
          474528.2225,
          467289.29,
          475540.48,
          482784.01,
          486243.55,
          477094.6925,
          468014.785,
          472277.215,
          478543.33,
          470892.1325,
          463681.89,
          457405.63,
          459471.3975,
          451017.89,
          437513.4425,
          432038.995,
          424238.2675,
          436443.43,
          439014.5475,
          446431.7125,
          439471.72,
          427778.285,
          440605.7775,
          429416.625,
          424031.35,
          428831.505,
          432270.4325,
          424233.5025,
          427605.255,
          414174.7775,
          409519.295,
          383735.475,
          378869.46625,
          371172.64375,
          362289.01,
          357064.3025,
          348720.3275,
          354097.87,
          337228.17875,
          339102.47375,
          333210.305,
          326516.92,
          335076.0725,
          332738.64125,
          336857.98875,
          319610.0975,
          314710.5175,
          317086.01,
          312832.19,
          302184.155,
          298568.3775,
          299021.2575,
          294230.33125,
          293425.47875,
          283465.9225,
          288946.71625,
          284858.4825,
          279134.28125,
          277555.9025,
          278376.36,
          274221.505,
          266332.215,
          270234.5625,
          273935.88,
          267978.5225,
          265965.45875,
          257623.9925,
          255037.765,
          249455.24,
          252310.34125,
          245744.82125,
          247739.74125,
          244211.355,
          237391.0125,
          234485.6275,
          225805.26875,
          228710.57875,
          219817.961875,
          221736.42875,
          220802.244375,
          223294.30125,
          217388.481875,
          210565.30625,
          211444.970625,
          212435.98125,
          206209.1075,
          203608.908125,
          204204.585,
          200059.30875,
          196043.955,
          194867.486875,
          187008.640625,
          182799.0075,
          184286.83625,
          179361.67625,
          173642.5725,
          176499.235,
          172534.344375,
          174184.755,
          171355.121875,
          165802.62,
          163054.0875,
          163209.85,
          161693.8575,
          152206.3975,
          149598.21875,
          146057.05125,
          145083.965,
          143087.543125,
          145087.6090625,
          142967.71,
          144635.0225,
          144441.296875,
          141976.5778125,
          139522.9271875,
          137641.253125,
          139653.995625,
          141033.166875,
          137932.12375,
          135969.70875,
          131137.2640625,
          131428.538125,
          131413.81875,
          132256.360625,
          132626.38875,
          130563.4565625,
          129416.52125,
          128714.403125,
          125939.5075,
          124035.913125,
          122030.8878125,
          121806.10125,
          122223.6825,
          120002.6025,
          120607.2653125,
          120941.0203125,
          120036.821875,
          120058.1925,
          118982.5209375,
          117256.616875,
          116059.405625,
          115349.3515625,
          115483.70625,
          114839.5496875,
          114591.655,
          112955.4809375,
          114197.3525,
          112517.1609375,
          112908.5825,
          111898.916875,
          111242.6878125,
          112113.53625,
          112176.96125,
          113510.16625,
          113081.5684375,
          111793.0903125,
          112054.1790625,
          111754.371875,
          110575.245,
          110379.6846875,
          110527.6078125,
          109848.96,
          109985.2,
          108296.4565625,
          108544.65328125,
          107093.95953125,
          106716.78828125,
          107851.37171875,
          107496.3171875,
          108062.623125,
          105521.27109375,
          105461.9321875,
          105755.5528125,
          105803.43796875,
          106396.916875,
          105659.59625,
          104115.65953125,
          103785.06265625,
          104195.28203125,
          103325.6646875,
          102230.8359375,
          102829.25515625,
          101572.0375,
          100789.5959375,
          101384.17515625,
          101606.844375,
          101495.4253125,
          102839.79859375,
          103671.7734375,
          102559.2309375
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=recon_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "recon_loss",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "recon_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          1.0018123237291972,
          1.003304656346639,
          1.0053319183985392,
          1.0103846375147503,
          1.016711033185323,
          1.015059421857198,
          1.0232942581176758,
          1.028361627260844,
          1.0343375062942506,
          1.058976674079895,
          1.0771565834681194,
          1.0744638872146606,
          1.109225444793701,
          1.1176982164382934,
          1.1244121185938518,
          1.1634951988855997,
          1.18673424243927,
          1.2662236324946086,
          1.198178105354309,
          1.3135628112157185,
          1.3178373908996581,
          1.3465905300776164,
          1.532252271970113,
          1.3932839075724284,
          1.6092873525619507,
          1.6071257654825846,
          1.550710514386495,
          1.7494024515151978,
          1.6959874455134074,
          1.9171500237782797,
          1.7932742134730022,
          1.7722128534317017,
          2.292759339014689,
          2.07513064066569,
          1.770178591410319,
          1.9457634417215983,
          2.2002641057968138,
          3.061612828572591,
          2.401371421813965,
          2.7211166636149087,
          2.148983597755432,
          2.1220368067423503,
          1.850635043780009,
          2.1046574703852334,
          2.2241544103622437,
          2.113907470703125,
          2.268472204208374,
          2.875119164784749,
          2.2853871901830036,
          2.4560109106699626,
          2.5520961395899455,
          2.8881743399302167,
          2.112221490542094,
          1.9940277894337972,
          2.213482693036397,
          2.6131472380956016,
          2.1783329900105795,
          2.4939239692687987,
          1.9344212945302328,
          2.43928440729777,
          2.9080014928181965,
          2.2414039993286132,
          2.369618740081787,
          2.128360810279846,
          3.211953856150309,
          1.9477786906560262,
          1.994489057858785,
          2.1455992110570272,
          1.8023962608973185,
          2.0345617564519247,
          2.0965950314203896,
          1.7787439695994058,
          2.468676231702169,
          1.7262297137578329,
          2.0642355553309124,
          1.8474533224105836,
          2.244308042526245,
          1.6908942461013794,
          1.664009067217509,
          1.520259475708008,
          1.8727891937891643,
          2.1496932729085287,
          1.8966597445805868,
          1.5609417486190795,
          1.85794850508372,
          1.4926365264256796,
          1.5322104358673097,
          2.2753839047749835,
          1.573660626411438,
          1.4402039861679077,
          1.974876586596171,
          1.6130459213256836,
          1.6266579453150432,
          1.600441320737203,
          1.6764291143417358,
          1.5865979512532553,
          1.9910027154286702,
          1.5862647040685018,
          1.3501376469930013,
          1.6165462191899618,
          1.52122123559316,
          1.6894464492797852,
          1.473812001546224,
          1.3181603717803956,
          1.579620976448059,
          1.4984325949350994,
          1.4424662812550864,
          1.7572960662841797,
          1.862997194925944,
          1.3274989573160807,
          1.3330757554372152,
          2.0201317485173544,
          1.4305493942896526,
          1.3313736995061238,
          1.3282126347223917,
          1.3432260624567667,
          1.3528256543477377,
          1.3879941606521606,
          1.3493482573827107,
          1.421679129600525,
          1.632032036781311,
          1.2570171133677164,
          1.3299811251958211,
          1.4208262761433919,
          1.4611639722188314,
          1.2983481041590372,
          1.4241198476155599,
          1.4511075480779012,
          1.2182835785547892,
          1.3137621259689332,
          1.348138461112976,
          1.5105176862080891,
          1.4095658906300863,
          1.4724366076787312,
          1.2471572033564249,
          1.4032743247350057,
          1.4609157578150431,
          1.249645848274231,
          1.3152746073404948,
          1.3226920890808105,
          1.399929846127828,
          1.4904691282908122,
          1.353994836807251,
          1.278908658027649,
          1.3371936686833699,
          1.242217960357666,
          1.3194915946324666,
          1.2104153251647949,
          1.2422724262873333,
          1.3554713074366251,
          1.218233110109965,
          1.327813048362732,
          1.1917480659484863,
          1.1407500950495402,
          1.2208127625783285,
          1.4041152509053547,
          1.1862511618932088,
          1.2543231280644735,
          1.273485581080119,
          1.2177446826299032,
          1.133096415201823,
          1.3210815540949503,
          1.3665372896194459,
          1.1246863222122192,
          1.1258615255355835,
          1.2311933135986328,
          1.1167399915059408,
          1.2628854497273763,
          1.1436359198888142,
          1.2081425619125366,
          1.2015255610148112,
          1.272629230817159,
          1.1385061836242676,
          1.1985326941808065,
          1.1992361386617025,
          1.09114320119222,
          1.2728884331385295,
          1.2598834403355916,
          1.1507264582316081,
          1.171897136370341,
          1.1919531186421712,
          1.133823431332906,
          1.1743503793080647,
          1.2284527540206909,
          1.215282885233561,
          1.096612949371338,
          1.148078630765279,
          1.1266772349675496,
          1.147491013209025,
          1.0989360443751017,
          1.1065405082702637,
          1.3220515060424805,
          1.1564775896072388,
          1.1052025365829468,
          1.0716199986139934,
          1.1936303027470907,
          1.1277109813690185,
          1.084122166633606,
          1.1281813112894694,
          1.1264104827245076,
          1.1749298620223998,
          1.094189035097758,
          1.2638575919469197,
          1.1118217039108276,
          1.1256346368789674,
          1.1335871267318725,
          1.180653166770935,
          1.0722007131576539,
          1.0896100616455078,
          1.116783553759257,
          1.0652113437652588,
          1.140620985031128,
          1.0867787345250448,
          1.097907191912333,
          1.1552453629175823,
          1.1050169293085734,
          1.0664064645767213,
          1.0951112127304077,
          1.0978598769505818,
          1.0796627616882324,
          1.074550757408142,
          1.101381319363912,
          1.081626148223877,
          1.06285728931427,
          1.0746773354212442,
          1.1631645250320435,
          1.169364579518636,
          1.109111132621765,
          1.0486322275797526,
          1.11810950756073,
          1.0778893327713013,
          1.1193019247055054,
          1.1477027861277262,
          1.1006067927678427,
          1.0592523082097371,
          1.119623401959737,
          1.0741069491704305,
          1.0817058515548705,
          1.070587418874105,
          1.0626938947041829,
          1.1162044191360474,
          1.1097443278630574,
          1.0412404775619506,
          1.063928116162618,
          1.060555879275004,
          1.0437253665924073,
          1.0559845749537151,
          1.1176706234614053,
          1.1029164298375447,
          1.0526378631591797,
          1.0601570796966553,
          1.0495037714640298,
          1.0722762632369995,
          1.1086439736684164,
          1.0430123790105184,
          1.0507507260640463,
          1.0992103974024454,
          1.069022569656372,
          1.0637319040298463,
          1.0587712176640829,
          1.0556617561976116,
          1.0446673758824667,
          1.0817664384841919,
          1.0616847562789917,
          1.0820865631103516,
          1.0729097541173298,
          1.0460772148768107,
          1.0760233243306478,
          1.0717707045873006,
          1.0400140206019084,
          1.0758845043182372,
          1.0490880791346233,
          1.0266028610865274,
          1.0762931458155314,
          1.0431343364715575,
          1.0762349144617716,
          1.052735244433085,
          1.040408158302307,
          1.0168684323628743,
          1.0664438581466675,
          1.0752595520019532,
          1.0378903834025066,
          1.0511369721094768,
          1.0391248528162638,
          1.0312070099512736,
          1.050488847096761,
          1.0404956197738648,
          1.0356480471293132,
          1.0484186601638794,
          1.0350586907068888,
          1.0760233243306478,
          1.0542073901494344,
          1.0224832153320313,
          1.0382483720779419,
          1.0960005776087443,
          1.0306431325276693,
          1.0569319566090902,
          1.022838037808736,
          1.0413114309310914,
          1.025242632230123,
          1.0406319570541382,
          1.0475351333618164,
          1.0329620297749837,
          1.0558923133214315,
          1.0449543253580729,
          1.0178041164080303,
          1.038977281252543,
          1.0411004559199015,
          1.0178144311904906,
          1.067083846728007,
          1.0332594219843547,
          1.0604880984624228,
          1.017471570968628,
          1.0433420038223267,
          1.0252944056193034,
          1.0423455286026,
          1.035608229637146,
          1.0208633915583292,
          1.0351819308598835,
          1.0624654404322307,
          1.0297688055038452,
          1.0746291716893515,
          1.021869174639384,
          1.0237881739934285,
          1.0762026580174764,
          1.0402232631047568,
          1.0171947582562764,
          1.0326502911249797,
          1.044492211341858,
          1.019378784497579,
          1.0146374018987019,
          1.0325228118896483,
          1.026476411819458,
          1.019290428161621,
          1.0277155669530234,
          1.0247529029846192,
          1.0186710850397747,
          1.0182912333806355,
          1.0282625579833984,
          1.0259586191177368,
          1.0155018424987794,
          1.0276987330118814,
          1.024918295542399,
          1.0110419877370198,
          1.0274880647659301,
          1.0166228755315145,
          1.0060552104314169,
          1.0217921749750773,
          1.028634680112203,
          1.0197504806518554,
          1.0278513701756795,
          1.0231341822942097,
          1.012060211499532,
          1.0194782892862955,
          1.0147219530741374,
          1.0145334577560425,
          1.0321825981140136,
          1.0203536717096964,
          1.0124407450358073,
          1.0155919583638509,
          1.017011742591858,
          1.0148975038528443,
          1.021877408027649,
          1.0133847920099894,
          1.0131913455327353,
          1.0086467266082764,
          1.0153937673568725,
          1.0169483709335327,
          1.0187568871180217,
          1.0096015850702922,
          1.028637440999349,
          1.0099569702148437,
          1.0127827008565267,
          1.0132437872886657,
          1.0111823018391928,
          1.0207191610336304,
          1.0095619336764017,
          1.015276673634847,
          1.0061139035224915,
          1.007409389813741,
          1.0139813645680746,
          1.0238348404566446,
          1.010946749051412,
          1.0073897568384806,
          1.0171562973658244,
          1.0085713704427084,
          1.013527414004008,
          1.0108771340052287,
          1.008955101966858,
          1.0103657261530559,
          1.0068717432022094,
          1.0121526845296225,
          1.0066641362508137,
          1.0060600678126017,
          1.0064082447687785,
          1.0079328028361003,
          1.0100821812947591,
          1.0439575465520223,
          1.0034444220860799,
          1.0091927671432495,
          1.0022195108731589,
          1.0080893198649088,
          1.007293070157369,
          1.0074753936131795,
          1.0062033478418986,
          1.0128134576479595,
          1.0025691143671671,
          1.005675102074941,
          1.0101130549112955,
          1.0093331416447957,
          1.0058326387405396,
          1.0137445624669392,
          1.0037314128875732,
          1.0052680317560831,
          1.0112935654322306,
          1.0038550074895223,
          1.0044061501820882,
          1.00315256913503,
          1.0059109942118327,
          1.0036146720250447,
          1.0079308692614237,
          1.021438577969869,
          1.0017059191068014,
          1.0018766665458678,
          1.00293949286143,
          1.004926426410675,
          1.0044375816980997,
          1.0065308427810669,
          1.0048353854815166,
          1.0059688329696654,
          1.0053224118550619,
          1.0033798869450887,
          1.0025357866287232,
          1.0223741579055785,
          1.002440505027771,
          1.000591552257538,
          1.0051464986801149,
          1.0050849032402038,
          1.0033970499038696,
          1.0049573771158855,
          1.0011096890767415,
          1.0044868596394856,
          1.005505739847819,
          1.003774298032125,
          1.0133200240135194,
          1.0023959875106812,
          1.000894292195638,
          1.0030329751968383,
          1.002426085472107,
          1.0031044181187947,
          1.0049182812372843,
          1.0036626609166464,
          1.0014933466911315,
          1.0051095263163248,
          1.0039329139391582,
          1.002268794377645,
          1.0027522150675456,
          1.0015783055623373,
          1.0017054732640585,
          1.0065495729446412,
          1.0005774195988972,
          1.00207545598348,
          1.0034753545125326,
          1.0013779346148173,
          1.002889769077301,
          1.0019504563013713,
          1.0052021678288778,
          1.0017729981740315,
          1.0015148321787517,
          1.0018551715215047,
          1.0033274221420287,
          1.001141935189565,
          1.0026180529594422,
          1.0013826529184977,
          1.002012505531311,
          1.0054603060086569,
          1.0002565749486287,
          1.0015249427159627,
          1.0006042591730753,
          1.001124882698059,
          1.0091040555636088,
          1.0013444630304973,
          1.0006247806549071,
          1.000736382007599,
          1.0013016263643901,
          1.0042116912206014,
          1.0022573781013489,
          1.000708139737447,
          1.0011969550450643,
          1.0018997367223104,
          1.0029502868652345,
          1.0013491789499918,
          1.0012460724512735,
          1.0000817211469015,
          1.005872786839803,
          1.0014879592259724,
          1.0011688248316446,
          1.0008786598841348,
          1.000567025343577,
          1.001623566945394
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=val_recon_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "val_recon_loss",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "val_recon_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          1.2337059879302978,
          1.351860704421997,
          2.1147008895874024,
          1.3753893756866455,
          1.2383141040802002,
          1.6148395442962646,
          1.318017644882202,
          1.1955583572387696,
          1.3171578121185303,
          1.9878275299072266,
          1.436251540184021,
          1.6077058601379395,
          1.6762568187713622,
          1.6032749938964843,
          1.8837822675704956,
          1.6079079389572144,
          1.987519383430481,
          2.2346076202392577,
          1.841640625,
          5.9502565383911135,
          1.604234881401062,
          2.324268946647644,
          1.5800415420532226,
          4.662978954315186,
          5.068653717041015,
          1.9095220565795898,
          1.8523904037475587,
          1.6474079370498658,
          5.769844245910645,
          3.902277317047119,
          3.533078155517578,
          9.719807090759277,
          2.036838970184326,
          1.48722487449646,
          3.0757612419128417,
          3.3029210281372072,
          1.7018096828460694,
          4.013806648254395,
          17.241548538208008,
          24.91314727783203,
          3.392131824493408,
          3.0112252616882325,
          4.855702857971192,
          6.001467742919922,
          2.0852801609039306,
          6.051631889343262,
          9.031329002380371,
          1.483343348503113,
          4.016885795593262,
          15.350895080566406,
          1.2743608903884889,
          9.437051277160645,
          2.4276537895202637,
          40.839032592773435,
          2.6318348693847655,
          1.4079161834716798,
          2.6692386627197267,
          1.4188440084457397,
          8.820275993347169,
          2.527434673309326,
          2.6792518424987795,
          1.7511374950408936,
          3.6309232330322265,
          1.7490560054779052,
          2.9783936500549317,
          2.2287883377075195,
          7.0678855895996096,
          1.6065890312194824,
          9.104033241271972,
          7.948270416259765,
          1.2724714088439941,
          21.237639923095703,
          1.7281287288665772,
          1.274966278076172,
          1.96668288230896,
          1.3543755626678466,
          1.239274158477783,
          7.240285530090332,
          2.1362730121612548,
          8.798172569274902,
          1.7398926544189453,
          2.0899105882644653,
          1.316423349380493,
          1.45898184299469,
          1.2827076721191406,
          1.3208981895446776,
          17.447168655395508,
          1.3084768915176392,
          1.1805937671661377,
          30.20754455566406,
          2.3174750328063967,
          1.938747434616089,
          9.222395324707032,
          1.2402731704711913,
          9.921567077636718,
          14.033196105957032,
          8.864989166259766,
          1.2574902725219728,
          1.4680436277389526,
          4.8279489898681645,
          2.981525726318359,
          1.1039827919006349,
          1.1374299716949463,
          1.0584208154678345,
          1.4708377647399902,
          6.002461776733399,
          2.1359269428253174,
          1.035488338470459,
          1.510922622680664,
          3.1804618072509765,
          1.03621440410614,
          1.4882991981506348,
          2.217812156677246,
          2.0529188346862792,
          2.959724884033203,
          3.6493047714233398,
          1.393292932510376,
          1.9109116840362548,
          1.9883332824707032,
          6.257832641601563,
          1.3647204971313476,
          2.236134510040283,
          1.0542294216156005,
          1.0284899139404298,
          1.6415095329284668,
          1.0340639162063598,
          8.828513870239258,
          1.1346487951278688,
          2.7167231941223147,
          1.0522261714935304,
          1.3047537231445312,
          1.4886252546310426,
          1.2279762506484986,
          1.9224636268615722,
          1.3929312229156494,
          1.4233519792556764,
          1.0560636711120606,
          1.1117384243011474,
          1.565991439819336,
          1.1256812763214112,
          3.46769474029541,
          5.986996212005615,
          1.0522323560714721,
          1.1884663105010986,
          1.9783748054504395,
          7.889948348999024,
          1.1865385675430298,
          2.182544288635254,
          1.2637126922607422,
          1.152826156616211,
          7.692971687316895,
          1.8619212436676025,
          2.637457904815674,
          1.3003139972686768,
          1.1542641735076904,
          1.2419838905334473,
          1.414037218093872,
          1.2540254497528076,
          1.0191392993927002,
          1.0722520923614502,
          1.6055418872833251,
          1.0167535734176636,
          1.0979012870788574,
          1.4523973178863525,
          1.2947398376464845,
          1.1701583671569824,
          1.1956205368041992,
          1.0451800966262816,
          1.2100801944732666,
          1.3739887619018554,
          1.2164685869216918,
          1.3727094650268554,
          2.280867156982422,
          1.0378672122955321,
          1.0674857473373414,
          1.9997471237182618,
          1.315582447052002,
          1.0481225442886353,
          1.211552963256836,
          1.074147720336914,
          1.9910062789916991,
          1.0400086069107055,
          3.005900115966797,
          1.0973902416229249,
          1.0448845863342284,
          1.368344464302063,
          1.2367728710174561,
          1.031317310333252,
          1.011183605194092,
          1.0558496952056884,
          1.8804392337799072,
          1.0426850891113282,
          2.1403662967681885,
          1.1678048133850099,
          1.0757290458679198,
          1.4745420837402343,
          1.023762083053589,
          1.1727228736877442,
          1.0439020633697509,
          1.427834119796753,
          1.0944486665725708,
          2.247328176498413,
          1.0202442073822022,
          1.1445230293273925,
          1.0131053161621093,
          1.1040719890594481,
          1.1832856559753417,
          1.4604202842712402,
          1.400449161529541,
          1.2381614542007446,
          1.0610303592681884,
          1.0534148693084717,
          1.105573673248291,
          1.0899804401397706,
          1.0307969331741333,
          1.1028665113449097,
          1.0599782466888428,
          1.32148334980011,
          1.0717354202270508,
          1.0105808210372924,
          1.0268258571624755,
          1.093325242996216,
          1.0116553688049317,
          1.0430340099334716,
          1.2827282905578614,
          1.2372526741027832,
          1.2947565746307372,
          1.3826547145843506,
          1.5489255714416503,
          1.0566956520080566,
          2.1706556701660156,
          1.0565180110931396,
          1.050298914909363,
          1.1069781875610352,
          1.078271918296814,
          1.103220453262329,
          1.1750861263275147,
          1.1021334075927733,
          1.069052391052246,
          2.751678981781006,
          1.0749610900878905,
          1.0954022026062011,
          1.147005729675293,
          1.0363916873931884,
          1.04213716506958,
          1.0749409866333008,
          1.522903652191162,
          1.0437063407897949,
          1.0823213291168212,
          1.0260074377059936,
          1.053489933013916,
          1.1763527059555055,
          1.8152790594100952,
          1.0173767232894897,
          1.056299557685852,
          1.2541464519500733,
          1.1356927013397218,
          1.371361346244812,
          1.0614874458312988,
          1.0249743556976318,
          1.073734664916992,
          1.196395263671875,
          1.7817879676818849,
          1.6501505756378174,
          1.1632560443878175,
          1.0673101711273194,
          1.076441617012024,
          1.0083374929428102,
          1.018678731918335,
          1.210297884941101,
          1.1409063148498535,
          1.0118184089660645,
          1.0602752208709716,
          1.421940622329712,
          1.190887303352356,
          1.0985053300857544,
          1.3590153026580811,
          1.0250185489654542,
          1.1583401775360107,
          1.0536903047561645,
          1.035127830505371,
          1.0241227054595947,
          1.0212639665603638,
          1.1018453550338745,
          1.0399214839935302,
          1.0399200105667115,
          1.015111255645752,
          1.1489267778396606,
          1.0111666107177735,
          1.0724574184417726,
          1.0191726779937744,
          1.658737154006958,
          1.109180784225464,
          1.3540647220611572,
          1.395344443321228,
          1.0370122766494752,
          1.0276365280151367,
          1.3757623386383058,
          1.079363799095154,
          1.05715238571167,
          1.2879318714141845,
          1.1032186317443848,
          1.1986987066268922,
          1.0611519527435302,
          1.0356716632843017,
          1.0503517246246339,
          1.0317685651779174,
          1.1964571046829224,
          1.0641998958587646,
          1.128982000350952,
          1.1219400787353515,
          1.0984999656677246,
          1.2894544506072998,
          1.0469770908355713,
          1.0318370532989503,
          1.0177626562118531,
          1.1369265937805175,
          1.0963188695907593,
          1.285557460784912,
          1.5822120094299317,
          1.042633581161499,
          1.0268170261383056,
          1.0691972732543946,
          1.6276996898651124,
          1.028466033935547,
          1.0045975208282472,
          1.0118612813949586,
          1.0919570922851562,
          1.028628797531128,
          1.0243056964874269,
          1.043986005783081,
          1.030335454940796,
          1.0355054998397828,
          1.015088963508606,
          1.0720751571655274,
          1.0368337726593018,
          1.0474043273925782,
          1.027946481704712,
          1.0163734579086303,
          1.1846213912963868,
          1.0325249195098878,
          1.0143491506576539,
          1.0296315479278564,
          1.035069899559021,
          1.0703010749816895,
          1.0463373947143555,
          1.0323468589782714,
          1.0046512293815613,
          1.0172923946380614,
          1.0667387199401857,
          1.0108306550979613,
          1.0101791906356812,
          1.019277958869934,
          1.0272976779937744,
          1.0441314029693602,
          1.0669099378585816,
          1.0063304448127746,
          1.0507357358932494,
          1.0152488088607787,
          1.170951428413391,
          1.0098418283462525,
          1.0235236740112306,
          1.0508129930496215,
          1.0238651752471923,
          1.0217947483062744,
          1.01619056224823,
          1.1013114738464356,
          1.0640755891799927,
          1.0222858572006226,
          1.0288868999481202,
          1.0029280042648316,
          1.026583695411682,
          1.0292675876617432,
          1.012386784553528,
          1.0460708141326904,
          1.0149144077301024,
          1.0136861038208007,
          1.020612087249756,
          1.0165778875350953,
          1.0068195056915283,
          1.0081549286842346,
          1.1192541933059692,
          1.0097184133529664,
          1.034395875930786,
          1.0488876342773437,
          1.0101396942138672,
          1.0758126258850098,
          1.0046488857269287,
          1.2939218378067017,
          1.0372891330718994,
          1.016770362854004,
          1.008133089542389,
          1.0135618400573732,
          1.0200325870513915,
          1.058579626083374,
          1.0046802902221679,
          1.1976180744171143,
          1.0090403938293457,
          1.0040880250930786,
          1.0034234237670898,
          1.0018401288986205,
          1.0089520883560181,
          1.0047426557540893,
          1.0027854442596436,
          1.0086460399627686,
          1.0036383008956908,
          1.00540048122406,
          1.0108539295196532,
          1.0386959552764892,
          1.0042317867279054,
          1.0145358657836914,
          1.0064992904663086,
          1.0044375085830688,
          1.0024816942214967,
          1.0023614358901978,
          1.0018457460403443,
          1.0175482797622681,
          1.0131600666046143,
          1.0027410554885865,
          1.0028425097465514,
          1.0035423803329468,
          1.002422914505005,
          1.0024130368232727,
          1.0108944797515869,
          1.006398811340332,
          1.0021292209625243,
          1.002343280315399,
          1.0058364152908326,
          1.0016207218170166,
          1.0096968388557435,
          1.0164080142974854,
          1.0035836029052734,
          1.002118434906006,
          1.0026568102836608,
          1.0023075437545776,
          1.0032167863845824,
          1.0033591032028197,
          1.0082529282569885,
          1.00422523021698,
          1.0039510822296143,
          1.0068277215957642,
          1.0018639826774598,
          1.0022277927398682,
          1.017229356765747,
          1.0031101322174072,
          1.0032340455055238,
          1.0035261273384095,
          1.0029013013839723,
          1.00275616645813,
          1.0025159072875978,
          1.0046085166931151,
          1.0024315309524536,
          1.002711615562439,
          1.0054818081855774,
          1.0022451043128968,
          1.0037910985946654,
          1.0020897817611694,
          1.0008541107177735,
          1.0042992734909058,
          1.0022249174118043,
          1.0051906275749207,
          1.0021887135505676,
          1.0029455041885376,
          1.0082605576515198,
          1.0039876675605774,
          1.0024639749526978,
          1.0053273439407349,
          1.0027395296096802,
          1.0034658765792848,
          1.0038640546798705,
          1.0038644170761108,
          1.0027201533317567,
          1.002546935081482,
          1.0014220929145814,
          1.026542854309082,
          1.0021476340293884,
          1.0026519060134889,
          1.0010050916671753,
          1.0039014840126037,
          1.0018774104118346,
          1.0044149780273437,
          1.003888294696808,
          1.0029110932350158,
          1.0049693584442139,
          1.0026109218597412,
          1.0023835849761964,
          1.0030423593521118,
          1.002703537940979,
          1.0017071461677551,
          1.0062618684768676,
          1.0021249198913573,
          1.0025527095794677,
          1.0017896461486817,
          1.0024833154678345,
          1.005805130004883,
          1.003143038749695,
          1.0039395785331726,
          1.0028084874153138,
          1.0025823163986205,
          1.0030936670303345
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "step"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "loss_value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(plot_df_long, x=\"step\", y=\"loss_value\", color=\"type\", markers=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "And now I'll evaluate the model on train, valid, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 127814.26083333333\n",
      "valid MSE: 102559.2309375\n",
      "test MSE:  131554.17875\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train MSE:\",\n",
    "    model.evaluate(X_train, {\"recon\": X_train, \"reg_output\": y_train}, verbose=0)[4],\n",
    ")\n",
    "print(\n",
    "    \"valid MSE:\",\n",
    "    model.evaluate(X_valid, {\"recon\": X_valid, \"reg_output\": y_valid}, verbose=0)[4],\n",
    ")\n",
    "print(\n",
    "    \"test MSE: \",\n",
    "    model.evaluate(X_test, {\"recon\": X_test, \"reg_output\": y_test}, verbose=0)[4],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsnet-mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
