{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this notebook is to run an example experiment using the functions from `fsnet-tools.py` to illustrate it's intended use.\n",
    "\n",
    "# Data\n",
    "\n",
    "A wide toy dataset will be generated using `make_regression` from `sklearn`.  I'll then split off a test dataset, standardize, and split off a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# generate example regression dataset\n",
    "X, y = make_regression(n_samples=500, n_features=4000, n_informative=25)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape - X: (300, 4000) , y: (300,)\n",
      "valid shape - X: (100, 4000) , y: (100,)\n",
      "test shape - X: (100, 4000) , y: (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full_scaled, y_train_full)\n",
    "\n",
    "print(\"train shape - X:\", X_train.shape, \", y:\", y_train.shape)\n",
    "print(\"valid shape - X:\", X_valid.shape, \", y:\", y_valid.shape)\n",
    "print(\"test shape - X:\", X_test.shape, \", y:\", y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "Now I'll build the model using the newly created `fsnet-tools`.  `u_train` and `alpha` should be generated first, using the respective functions.  They will only need to be regenerated if `X_train` changes.  This is important to note, say, inside a cross-fold validation experiment.  \n",
    "\n",
    "It's also important that hyperparameters match between the various function calls.  Here, I'm defining a hyperparameter dictionary, as this is consistent with my typical model experiment workflow.  This method also lends itself well to hyperparameter tuning via optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fsnet_tools import get_utrain\n",
    "from fsnet_tools import get_alpha\n",
    "from fsnet_tools import build_model\n",
    "\n",
    "hps = {\n",
    "    \"bins\": 10,\n",
    "    \"min_temp\": 0.01,\n",
    "    \"start_temp\": 10.0,\n",
    "    \"num_epochs\": 500,\n",
    "    \"nfeat\": 50,\n",
    "    \"h_size\": 16,\n",
    "    \"batch_size\": 8,\n",
    "}\n",
    "\n",
    "u_train = get_utrain(X_train, bins=hps[\"bins\"])\n",
    "alpha = get_alpha(\n",
    "    X_train,\n",
    "    batch_size=hps[\"batch_size\"],\n",
    "    min_temp=hps[\"min_temp\"],\n",
    "    start_temp=hps[\"start_temp\"],\n",
    "    num_epochs=hps[\"num_epochs\"],\n",
    ")\n",
    "model = build_model(\n",
    "    num_inputs=X_train.shape[1],\n",
    "    nfeat=hps[\"nfeat\"],\n",
    "    u_train=u_train,\n",
    "    alpha=alpha,\n",
    "    h_size=hps[\"h_size\"],\n",
    "    bins=hps[\"bins\"],\n",
    "    start_temp=hps[\"start_temp\"],\n",
    "    min_temp=hps[\"min_temp\"],\n",
    "    num_epochs=hps[\"num_epochs\"],\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit\n",
    "\n",
    "Now I'll fit the data with the model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\Python\\Miniconda\\envs\\fsnet-mod\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/500\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 76779.0384 - recon_loss: 1.0019 - reg_output_loss: 76678.8515 - recon_mean_squared_error: 1.0019 - reg_output_mean_squared_error: 76678.8515 - val_loss: 72269.7255 - val_recon_loss: 1.3152 - val_reg_output_loss: 72138.2033 - val_recon_mean_squared_error: 1.3152 - val_reg_output_mean_squared_error: 72138.2033\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 76777.4465 - recon_loss: 1.0006 - reg_output_loss: 76677.3894 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 76677.3894 - val_loss: 72264.1503 - val_recon_loss: 1.2738 - val_reg_output_loss: 72136.7686 - val_recon_mean_squared_error: 1.2738 - val_reg_output_mean_squared_error: 72136.7686\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 76776.6076 - recon_loss: 1.0003 - reg_output_loss: 76676.5806 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 76676.5806 - val_loss: 72285.3728 - val_recon_loss: 1.5677 - val_reg_output_loss: 72128.5995 - val_recon_mean_squared_error: 1.5677 - val_reg_output_mean_squared_error: 72128.5995\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 633us/step - loss: 76777.9377 - recon_loss: 1.0002 - reg_output_loss: 76677.9201 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 76677.9201 - val_loss: 72272.1712 - val_recon_loss: 1.4180 - val_reg_output_loss: 72130.3741 - val_recon_mean_squared_error: 1.4180 - val_reg_output_mean_squared_error: 72130.3741\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 623us/step - loss: 76775.8735 - recon_loss: 1.0002 - reg_output_loss: 76675.8520 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 76675.8520 - val_loss: 72267.6459 - val_recon_loss: 1.3027 - val_reg_output_loss: 72137.3759 - val_recon_mean_squared_error: 1.3027 - val_reg_output_mean_squared_error: 72137.3759\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 0s 627us/step - loss: 76771.5942 - recon_loss: 1.0006 - reg_output_loss: 76671.5316 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 76671.5316 - val_loss: 72251.4878 - val_recon_loss: 1.1928 - val_reg_output_loss: 72132.2106 - val_recon_mean_squared_error: 1.1928 - val_reg_output_mean_squared_error: 72132.2106\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 620us/step - loss: 76762.8437 - recon_loss: 1.0009 - reg_output_loss: 76662.7574 - recon_mean_squared_error: 1.0009 - reg_output_mean_squared_error: 76662.7574 - val_loss: 72259.7219 - val_recon_loss: 1.2130 - val_reg_output_loss: 72138.4205 - val_recon_mean_squared_error: 1.2130 - val_reg_output_mean_squared_error: 72138.4205\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 76766.2069 - recon_loss: 1.0027 - reg_output_loss: 76665.9397 - recon_mean_squared_error: 1.0027 - reg_output_mean_squared_error: 76665.9397 - val_loss: 72262.0819 - val_recon_loss: 1.1859 - val_reg_output_loss: 72143.4950 - val_recon_mean_squared_error: 1.1859 - val_reg_output_mean_squared_error: 72143.4950\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 76768.7466 - recon_loss: 1.0012 - reg_output_loss: 76668.6308 - recon_mean_squared_error: 1.0012 - reg_output_mean_squared_error: 76668.6308 - val_loss: 72275.3491 - val_recon_loss: 1.2339 - val_reg_output_loss: 72151.9563 - val_recon_mean_squared_error: 1.2339 - val_reg_output_mean_squared_error: 72151.9563\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 76773.1290 - recon_loss: 1.0013 - reg_output_loss: 76672.9945 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 76672.9945 - val_loss: 72268.8658 - val_recon_loss: 1.1360 - val_reg_output_loss: 72155.2631 - val_recon_mean_squared_error: 1.1360 - val_reg_output_mean_squared_error: 72155.2631\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 76760.5305 - recon_loss: 1.0008 - reg_output_loss: 76660.4518 - recon_mean_squared_error: 1.0008 - reg_output_mean_squared_error: 76660.4518 - val_loss: 72272.9405 - val_recon_loss: 1.1739 - val_reg_output_loss: 72155.5466 - val_recon_mean_squared_error: 1.1739 - val_reg_output_mean_squared_error: 72155.5466\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 76747.0732 - recon_loss: 1.0021 - reg_output_loss: 76646.8672 - recon_mean_squared_error: 1.0021 - reg_output_mean_squared_error: 76646.8672 - val_loss: 72287.3737 - val_recon_loss: 1.2949 - val_reg_output_loss: 72157.8878 - val_recon_mean_squared_error: 1.2949 - val_reg_output_mean_squared_error: 72157.8878\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 76741.7616 - recon_loss: 1.0015 - reg_output_loss: 76641.6084 - recon_mean_squared_error: 1.0015 - reg_output_mean_squared_error: 76641.6084 - val_loss: 72295.6767 - val_recon_loss: 1.4069 - val_reg_output_loss: 72154.9883 - val_recon_mean_squared_error: 1.4069 - val_reg_output_mean_squared_error: 72154.9883\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 76749.6240 - recon_loss: 1.0024 - reg_output_loss: 76649.3800 - recon_mean_squared_error: 1.0024 - reg_output_mean_squared_error: 76649.3800 - val_loss: 72284.8275 - val_recon_loss: 1.2145 - val_reg_output_loss: 72163.3734 - val_recon_mean_squared_error: 1.2145 - val_reg_output_mean_squared_error: 72163.3734\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 76730.4444 - recon_loss: 1.0025 - reg_output_loss: 76630.1933 - recon_mean_squared_error: 1.0025 - reg_output_mean_squared_error: 76630.1933 - val_loss: 72278.9991 - val_recon_loss: 1.0997 - val_reg_output_loss: 72169.0320 - val_recon_mean_squared_error: 1.0997 - val_reg_output_mean_squared_error: 72169.0320\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 76724.8108 - recon_loss: 1.0028 - reg_output_loss: 76624.5268 - recon_mean_squared_error: 1.0028 - reg_output_mean_squared_error: 76624.5268 - val_loss: 72285.7044 - val_recon_loss: 1.1745 - val_reg_output_loss: 72168.2566 - val_recon_mean_squared_error: 1.1745 - val_reg_output_mean_squared_error: 72168.2566\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 76714.4866 - recon_loss: 1.0041 - reg_output_loss: 76614.0797 - recon_mean_squared_error: 1.0041 - reg_output_mean_squared_error: 76614.0797 - val_loss: 72317.2889 - val_recon_loss: 1.1499 - val_reg_output_loss: 72202.2991 - val_recon_mean_squared_error: 1.1499 - val_reg_output_mean_squared_error: 72202.2991\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 76701.3132 - recon_loss: 1.0045 - reg_output_loss: 76600.8628 - recon_mean_squared_error: 1.0045 - reg_output_mean_squared_error: 76600.8628 - val_loss: 72355.0194 - val_recon_loss: 1.3386 - val_reg_output_loss: 72221.1569 - val_recon_mean_squared_error: 1.3386 - val_reg_output_mean_squared_error: 72221.1569\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 76722.0511 - recon_loss: 1.0101 - reg_output_loss: 76621.0436 - recon_mean_squared_error: 1.0101 - reg_output_mean_squared_error: 76621.0436 - val_loss: 72314.0097 - val_recon_loss: 1.1472 - val_reg_output_loss: 72199.2858 - val_recon_mean_squared_error: 1.1472 - val_reg_output_mean_squared_error: 72199.2858\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 76714.1505 - recon_loss: 1.0096 - reg_output_loss: 76613.1948 - recon_mean_squared_error: 1.0096 - reg_output_mean_squared_error: 76613.1948 - val_loss: 72326.5036 - val_recon_loss: 1.1352 - val_reg_output_loss: 72212.9825 - val_recon_mean_squared_error: 1.1352 - val_reg_output_mean_squared_error: 72212.9825\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 76670.3055 - recon_loss: 1.0049 - reg_output_loss: 76569.8156 - recon_mean_squared_error: 1.0049 - reg_output_mean_squared_error: 76569.8156 - val_loss: 72354.8286 - val_recon_loss: 1.1209 - val_reg_output_loss: 72242.7409 - val_recon_mean_squared_error: 1.1209 - val_reg_output_mean_squared_error: 72242.7409\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 76655.8476 - recon_loss: 1.0104 - reg_output_loss: 76554.8106 - recon_mean_squared_error: 1.0104 - reg_output_mean_squared_error: 76554.8106 - val_loss: 72433.2859 - val_recon_loss: 1.3763 - val_reg_output_loss: 72295.6580 - val_recon_mean_squared_error: 1.3763 - val_reg_output_mean_squared_error: 72295.6580\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 76548.6596 - recon_loss: 1.0093 - reg_output_loss: 76447.7325 - recon_mean_squared_error: 1.0093 - reg_output_mean_squared_error: 76447.7325 - val_loss: 72556.4878 - val_recon_loss: 1.5759 - val_reg_output_loss: 72398.8956 - val_recon_mean_squared_error: 1.5759 - val_reg_output_mean_squared_error: 72398.8956\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 76500.4194 - recon_loss: 1.0196 - reg_output_loss: 76398.4565 - recon_mean_squared_error: 1.0196 - reg_output_mean_squared_error: 76398.4565 - val_loss: 72875.0200 - val_recon_loss: 3.2777 - val_reg_output_loss: 72547.2495 - val_recon_mean_squared_error: 3.2777 - val_reg_output_mean_squared_error: 72547.2495\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 76418.1967 - recon_loss: 1.0250 - reg_output_loss: 76315.6993 - recon_mean_squared_error: 1.0250 - reg_output_mean_squared_error: 76315.6993 - val_loss: 73007.1522 - val_recon_loss: 1.6604 - val_reg_output_loss: 72841.1097 - val_recon_mean_squared_error: 1.6604 - val_reg_output_mean_squared_error: 72841.1097\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 76554.0782 - recon_loss: 1.0238 - reg_output_loss: 76451.6976 - recon_mean_squared_error: 1.0238 - reg_output_mean_squared_error: 76451.6976 - val_loss: 73205.3464 - val_recon_loss: 1.5420 - val_reg_output_loss: 73051.1483 - val_recon_mean_squared_error: 1.5420 - val_reg_output_mean_squared_error: 73051.1483\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 76323.6044 - recon_loss: 1.0861 - reg_output_loss: 76214.9939 - recon_mean_squared_error: 1.0861 - reg_output_mean_squared_error: 76214.9939 - val_loss: 73595.8819 - val_recon_loss: 1.7360 - val_reg_output_loss: 73422.2802 - val_recon_mean_squared_error: 1.7360 - val_reg_output_mean_squared_error: 73422.2802\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 76439.8045 - recon_loss: 1.0382 - reg_output_loss: 76335.9791 - recon_mean_squared_error: 1.0382 - reg_output_mean_squared_error: 76335.9791 - val_loss: 74095.8813 - val_recon_loss: 1.8181 - val_reg_output_loss: 73914.0752 - val_recon_mean_squared_error: 1.8181 - val_reg_output_mean_squared_error: 73914.0752\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 76280.2070 - recon_loss: 1.0891 - reg_output_loss: 76171.2988 - recon_mean_squared_error: 1.0891 - reg_output_mean_squared_error: 76171.2988 - val_loss: 74995.6880 - val_recon_loss: 2.4743 - val_reg_output_loss: 74748.2578 - val_recon_mean_squared_error: 2.4743 - val_reg_output_mean_squared_error: 74748.2578\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 76063.2991 - recon_loss: 1.1347 - reg_output_loss: 75949.8310 - recon_mean_squared_error: 1.1347 - reg_output_mean_squared_error: 75949.8310 - val_loss: 76866.0175 - val_recon_loss: 9.5572 - val_reg_output_loss: 75910.2972 - val_recon_mean_squared_error: 9.5572 - val_reg_output_mean_squared_error: 75910.2972\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 76019.6489 - recon_loss: 1.0845 - reg_output_loss: 75911.2034 - recon_mean_squared_error: 1.0845 - reg_output_mean_squared_error: 75911.2034 - val_loss: 78347.2330 - val_recon_loss: 13.5451 - val_reg_output_loss: 76992.7281 - val_recon_mean_squared_error: 13.5451 - val_reg_output_mean_squared_error: 76992.7281\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 75973.1703 - recon_loss: 1.1569 - reg_output_loss: 75857.4832 - recon_mean_squared_error: 1.1569 - reg_output_mean_squared_error: 75857.4832 - val_loss: 79661.9830 - val_recon_loss: 12.0662 - val_reg_output_loss: 78455.3616 - val_recon_mean_squared_error: 12.0662 - val_reg_output_mean_squared_error: 78455.3616\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 75779.9924 - recon_loss: 1.1037 - reg_output_loss: 75669.6227 - recon_mean_squared_error: 1.1037 - reg_output_mean_squared_error: 75669.6227 - val_loss: 80400.5827 - val_recon_loss: 2.2225 - val_reg_output_loss: 80178.3306 - val_recon_mean_squared_error: 2.2225 - val_reg_output_mean_squared_error: 80178.3306\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 75821.8666 - recon_loss: 1.1627 - reg_output_loss: 75705.6007 - recon_mean_squared_error: 1.1627 - reg_output_mean_squared_error: 75705.6007 - val_loss: 82166.9937 - val_recon_loss: 3.0811 - val_reg_output_loss: 81858.8828 - val_recon_mean_squared_error: 3.0811 - val_reg_output_mean_squared_error: 81858.8828\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 75334.0789 - recon_loss: 1.1032 - reg_output_loss: 75223.7593 - recon_mean_squared_error: 1.1032 - reg_output_mean_squared_error: 75223.7593 - val_loss: 84984.2973 - val_recon_loss: 3.9613 - val_reg_output_loss: 84588.1627 - val_recon_mean_squared_error: 3.9613 - val_reg_output_mean_squared_error: 84588.1627\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 75301.0112 - recon_loss: 1.5435 - reg_output_loss: 75146.6619 - recon_mean_squared_error: 1.5435 - reg_output_mean_squared_error: 75146.6619 - val_loss: 89804.8941 - val_recon_loss: 20.5169 - val_reg_output_loss: 87753.2025 - val_recon_mean_squared_error: 20.5169 - val_reg_output_mean_squared_error: 87753.2025\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 75474.6687 - recon_loss: 1.1807 - reg_output_loss: 75356.5996 - recon_mean_squared_error: 1.1807 - reg_output_mean_squared_error: 75356.5996 - val_loss: 90550.4234 - val_recon_loss: 6.2902 - val_reg_output_loss: 89921.3994 - val_recon_mean_squared_error: 6.2902 - val_reg_output_mean_squared_error: 89921.3994\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 75072.9106 - recon_loss: 1.2020 - reg_output_loss: 74952.7093 - recon_mean_squared_error: 1.2020 - reg_output_mean_squared_error: 74952.7093 - val_loss: 95681.6947 - val_recon_loss: 4.2852 - val_reg_output_loss: 95253.1756 - val_recon_mean_squared_error: 4.2852 - val_reg_output_mean_squared_error: 95253.1756\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 75059.0901 - recon_loss: 1.2230 - reg_output_loss: 74936.7852 - recon_mean_squared_error: 1.2230 - reg_output_mean_squared_error: 74936.7852 - val_loss: 100102.0072 - val_recon_loss: 2.5795 - val_reg_output_loss: 99844.0566 - val_recon_mean_squared_error: 2.5795 - val_reg_output_mean_squared_error: 99844.0566\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 74626.4347 - recon_loss: 1.2711 - reg_output_loss: 74499.3246 - recon_mean_squared_error: 1.2711 - reg_output_mean_squared_error: 74499.3246 - val_loss: 104434.8447 - val_recon_loss: 3.8221 - val_reg_output_loss: 104052.6359 - val_recon_mean_squared_error: 3.8221 - val_reg_output_mean_squared_error: 104052.6359\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 74931.1981 - recon_loss: 1.2944 - reg_output_loss: 74801.7569 - recon_mean_squared_error: 1.2944 - reg_output_mean_squared_error: 74801.7569 - val_loss: 107447.1734 - val_recon_loss: 5.6487 - val_reg_output_loss: 106882.3072 - val_recon_mean_squared_error: 5.6487 - val_reg_output_mean_squared_error: 106882.3072\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 737us/step - loss: 74573.9283 - recon_loss: 1.6533 - reg_output_loss: 74408.5957 - recon_mean_squared_error: 1.6533 - reg_output_mean_squared_error: 74408.5957 - val_loss: 111957.0412 - val_recon_loss: 2.2560 - val_reg_output_loss: 111731.4453 - val_recon_mean_squared_error: 2.2560 - val_reg_output_mean_squared_error: 111731.4453\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 74486.7696 - recon_loss: 1.4448 - reg_output_loss: 74342.2907 - recon_mean_squared_error: 1.4448 - reg_output_mean_squared_error: 74342.2907 - val_loss: 117698.1837 - val_recon_loss: 3.5031 - val_reg_output_loss: 117347.8781 - val_recon_mean_squared_error: 3.5031 - val_reg_output_mean_squared_error: 117347.8781\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 74576.8645 - recon_loss: 1.4481 - reg_output_loss: 74432.0523 - recon_mean_squared_error: 1.4481 - reg_output_mean_squared_error: 74432.0523 - val_loss: 125501.7444 - val_recon_loss: 28.2059 - val_reg_output_loss: 122681.1550 - val_recon_mean_squared_error: 28.2059 - val_reg_output_mean_squared_error: 122681.1550\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 74233.4383 - recon_loss: 1.7566 - reg_output_loss: 74057.7770 - recon_mean_squared_error: 1.7566 - reg_output_mean_squared_error: 74057.7770 - val_loss: 128056.5406 - val_recon_loss: 9.6069 - val_reg_output_loss: 127095.8484 - val_recon_mean_squared_error: 9.6069 - val_reg_output_mean_squared_error: 127095.8484\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 73960.5321 - recon_loss: 1.8335 - reg_output_loss: 73777.1864 - recon_mean_squared_error: 1.8335 - reg_output_mean_squared_error: 73777.1864 - val_loss: 130591.6572 - val_recon_loss: 3.1520 - val_reg_output_loss: 130276.4519 - val_recon_mean_squared_error: 3.1520 - val_reg_output_mean_squared_error: 130276.4519\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 867us/step - loss: 73555.0955 - recon_loss: 1.3728 - reg_output_loss: 73417.8104 - recon_mean_squared_error: 1.3728 - reg_output_mean_squared_error: 73417.8104 - val_loss: 134939.9362 - val_recon_loss: 13.2287 - val_reg_output_loss: 133617.0688 - val_recon_mean_squared_error: 13.2287 - val_reg_output_mean_squared_error: 133617.0688\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 1000us/step - loss: 74009.3506 - recon_loss: 1.3720 - reg_output_loss: 73872.1525 - recon_mean_squared_error: 1.3720 - reg_output_mean_squared_error: 73872.1525 - val_loss: 141854.6231 - val_recon_loss: 37.7032 - val_reg_output_loss: 138084.3009 - val_recon_mean_squared_error: 37.7032 - val_reg_output_mean_squared_error: 138084.3009\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 873us/step - loss: 73257.2776 - recon_loss: 1.4495 - reg_output_loss: 73112.3321 - recon_mean_squared_error: 1.4495 - reg_output_mean_squared_error: 73112.3321 - val_loss: 144963.9894 - val_recon_loss: 5.0576 - val_reg_output_loss: 144458.2253 - val_recon_mean_squared_error: 5.0576 - val_reg_output_mean_squared_error: 144458.2253\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 827us/step - loss: 72504.3954 - recon_loss: 1.4774 - reg_output_loss: 72356.6593 - recon_mean_squared_error: 1.4774 - reg_output_mean_squared_error: 72356.6593 - val_loss: 161458.1047 - val_recon_loss: 3.6102 - val_reg_output_loss: 161097.0850 - val_recon_mean_squared_error: 3.6102 - val_reg_output_mean_squared_error: 161097.0850\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 773us/step - loss: 73240.9507 - recon_loss: 1.6324 - reg_output_loss: 73077.7137 - recon_mean_squared_error: 1.6324 - reg_output_mean_squared_error: 73077.7137 - val_loss: 166954.9272 - val_recon_loss: 10.1843 - val_reg_output_loss: 165936.4966 - val_recon_mean_squared_error: 10.1843 - val_reg_output_mean_squared_error: 165936.4966\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 787us/step - loss: 72902.3179 - recon_loss: 1.4061 - reg_output_loss: 72761.7090 - recon_mean_squared_error: 1.4061 - reg_output_mean_squared_error: 72761.7090 - val_loss: 176599.3416 - val_recon_loss: 14.8124 - val_reg_output_loss: 175118.0997 - val_recon_mean_squared_error: 14.8124 - val_reg_output_mean_squared_error: 175118.0997\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 770us/step - loss: 72312.1074 - recon_loss: 1.5032 - reg_output_loss: 72161.7884 - recon_mean_squared_error: 1.5032 - reg_output_mean_squared_error: 72161.7884 - val_loss: 184628.4763 - val_recon_loss: 9.9733 - val_reg_output_loss: 183631.1500 - val_recon_mean_squared_error: 9.9733 - val_reg_output_mean_squared_error: 183631.1500\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 723us/step - loss: 72794.8970 - recon_loss: 1.6758 - reg_output_loss: 72627.3140 - recon_mean_squared_error: 1.6758 - reg_output_mean_squared_error: 72627.3140 - val_loss: 190064.5559 - val_recon_loss: 3.0658 - val_reg_output_loss: 189757.9731 - val_recon_mean_squared_error: 3.0658 - val_reg_output_mean_squared_error: 189757.9731\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 773us/step - loss: 71738.5660 - recon_loss: 1.4796 - reg_output_loss: 71590.6041 - recon_mean_squared_error: 1.4796 - reg_output_mean_squared_error: 71590.6041 - val_loss: 204464.9531 - val_recon_loss: 11.4201 - val_reg_output_loss: 203322.9469 - val_recon_mean_squared_error: 11.4201 - val_reg_output_mean_squared_error: 203322.9469\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 743us/step - loss: 72628.7699 - recon_loss: 1.8195 - reg_output_loss: 72446.8151 - recon_mean_squared_error: 1.8195 - reg_output_mean_squared_error: 72446.8151 - val_loss: 202438.6819 - val_recon_loss: 8.1824 - val_reg_output_loss: 201620.4356 - val_recon_mean_squared_error: 8.1824 - val_reg_output_mean_squared_error: 201620.4356\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 71674.1770 - recon_loss: 1.7046 - reg_output_loss: 71503.7195 - recon_mean_squared_error: 1.7046 - reg_output_mean_squared_error: 71503.7195 - val_loss: 209503.7513 - val_recon_loss: 2.7934 - val_reg_output_loss: 209224.4081 - val_recon_mean_squared_error: 2.7934 - val_reg_output_mean_squared_error: 209224.4081\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 72096.9080 - recon_loss: 1.8666 - reg_output_loss: 71910.2506 - recon_mean_squared_error: 1.8666 - reg_output_mean_squared_error: 71910.2506 - val_loss: 210998.4769 - val_recon_loss: 2.4692 - val_reg_output_loss: 210751.5606 - val_recon_mean_squared_error: 2.4692 - val_reg_output_mean_squared_error: 210751.5606\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 73023.1710 - recon_loss: 2.1521 - reg_output_loss: 72807.9652 - recon_mean_squared_error: 2.1521 - reg_output_mean_squared_error: 72807.9652 - val_loss: 207286.4713 - val_recon_loss: 8.4775 - val_reg_output_loss: 206438.7244 - val_recon_mean_squared_error: 8.4775 - val_reg_output_mean_squared_error: 206438.7244\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 637us/step - loss: 71820.6464 - recon_loss: 1.5660 - reg_output_loss: 71664.0464 - recon_mean_squared_error: 1.5660 - reg_output_mean_squared_error: 71664.0464 - val_loss: 216957.2394 - val_recon_loss: 3.5476 - val_reg_output_loss: 216602.4800 - val_recon_mean_squared_error: 3.5476 - val_reg_output_mean_squared_error: 216602.4800\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70907.2346 - recon_loss: 1.7361 - reg_output_loss: 70733.6278 - recon_mean_squared_error: 1.7361 - reg_output_mean_squared_error: 70733.6278 - val_loss: 225559.9544 - val_recon_loss: 4.5915 - val_reg_output_loss: 225100.8056 - val_recon_mean_squared_error: 4.5915 - val_reg_output_mean_squared_error: 225100.8056\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 750us/step - loss: 71579.4347 - recon_loss: 1.8994 - reg_output_loss: 71389.4941 - recon_mean_squared_error: 1.8994 - reg_output_mean_squared_error: 71389.4941 - val_loss: 230995.1737 - val_recon_loss: 3.5640 - val_reg_output_loss: 230638.7756 - val_recon_mean_squared_error: 3.5640 - val_reg_output_mean_squared_error: 230638.7756\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 71807.1904 - recon_loss: 1.6627 - reg_output_loss: 71640.9218 - recon_mean_squared_error: 1.6627 - reg_output_mean_squared_error: 71640.9218 - val_loss: 227894.9644 - val_recon_loss: 1.4112 - val_reg_output_loss: 227753.8481 - val_recon_mean_squared_error: 1.4112 - val_reg_output_mean_squared_error: 227753.8481\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 71351.2445 - recon_loss: 1.7897 - reg_output_loss: 71172.2785 - recon_mean_squared_error: 1.7897 - reg_output_mean_squared_error: 71172.2785 - val_loss: 235113.1756 - val_recon_loss: 3.8117 - val_reg_output_loss: 234732.0088 - val_recon_mean_squared_error: 3.8117 - val_reg_output_mean_squared_error: 234732.0088\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 70937.4017 - recon_loss: 1.5670 - reg_output_loss: 70780.7005 - recon_mean_squared_error: 1.5670 - reg_output_mean_squared_error: 70780.7005 - val_loss: 243121.5819 - val_recon_loss: 1.2760 - val_reg_output_loss: 242993.9850 - val_recon_mean_squared_error: 1.2760 - val_reg_output_mean_squared_error: 242993.9850\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 71057.7207 - recon_loss: 2.2808 - reg_output_loss: 70829.6443 - recon_mean_squared_error: 2.2808 - reg_output_mean_squared_error: 70829.6443 - val_loss: 250017.6150 - val_recon_loss: 1.6601 - val_reg_output_loss: 249851.6081 - val_recon_mean_squared_error: 1.6601 - val_reg_output_mean_squared_error: 249851.6081\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 70952.3758 - recon_loss: 1.4614 - reg_output_loss: 70806.2312 - recon_mean_squared_error: 1.4614 - reg_output_mean_squared_error: 70806.2312 - val_loss: 251646.2444 - val_recon_loss: 1.7440 - val_reg_output_loss: 251471.8469 - val_recon_mean_squared_error: 1.7440 - val_reg_output_mean_squared_error: 251471.8469\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70136.2241 - recon_loss: 1.8242 - reg_output_loss: 69953.8047 - recon_mean_squared_error: 1.8242 - reg_output_mean_squared_error: 69953.8047 - val_loss: 251693.1244 - val_recon_loss: 1.4017 - val_reg_output_loss: 251552.9488 - val_recon_mean_squared_error: 1.4017 - val_reg_output_mean_squared_error: 251552.9488\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71302.8750 - recon_loss: 1.4935 - reg_output_loss: 71153.5245 - recon_mean_squared_error: 1.4935 - reg_output_mean_squared_error: 71153.5245 - val_loss: 250515.5375 - val_recon_loss: 2.4332 - val_reg_output_loss: 250272.2175 - val_recon_mean_squared_error: 2.4332 - val_reg_output_mean_squared_error: 250272.2175\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 69601.4834 - recon_loss: 1.6853 - reg_output_loss: 69432.9505 - recon_mean_squared_error: 1.6853 - reg_output_mean_squared_error: 69432.9505 - val_loss: 270256.5769 - val_recon_loss: 3.8027 - val_reg_output_loss: 269876.3144 - val_recon_mean_squared_error: 3.8027 - val_reg_output_mean_squared_error: 269876.3144\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69848.2910 - recon_loss: 1.9751 - reg_output_loss: 69650.7814 - recon_mean_squared_error: 1.9751 - reg_output_mean_squared_error: 69650.7814 - val_loss: 261848.0856 - val_recon_loss: 1.9369 - val_reg_output_loss: 261654.3987 - val_recon_mean_squared_error: 1.9369 - val_reg_output_mean_squared_error: 261654.3987\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70236.8899 - recon_loss: 1.3968 - reg_output_loss: 70097.2133 - recon_mean_squared_error: 1.3968 - reg_output_mean_squared_error: 70097.2133 - val_loss: 260519.4544 - val_recon_loss: 2.3633 - val_reg_output_loss: 260283.1281 - val_recon_mean_squared_error: 2.3633 - val_reg_output_mean_squared_error: 260283.1281\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70361.0565 - recon_loss: 2.3601 - reg_output_loss: 70125.0480 - recon_mean_squared_error: 2.3601 - reg_output_mean_squared_error: 70125.0480 - val_loss: 259723.3944 - val_recon_loss: 1.5571 - val_reg_output_loss: 259567.6856 - val_recon_mean_squared_error: 1.5571 - val_reg_output_mean_squared_error: 259567.6856\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 69233.8379 - recon_loss: 1.7333 - reg_output_loss: 69060.5104 - recon_mean_squared_error: 1.7333 - reg_output_mean_squared_error: 69060.5104 - val_loss: 267557.3144 - val_recon_loss: 2.7853 - val_reg_output_loss: 267278.7869 - val_recon_mean_squared_error: 2.7853 - val_reg_output_mean_squared_error: 267278.7869\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 69195.6455 - recon_loss: 1.3391 - reg_output_loss: 69061.7382 - recon_mean_squared_error: 1.3391 - reg_output_mean_squared_error: 69061.7382 - val_loss: 279454.5488 - val_recon_loss: 1.1740 - val_reg_output_loss: 279337.1462 - val_recon_mean_squared_error: 1.1740 - val_reg_output_mean_squared_error: 279337.1462\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 750us/step - loss: 69407.4454 - recon_loss: 1.5099 - reg_output_loss: 69256.4533 - recon_mean_squared_error: 1.5099 - reg_output_mean_squared_error: 69256.4533 - val_loss: 283512.5344 - val_recon_loss: 2.0969 - val_reg_output_loss: 283302.8463 - val_recon_mean_squared_error: 2.0969 - val_reg_output_mean_squared_error: 283302.8463\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 70476.9449 - recon_loss: 1.4895 - reg_output_loss: 70327.9951 - recon_mean_squared_error: 1.4895 - reg_output_mean_squared_error: 70327.9951 - val_loss: 291774.6625 - val_recon_loss: 1.4023 - val_reg_output_loss: 291634.4344 - val_recon_mean_squared_error: 1.4023 - val_reg_output_mean_squared_error: 291634.4344\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 70539.9120 - recon_loss: 1.7368 - reg_output_loss: 70366.2339 - recon_mean_squared_error: 1.7368 - reg_output_mean_squared_error: 70366.2339 - val_loss: 277246.8362 - val_recon_loss: 1.5451 - val_reg_output_loss: 277092.3244 - val_recon_mean_squared_error: 1.5451 - val_reg_output_mean_squared_error: 277092.3244\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70129.4365 - recon_loss: 1.7027 - reg_output_loss: 69959.1663 - recon_mean_squared_error: 1.7027 - reg_output_mean_squared_error: 69959.1663 - val_loss: 274851.5006 - val_recon_loss: 1.3872 - val_reg_output_loss: 274712.7775 - val_recon_mean_squared_error: 1.3872 - val_reg_output_mean_squared_error: 274712.7775\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 69600.1045 - recon_loss: 1.6597 - reg_output_loss: 69434.1306 - recon_mean_squared_error: 1.6597 - reg_output_mean_squared_error: 69434.1306 - val_loss: 278200.5794 - val_recon_loss: 1.1940 - val_reg_output_loss: 278081.1813 - val_recon_mean_squared_error: 1.1940 - val_reg_output_mean_squared_error: 278081.1813\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70015.5695 - recon_loss: 1.7105 - reg_output_loss: 69844.5174 - recon_mean_squared_error: 1.7105 - reg_output_mean_squared_error: 69844.5174 - val_loss: 284472.5281 - val_recon_loss: 1.9256 - val_reg_output_loss: 284279.9725 - val_recon_mean_squared_error: 1.9256 - val_reg_output_mean_squared_error: 284279.9725\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 68597.4760 - recon_loss: 1.8546 - reg_output_loss: 68412.0130 - recon_mean_squared_error: 1.8546 - reg_output_mean_squared_error: 68412.0130 - val_loss: 292592.4088 - val_recon_loss: 1.3515 - val_reg_output_loss: 292457.2519 - val_recon_mean_squared_error: 1.3515 - val_reg_output_mean_squared_error: 292457.2519\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 69292.0394 - recon_loss: 1.6541 - reg_output_loss: 69126.6324 - recon_mean_squared_error: 1.6541 - reg_output_mean_squared_error: 69126.6324 - val_loss: 286270.3800 - val_recon_loss: 1.2832 - val_reg_output_loss: 286142.0600 - val_recon_mean_squared_error: 1.2832 - val_reg_output_mean_squared_error: 286142.0600\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 70746.9474 - recon_loss: 2.0230 - reg_output_loss: 70544.6436 - recon_mean_squared_error: 2.0230 - reg_output_mean_squared_error: 70544.6436 - val_loss: 280205.2319 - val_recon_loss: 1.1871 - val_reg_output_loss: 280086.5206 - val_recon_mean_squared_error: 1.1871 - val_reg_output_mean_squared_error: 280086.5206\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 70399.7753 - recon_loss: 1.6818 - reg_output_loss: 70231.5951 - recon_mean_squared_error: 1.6818 - reg_output_mean_squared_error: 70231.5951 - val_loss: 263899.6644 - val_recon_loss: 1.8160 - val_reg_output_loss: 263718.0644 - val_recon_mean_squared_error: 1.8160 - val_reg_output_mean_squared_error: 263718.0644\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 69558.2567 - recon_loss: 1.4529 - reg_output_loss: 69412.9657 - recon_mean_squared_error: 1.4529 - reg_output_mean_squared_error: 69412.9657 - val_loss: 262167.4012 - val_recon_loss: 1.8015 - val_reg_output_loss: 261987.2544 - val_recon_mean_squared_error: 1.8015 - val_reg_output_mean_squared_error: 261987.2544\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 67870.2345 - recon_loss: 1.8767 - reg_output_loss: 67682.5659 - recon_mean_squared_error: 1.8767 - reg_output_mean_squared_error: 67682.5659 - val_loss: 286040.6512 - val_recon_loss: 1.6241 - val_reg_output_loss: 285878.2363 - val_recon_mean_squared_error: 1.6241 - val_reg_output_mean_squared_error: 285878.2363\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 69259.9036 - recon_loss: 1.4393 - reg_output_loss: 69115.9711 - recon_mean_squared_error: 1.4393 - reg_output_mean_squared_error: 69115.9711 - val_loss: 277123.2444 - val_recon_loss: 1.4419 - val_reg_output_loss: 276979.0575 - val_recon_mean_squared_error: 1.4419 - val_reg_output_mean_squared_error: 276979.0575\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 68295.8823 - recon_loss: 1.8702 - reg_output_loss: 68108.8595 - recon_mean_squared_error: 1.8702 - reg_output_mean_squared_error: 68108.8595 - val_loss: 273656.1312 - val_recon_loss: 1.7608 - val_reg_output_loss: 273480.0506 - val_recon_mean_squared_error: 1.7608 - val_reg_output_mean_squared_error: 273480.0506\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68902.6285 - recon_loss: 1.7571 - reg_output_loss: 68726.9232 - recon_mean_squared_error: 1.7571 - reg_output_mean_squared_error: 68726.9232 - val_loss: 265711.1981 - val_recon_loss: 1.2161 - val_reg_output_loss: 265589.5919 - val_recon_mean_squared_error: 1.2161 - val_reg_output_mean_squared_error: 265589.5919\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 69559.3705 - recon_loss: 1.8263 - reg_output_loss: 69376.7382 - recon_mean_squared_error: 1.8263 - reg_output_mean_squared_error: 69376.7382 - val_loss: 253923.7656 - val_recon_loss: 2.1090 - val_reg_output_loss: 253712.8669 - val_recon_mean_squared_error: 2.1090 - val_reg_output_mean_squared_error: 253712.8669\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69148.7307 - recon_loss: 1.4951 - reg_output_loss: 68999.2175 - recon_mean_squared_error: 1.4951 - reg_output_mean_squared_error: 68999.2175 - val_loss: 245129.4234 - val_recon_loss: 2.8647 - val_reg_output_loss: 244842.9528 - val_recon_mean_squared_error: 2.8647 - val_reg_output_mean_squared_error: 244842.9528\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69323.6332 - recon_loss: 1.4642 - reg_output_loss: 69177.2084 - recon_mean_squared_error: 1.4642 - reg_output_mean_squared_error: 69177.2084 - val_loss: 242649.2050 - val_recon_loss: 1.6483 - val_reg_output_loss: 242484.3731 - val_recon_mean_squared_error: 1.6483 - val_reg_output_mean_squared_error: 242484.3731\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69788.6017 - recon_loss: 4.7542 - reg_output_loss: 69313.1782 - recon_mean_squared_error: 4.7542 - reg_output_mean_squared_error: 69313.1782 - val_loss: 232929.7963 - val_recon_loss: 1.0972 - val_reg_output_loss: 232820.0738 - val_recon_mean_squared_error: 1.0972 - val_reg_output_mean_squared_error: 232820.0738\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 69710.1450 - recon_loss: 1.2672 - reg_output_loss: 69583.4240 - recon_mean_squared_error: 1.2672 - reg_output_mean_squared_error: 69583.4240 - val_loss: 233545.9662 - val_recon_loss: 3.1922 - val_reg_output_loss: 233226.7450 - val_recon_mean_squared_error: 3.1922 - val_reg_output_mean_squared_error: 233226.7450\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 67587.0807 - recon_loss: 2.6043 - reg_output_loss: 67326.6540 - recon_mean_squared_error: 2.6043 - reg_output_mean_squared_error: 67326.6540 - val_loss: 226501.5116 - val_recon_loss: 1.2701 - val_reg_output_loss: 226374.4953 - val_recon_mean_squared_error: 1.2701 - val_reg_output_mean_squared_error: 226374.4953\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 72556.8235 - recon_loss: 1.5128 - reg_output_loss: 72405.5464 - recon_mean_squared_error: 1.5128 - reg_output_mean_squared_error: 72405.5464 - val_loss: 208176.1619 - val_recon_loss: 1.3004 - val_reg_output_loss: 208046.1216 - val_recon_mean_squared_error: 1.3004 - val_reg_output_mean_squared_error: 208046.1216\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 71400.9956 - recon_loss: 1.7529 - reg_output_loss: 71225.7053 - recon_mean_squared_error: 1.7529 - reg_output_mean_squared_error: 71225.7053 - val_loss: 195997.9359 - val_recon_loss: 1.9988 - val_reg_output_loss: 195798.0531 - val_recon_mean_squared_error: 1.9988 - val_reg_output_mean_squared_error: 195798.0531\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 71780.6920 - recon_loss: 1.2900 - reg_output_loss: 71651.6911 - recon_mean_squared_error: 1.2900 - reg_output_mean_squared_error: 71651.6911 - val_loss: 184860.4272 - val_recon_loss: 1.5319 - val_reg_output_loss: 184707.2409 - val_recon_mean_squared_error: 1.5319 - val_reg_output_mean_squared_error: 184707.2409\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 69435.0277 - recon_loss: 1.2356 - reg_output_loss: 69311.4674 - recon_mean_squared_error: 1.2356 - reg_output_mean_squared_error: 69311.4674 - val_loss: 187256.0559 - val_recon_loss: 1.7987 - val_reg_output_loss: 187076.1834 - val_recon_mean_squared_error: 1.7987 - val_reg_output_mean_squared_error: 187076.1834\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 69764.4674 - recon_loss: 1.2823 - reg_output_loss: 69636.2386 - recon_mean_squared_error: 1.2823 - reg_output_mean_squared_error: 69636.2386 - val_loss: 186578.5359 - val_recon_loss: 3.6396 - val_reg_output_loss: 186214.5741 - val_recon_mean_squared_error: 3.6396 - val_reg_output_mean_squared_error: 186214.5741\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70677.3070 - recon_loss: 1.4771 - reg_output_loss: 70529.5935 - recon_mean_squared_error: 1.4771 - reg_output_mean_squared_error: 70529.5935 - val_loss: 182081.9637 - val_recon_loss: 1.2128 - val_reg_output_loss: 181960.6812 - val_recon_mean_squared_error: 1.2128 - val_reg_output_mean_squared_error: 181960.6812\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 69472.6066 - recon_loss: 1.4885 - reg_output_loss: 69323.7596 - recon_mean_squared_error: 1.4885 - reg_output_mean_squared_error: 69323.7596 - val_loss: 180550.2297 - val_recon_loss: 1.1498 - val_reg_output_loss: 180435.2469 - val_recon_mean_squared_error: 1.1498 - val_reg_output_mean_squared_error: 180435.2469\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70958.8607 - recon_loss: 1.6197 - reg_output_loss: 70796.8952 - recon_mean_squared_error: 1.6197 - reg_output_mean_squared_error: 70796.8952 - val_loss: 174847.1128 - val_recon_loss: 2.9160 - val_reg_output_loss: 174555.5147 - val_recon_mean_squared_error: 2.9160 - val_reg_output_mean_squared_error: 174555.5147\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 66372.1087 - recon_loss: 1.9702 - reg_output_loss: 66175.0847 - recon_mean_squared_error: 1.9702 - reg_output_mean_squared_error: 66175.0847 - val_loss: 173418.5969 - val_recon_loss: 1.1778 - val_reg_output_loss: 173300.8238 - val_recon_mean_squared_error: 1.1778 - val_reg_output_mean_squared_error: 173300.8238\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 682us/step - loss: 71894.0754 - recon_loss: 1.8985 - reg_output_loss: 71704.2251 - recon_mean_squared_error: 1.8985 - reg_output_mean_squared_error: 71704.2251 - val_loss: 164001.0150 - val_recon_loss: 1.1453 - val_reg_output_loss: 163886.4838 - val_recon_mean_squared_error: 1.1453 - val_reg_output_mean_squared_error: 163886.4838\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 69540.7029 - recon_loss: 1.4369 - reg_output_loss: 69397.0145 - recon_mean_squared_error: 1.4369 - reg_output_mean_squared_error: 69397.0145 - val_loss: 162838.9287 - val_recon_loss: 1.0603 - val_reg_output_loss: 162732.8937 - val_recon_mean_squared_error: 1.0603 - val_reg_output_mean_squared_error: 162732.8937\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70728.5086 - recon_loss: 1.4546 - reg_output_loss: 70583.0490 - recon_mean_squared_error: 1.4546 - reg_output_mean_squared_error: 70583.0490 - val_loss: 155433.4153 - val_recon_loss: 2.5872 - val_reg_output_loss: 155174.6975 - val_recon_mean_squared_error: 2.5872 - val_reg_output_mean_squared_error: 155174.6975\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71383.7061 - recon_loss: 1.5729 - reg_output_loss: 71226.4145 - recon_mean_squared_error: 1.5729 - reg_output_mean_squared_error: 71226.4145 - val_loss: 142976.8006 - val_recon_loss: 1.0308 - val_reg_output_loss: 142873.7228 - val_recon_mean_squared_error: 1.0308 - val_reg_output_mean_squared_error: 142873.7228\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 69796.9066 - recon_loss: 1.5772 - reg_output_loss: 69639.1910 - recon_mean_squared_error: 1.5772 - reg_output_mean_squared_error: 69639.1910 - val_loss: 140579.9244 - val_recon_loss: 1.0278 - val_reg_output_loss: 140477.1484 - val_recon_mean_squared_error: 1.0278 - val_reg_output_mean_squared_error: 140477.1484\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 71292.7315 - recon_loss: 1.6297 - reg_output_loss: 71129.7578 - recon_mean_squared_error: 1.6297 - reg_output_mean_squared_error: 71129.7578 - val_loss: 134627.3841 - val_recon_loss: 1.0354 - val_reg_output_loss: 134523.8456 - val_recon_mean_squared_error: 1.0354 - val_reg_output_mean_squared_error: 134523.8456\n",
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 69245.7378 - recon_loss: 1.5729 - reg_output_loss: 69088.4502 - recon_mean_squared_error: 1.5729 - reg_output_mean_squared_error: 69088.4502 - val_loss: 135347.7588 - val_recon_loss: 3.6657 - val_reg_output_loss: 134981.1862 - val_recon_mean_squared_error: 3.6657 - val_reg_output_mean_squared_error: 134981.1862\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 637us/step - loss: 74423.6399 - recon_loss: 1.9368 - reg_output_loss: 74229.9606 - recon_mean_squared_error: 1.9368 - reg_output_mean_squared_error: 74229.9606 - val_loss: 121825.2241 - val_recon_loss: 1.7372 - val_reg_output_loss: 121651.5028 - val_recon_mean_squared_error: 1.7372 - val_reg_output_mean_squared_error: 121651.5028\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70069.4399 - recon_loss: 1.4827 - reg_output_loss: 69921.1700 - recon_mean_squared_error: 1.4827 - reg_output_mean_squared_error: 69921.1700 - val_loss: 118304.2247 - val_recon_loss: 1.0450 - val_reg_output_loss: 118199.7219 - val_recon_mean_squared_error: 1.0450 - val_reg_output_mean_squared_error: 118199.7219\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 72476.1754 - recon_loss: 1.6222 - reg_output_loss: 72313.9518 - recon_mean_squared_error: 1.6222 - reg_output_mean_squared_error: 72313.9518 - val_loss: 113822.3397 - val_recon_loss: 1.0300 - val_reg_output_loss: 113719.3409 - val_recon_mean_squared_error: 1.0300 - val_reg_output_mean_squared_error: 113719.3409\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 71134.2783 - recon_loss: 1.2003 - reg_output_loss: 71014.2478 - recon_mean_squared_error: 1.2003 - reg_output_mean_squared_error: 71014.2478 - val_loss: 112991.1847 - val_recon_loss: 1.0490 - val_reg_output_loss: 112886.2822 - val_recon_mean_squared_error: 1.0490 - val_reg_output_mean_squared_error: 112886.2822\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 72438.1896 - recon_loss: 1.6563 - reg_output_loss: 72272.5648 - recon_mean_squared_error: 1.6563 - reg_output_mean_squared_error: 72272.5648 - val_loss: 106475.3622 - val_recon_loss: 1.0476 - val_reg_output_loss: 106370.6047 - val_recon_mean_squared_error: 1.0476 - val_reg_output_mean_squared_error: 106370.6047\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69068.2974 - recon_loss: 1.2630 - reg_output_loss: 68941.9929 - recon_mean_squared_error: 1.2630 - reg_output_mean_squared_error: 68941.9929 - val_loss: 106497.6753 - val_recon_loss: 2.4351 - val_reg_output_loss: 106254.1672 - val_recon_mean_squared_error: 2.4351 - val_reg_output_mean_squared_error: 106254.1672\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 70205.8499 - recon_loss: 1.5403 - reg_output_loss: 70051.8221 - recon_mean_squared_error: 1.5403 - reg_output_mean_squared_error: 70051.8221 - val_loss: 104782.8509 - val_recon_loss: 1.2684 - val_reg_output_loss: 104656.0144 - val_recon_mean_squared_error: 1.2684 - val_reg_output_mean_squared_error: 104656.0144\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 70336.5110 - recon_loss: 1.4264 - reg_output_loss: 70193.8674 - recon_mean_squared_error: 1.4264 - reg_output_mean_squared_error: 70193.8674 - val_loss: 104562.9000 - val_recon_loss: 1.0604 - val_reg_output_loss: 104456.8609 - val_recon_mean_squared_error: 1.0604 - val_reg_output_mean_squared_error: 104456.8609\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71193.6735 - recon_loss: 1.3777 - reg_output_loss: 71055.9057 - recon_mean_squared_error: 1.3777 - reg_output_mean_squared_error: 71055.9057 - val_loss: 100272.2122 - val_recon_loss: 1.0301 - val_reg_output_loss: 100169.2059 - val_recon_mean_squared_error: 1.0301 - val_reg_output_mean_squared_error: 100169.2059\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70185.9768 - recon_loss: 1.4566 - reg_output_loss: 70040.3152 - recon_mean_squared_error: 1.4566 - reg_output_mean_squared_error: 70040.3152 - val_loss: 99363.7116 - val_recon_loss: 1.0375 - val_reg_output_loss: 99259.9641 - val_recon_mean_squared_error: 1.0375 - val_reg_output_mean_squared_error: 99259.9641\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71518.8924 - recon_loss: 1.1846 - reg_output_loss: 71400.4317 - recon_mean_squared_error: 1.1846 - reg_output_mean_squared_error: 71400.4317 - val_loss: 97115.6777 - val_recon_loss: 1.0429 - val_reg_output_loss: 97011.3858 - val_recon_mean_squared_error: 1.0429 - val_reg_output_mean_squared_error: 97011.3858\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 70003.1977 - recon_loss: 1.6449 - reg_output_loss: 69838.7028 - recon_mean_squared_error: 1.6449 - reg_output_mean_squared_error: 69838.7028 - val_loss: 94434.9584 - val_recon_loss: 1.0305 - val_reg_output_loss: 94331.9097 - val_recon_mean_squared_error: 1.0305 - val_reg_output_mean_squared_error: 94331.9097\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 70929.1229 - recon_loss: 1.2424 - reg_output_loss: 70804.8795 - recon_mean_squared_error: 1.2424 - reg_output_mean_squared_error: 70804.8795 - val_loss: 92764.6534 - val_recon_loss: 1.0481 - val_reg_output_loss: 92659.8447 - val_recon_mean_squared_error: 1.0481 - val_reg_output_mean_squared_error: 92659.8447\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68970.1089 - recon_loss: 1.8221 - reg_output_loss: 68787.8980 - recon_mean_squared_error: 1.8221 - reg_output_mean_squared_error: 68787.8980 - val_loss: 93307.8938 - val_recon_loss: 1.0974 - val_reg_output_loss: 93198.1530 - val_recon_mean_squared_error: 1.0974 - val_reg_output_mean_squared_error: 93198.1530\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 718us/step - loss: 70127.8038 - recon_loss: 1.3321 - reg_output_loss: 69994.5932 - recon_mean_squared_error: 1.3321 - reg_output_mean_squared_error: 69994.5932 - val_loss: 91624.2178 - val_recon_loss: 1.0094 - val_reg_output_loss: 91523.2783 - val_recon_mean_squared_error: 1.0094 - val_reg_output_mean_squared_error: 91523.2783\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 74575.9058 - recon_loss: 1.2712 - reg_output_loss: 74448.7889 - recon_mean_squared_error: 1.2712 - reg_output_mean_squared_error: 74448.7889 - val_loss: 87103.9752 - val_recon_loss: 1.1645 - val_reg_output_loss: 86987.5236 - val_recon_mean_squared_error: 1.1645 - val_reg_output_mean_squared_error: 86987.5236\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70839.3611 - recon_loss: 1.2193 - reg_output_loss: 70717.4315 - recon_mean_squared_error: 1.2193 - reg_output_mean_squared_error: 70717.4315 - val_loss: 86765.0364 - val_recon_loss: 1.0455 - val_reg_output_loss: 86660.4844 - val_recon_mean_squared_error: 1.0455 - val_reg_output_mean_squared_error: 86660.4844\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70660.6181 - recon_loss: 1.3451 - reg_output_loss: 70526.1064 - recon_mean_squared_error: 1.3451 - reg_output_mean_squared_error: 70526.1064 - val_loss: 86330.8217 - val_recon_loss: 1.0156 - val_reg_output_loss: 86229.2617 - val_recon_mean_squared_error: 1.0156 - val_reg_output_mean_squared_error: 86229.2617\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 72776.9787 - recon_loss: 1.2171 - reg_output_loss: 72655.2708 - recon_mean_squared_error: 1.2171 - reg_output_mean_squared_error: 72655.2708 - val_loss: 85351.4662 - val_recon_loss: 1.0042 - val_reg_output_loss: 85251.0403 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 85251.0403\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 74190.2003 - recon_loss: 1.2818 - reg_output_loss: 74062.0196 - recon_mean_squared_error: 1.2818 - reg_output_mean_squared_error: 74062.0196 - val_loss: 82698.6288 - val_recon_loss: 1.0740 - val_reg_output_loss: 82591.2337 - val_recon_mean_squared_error: 1.0740 - val_reg_output_mean_squared_error: 82591.2337\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70997.9503 - recon_loss: 1.4186 - reg_output_loss: 70856.0882 - recon_mean_squared_error: 1.4186 - reg_output_mean_squared_error: 70856.0882 - val_loss: 83282.7997 - val_recon_loss: 1.0544 - val_reg_output_loss: 83177.3600 - val_recon_mean_squared_error: 1.0544 - val_reg_output_mean_squared_error: 83177.3600\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 67780.9311 - recon_loss: 1.4281 - reg_output_loss: 67638.1250 - recon_mean_squared_error: 1.4281 - reg_output_mean_squared_error: 67638.1250 - val_loss: 82653.2389 - val_recon_loss: 1.0227 - val_reg_output_loss: 82550.9731 - val_recon_mean_squared_error: 1.0227 - val_reg_output_mean_squared_error: 82550.9731\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 71452.8725 - recon_loss: 1.2514 - reg_output_loss: 71327.7319 - recon_mean_squared_error: 1.2514 - reg_output_mean_squared_error: 71327.7319 - val_loss: 82032.3936 - val_recon_loss: 1.3116 - val_reg_output_loss: 81901.2306 - val_recon_mean_squared_error: 1.3116 - val_reg_output_mean_squared_error: 81901.2306\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 71683.8141 - recon_loss: 1.4599 - reg_output_loss: 71537.8213 - recon_mean_squared_error: 1.4599 - reg_output_mean_squared_error: 71537.8213 - val_loss: 81838.2483 - val_recon_loss: 1.0141 - val_reg_output_loss: 81736.8367 - val_recon_mean_squared_error: 1.0141 - val_reg_output_mean_squared_error: 81736.8367\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 73121.8479 - recon_loss: 1.2157 - reg_output_loss: 73000.2762 - recon_mean_squared_error: 1.2157 - reg_output_mean_squared_error: 73000.2762 - val_loss: 80455.2078 - val_recon_loss: 1.0073 - val_reg_output_loss: 80354.4744 - val_recon_mean_squared_error: 1.0073 - val_reg_output_mean_squared_error: 80354.4744\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 72553.0857 - recon_loss: 1.3070 - reg_output_loss: 72422.3823 - recon_mean_squared_error: 1.3070 - reg_output_mean_squared_error: 72422.3823 - val_loss: 78982.9523 - val_recon_loss: 1.0146 - val_reg_output_loss: 78881.4888 - val_recon_mean_squared_error: 1.0146 - val_reg_output_mean_squared_error: 78881.4888\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 68368.8586 - recon_loss: 1.1449 - reg_output_loss: 68254.3695 - recon_mean_squared_error: 1.1449 - reg_output_mean_squared_error: 68254.3695 - val_loss: 79950.1458 - val_recon_loss: 1.0894 - val_reg_output_loss: 79841.2033 - val_recon_mean_squared_error: 1.0894 - val_reg_output_mean_squared_error: 79841.2033\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70542.3599 - recon_loss: 1.3784 - reg_output_loss: 70404.5183 - recon_mean_squared_error: 1.3784 - reg_output_mean_squared_error: 70404.5183 - val_loss: 78476.3975 - val_recon_loss: 1.0273 - val_reg_output_loss: 78373.6669 - val_recon_mean_squared_error: 1.0273 - val_reg_output_mean_squared_error: 78373.6669\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 640us/step - loss: 70734.1788 - recon_loss: 1.2711 - reg_output_loss: 70607.0694 - recon_mean_squared_error: 1.2711 - reg_output_mean_squared_error: 70607.0694 - val_loss: 78123.6647 - val_recon_loss: 1.0106 - val_reg_output_loss: 78022.6048 - val_recon_mean_squared_error: 1.0106 - val_reg_output_mean_squared_error: 78022.6048\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 69976.1817 - recon_loss: 1.1300 - reg_output_loss: 69863.1793 - recon_mean_squared_error: 1.1300 - reg_output_mean_squared_error: 69863.1793 - val_loss: 77659.9594 - val_recon_loss: 1.0175 - val_reg_output_loss: 77558.2097 - val_recon_mean_squared_error: 1.0175 - val_reg_output_mean_squared_error: 77558.2097\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 69310.4204 - recon_loss: 1.6237 - reg_output_loss: 69148.0507 - recon_mean_squared_error: 1.6237 - reg_output_mean_squared_error: 69148.0507 - val_loss: 77488.2145 - val_recon_loss: 1.0407 - val_reg_output_loss: 77384.1475 - val_recon_mean_squared_error: 1.0407 - val_reg_output_mean_squared_error: 77384.1475\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 72994.3342 - recon_loss: 1.1645 - reg_output_loss: 72877.8860 - recon_mean_squared_error: 1.1645 - reg_output_mean_squared_error: 72877.8860 - val_loss: 76713.5014 - val_recon_loss: 1.0712 - val_reg_output_loss: 76606.3763 - val_recon_mean_squared_error: 1.0712 - val_reg_output_mean_squared_error: 76606.3763\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 67860.1433 - recon_loss: 1.2192 - reg_output_loss: 67738.2211 - recon_mean_squared_error: 1.2192 - reg_output_mean_squared_error: 67738.2211 - val_loss: 78147.2098 - val_recon_loss: 1.0166 - val_reg_output_loss: 78045.5516 - val_recon_mean_squared_error: 1.0166 - val_reg_output_mean_squared_error: 78045.5516\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 74733.8308 - recon_loss: 1.2110 - reg_output_loss: 74612.7263 - recon_mean_squared_error: 1.2110 - reg_output_mean_squared_error: 74612.7263 - val_loss: 77354.8139 - val_recon_loss: 1.0523 - val_reg_output_loss: 77249.5822 - val_recon_mean_squared_error: 1.0523 - val_reg_output_mean_squared_error: 77249.5822\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 72227.8679 - recon_loss: 1.1357 - reg_output_loss: 72114.3024 - recon_mean_squared_error: 1.1357 - reg_output_mean_squared_error: 72114.3024 - val_loss: 77305.4620 - val_recon_loss: 1.0175 - val_reg_output_loss: 77203.7094 - val_recon_mean_squared_error: 1.0175 - val_reg_output_mean_squared_error: 77203.7094\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 73852.2321 - recon_loss: 1.3173 - reg_output_loss: 73720.5009 - recon_mean_squared_error: 1.3173 - reg_output_mean_squared_error: 73720.5009 - val_loss: 76499.7448 - val_recon_loss: 1.0391 - val_reg_output_loss: 76395.8306 - val_recon_mean_squared_error: 1.0391 - val_reg_output_mean_squared_error: 76395.8306\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 72929.6647 - recon_loss: 1.1646 - reg_output_loss: 72813.2017 - recon_mean_squared_error: 1.1646 - reg_output_mean_squared_error: 72813.2017 - val_loss: 75897.7884 - val_recon_loss: 1.0443 - val_reg_output_loss: 75793.3566 - val_recon_mean_squared_error: 1.0443 - val_reg_output_mean_squared_error: 75793.3566\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 640us/step - loss: 76963.9094 - recon_loss: 1.0990 - reg_output_loss: 76854.0064 - recon_mean_squared_error: 1.0990 - reg_output_mean_squared_error: 76854.0064 - val_loss: 74624.0059 - val_recon_loss: 1.0757 - val_reg_output_loss: 74516.4386 - val_recon_mean_squared_error: 1.0757 - val_reg_output_mean_squared_error: 74516.4386\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 74195.9329 - recon_loss: 1.1883 - reg_output_loss: 74077.1008 - recon_mean_squared_error: 1.1883 - reg_output_mean_squared_error: 74077.1008 - val_loss: 74232.8542 - val_recon_loss: 1.0292 - val_reg_output_loss: 74129.9316 - val_recon_mean_squared_error: 1.0292 - val_reg_output_mean_squared_error: 74129.9316\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 72031.7143 - recon_loss: 1.3729 - reg_output_loss: 71894.4268 - recon_mean_squared_error: 1.3729 - reg_output_mean_squared_error: 71894.4268 - val_loss: 74303.3605 - val_recon_loss: 1.0181 - val_reg_output_loss: 74201.5469 - val_recon_mean_squared_error: 1.0181 - val_reg_output_mean_squared_error: 74201.5469\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 73111.3607 - recon_loss: 1.1674 - reg_output_loss: 72994.6222 - recon_mean_squared_error: 1.1674 - reg_output_mean_squared_error: 72994.6222 - val_loss: 74357.0003 - val_recon_loss: 1.0065 - val_reg_output_loss: 74256.3519 - val_recon_mean_squared_error: 1.0065 - val_reg_output_mean_squared_error: 74256.3519\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70338.2171 - recon_loss: 1.1521 - reg_output_loss: 70223.0105 - recon_mean_squared_error: 1.1521 - reg_output_mean_squared_error: 70223.0105 - val_loss: 74671.0453 - val_recon_loss: 1.0138 - val_reg_output_loss: 74569.6613 - val_recon_mean_squared_error: 1.0138 - val_reg_output_mean_squared_error: 74569.6613\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 70343.5571 - recon_loss: 1.1579 - reg_output_loss: 70227.7631 - recon_mean_squared_error: 1.1579 - reg_output_mean_squared_error: 70227.7631 - val_loss: 75590.3284 - val_recon_loss: 1.0366 - val_reg_output_loss: 75486.6706 - val_recon_mean_squared_error: 1.0366 - val_reg_output_mean_squared_error: 75486.6706\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 73538.4540 - recon_loss: 1.1097 - reg_output_loss: 73427.4871 - recon_mean_squared_error: 1.1097 - reg_output_mean_squared_error: 73427.4871 - val_loss: 75347.1062 - val_recon_loss: 1.0176 - val_reg_output_loss: 75245.3438 - val_recon_mean_squared_error: 1.0176 - val_reg_output_mean_squared_error: 75245.3438\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 70576.6836 - recon_loss: 1.0936 - reg_output_loss: 70467.3224 - recon_mean_squared_error: 1.0936 - reg_output_mean_squared_error: 70467.3224 - val_loss: 76202.4027 - val_recon_loss: 1.0221 - val_reg_output_loss: 76100.1914 - val_recon_mean_squared_error: 1.0221 - val_reg_output_mean_squared_error: 76100.1914\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 69694.0257 - recon_loss: 1.1665 - reg_output_loss: 69577.3744 - recon_mean_squared_error: 1.1665 - reg_output_mean_squared_error: 69577.3744 - val_loss: 76421.7681 - val_recon_loss: 1.0174 - val_reg_output_loss: 76320.0320 - val_recon_mean_squared_error: 1.0174 - val_reg_output_mean_squared_error: 76320.0320\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 72226.3644 - recon_loss: 1.1972 - reg_output_loss: 72106.6418 - recon_mean_squared_error: 1.1972 - reg_output_mean_squared_error: 72106.6418 - val_loss: 75381.0633 - val_recon_loss: 1.0216 - val_reg_output_loss: 75278.9067 - val_recon_mean_squared_error: 1.0216 - val_reg_output_mean_squared_error: 75278.9067\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 72080.8574 - recon_loss: 1.2637 - reg_output_loss: 71954.4866 - recon_mean_squared_error: 1.2637 - reg_output_mean_squared_error: 71954.4866 - val_loss: 74474.8647 - val_recon_loss: 1.1188 - val_reg_output_loss: 74362.9856 - val_recon_mean_squared_error: 1.1188 - val_reg_output_mean_squared_error: 74362.9856\n",
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 71634.8270 - recon_loss: 1.1763 - reg_output_loss: 71517.2018 - recon_mean_squared_error: 1.1763 - reg_output_mean_squared_error: 71517.2018 - val_loss: 74604.0672 - val_recon_loss: 1.0071 - val_reg_output_loss: 74503.3556 - val_recon_mean_squared_error: 1.0071 - val_reg_output_mean_squared_error: 74503.3556\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 69075.5029 - recon_loss: 1.1231 - reg_output_loss: 68963.1960 - recon_mean_squared_error: 1.1231 - reg_output_mean_squared_error: 68963.1960 - val_loss: 75362.5650 - val_recon_loss: 1.0251 - val_reg_output_loss: 75260.0534 - val_recon_mean_squared_error: 1.0251 - val_reg_output_mean_squared_error: 75260.0534\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 72533.7251 - recon_loss: 1.2032 - reg_output_loss: 72413.4073 - recon_mean_squared_error: 1.2032 - reg_output_mean_squared_error: 72413.4073 - val_loss: 74292.3575 - val_recon_loss: 1.0498 - val_reg_output_loss: 74187.3780 - val_recon_mean_squared_error: 1.0498 - val_reg_output_mean_squared_error: 74187.3780\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 68564.9727 - recon_loss: 1.1285 - reg_output_loss: 68452.1216 - recon_mean_squared_error: 1.1285 - reg_output_mean_squared_error: 68452.1216 - val_loss: 75349.5116 - val_recon_loss: 1.0076 - val_reg_output_loss: 75248.7525 - val_recon_mean_squared_error: 1.0076 - val_reg_output_mean_squared_error: 75248.7525\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 71342.6236 - recon_loss: 1.1582 - reg_output_loss: 71226.8015 - recon_mean_squared_error: 1.1582 - reg_output_mean_squared_error: 71226.8015 - val_loss: 74923.8709 - val_recon_loss: 1.0087 - val_reg_output_loss: 74823.0058 - val_recon_mean_squared_error: 1.0087 - val_reg_output_mean_squared_error: 74823.0058\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 72886.3702 - recon_loss: 1.1594 - reg_output_loss: 72770.4292 - recon_mean_squared_error: 1.1594 - reg_output_mean_squared_error: 72770.4292 - val_loss: 74123.4248 - val_recon_loss: 1.0789 - val_reg_output_loss: 74015.5323 - val_recon_mean_squared_error: 1.0789 - val_reg_output_mean_squared_error: 74015.5323\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 73422.9896 - recon_loss: 1.3517 - reg_output_loss: 73287.8187 - recon_mean_squared_error: 1.3517 - reg_output_mean_squared_error: 73287.8187 - val_loss: 73945.7167 - val_recon_loss: 1.0210 - val_reg_output_loss: 73843.6197 - val_recon_mean_squared_error: 1.0210 - val_reg_output_mean_squared_error: 73843.6197\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 71357.2668 - recon_loss: 1.0922 - reg_output_loss: 71248.0483 - recon_mean_squared_error: 1.0922 - reg_output_mean_squared_error: 71248.0483 - val_loss: 73962.2833 - val_recon_loss: 1.0088 - val_reg_output_loss: 73861.4009 - val_recon_mean_squared_error: 1.0088 - val_reg_output_mean_squared_error: 73861.4009\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 73956.9984 - recon_loss: 1.1797 - reg_output_loss: 73839.0282 - recon_mean_squared_error: 1.1797 - reg_output_mean_squared_error: 73839.0282 - val_loss: 73386.8128 - val_recon_loss: 1.0098 - val_reg_output_loss: 73285.8375 - val_recon_mean_squared_error: 1.0098 - val_reg_output_mean_squared_error: 73285.8375\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 72170.6905 - recon_loss: 1.0871 - reg_output_loss: 72061.9814 - recon_mean_squared_error: 1.0871 - reg_output_mean_squared_error: 72061.9814 - val_loss: 73518.4453 - val_recon_loss: 1.0376 - val_reg_output_loss: 73414.6897 - val_recon_mean_squared_error: 1.0376 - val_reg_output_mean_squared_error: 73414.6897\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 72748.9016 - recon_loss: 1.1339 - reg_output_loss: 72635.5121 - recon_mean_squared_error: 1.1339 - reg_output_mean_squared_error: 72635.5121 - val_loss: 73269.2681 - val_recon_loss: 1.0170 - val_reg_output_loss: 73167.5638 - val_recon_mean_squared_error: 1.0170 - val_reg_output_mean_squared_error: 73167.5638\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 71329.4944 - recon_loss: 1.0772 - reg_output_loss: 71221.7724 - recon_mean_squared_error: 1.0772 - reg_output_mean_squared_error: 71221.7724 - val_loss: 73613.2097 - val_recon_loss: 1.0079 - val_reg_output_loss: 73512.4178 - val_recon_mean_squared_error: 1.0079 - val_reg_output_mean_squared_error: 73512.4178\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 72411.2035 - recon_loss: 1.1530 - reg_output_loss: 72295.9061 - recon_mean_squared_error: 1.1530 - reg_output_mean_squared_error: 72295.9061 - val_loss: 73655.5570 - val_recon_loss: 1.0334 - val_reg_output_loss: 73552.2200 - val_recon_mean_squared_error: 1.0334 - val_reg_output_mean_squared_error: 73552.2200\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 69788.8387 - recon_loss: 1.1394 - reg_output_loss: 69674.8948 - recon_mean_squared_error: 1.1394 - reg_output_mean_squared_error: 69674.8948 - val_loss: 74007.5019 - val_recon_loss: 1.1643 - val_reg_output_loss: 73891.0722 - val_recon_mean_squared_error: 1.1643 - val_reg_output_mean_squared_error: 73891.0722\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 71700.4629 - recon_loss: 1.1269 - reg_output_loss: 71587.7703 - recon_mean_squared_error: 1.1269 - reg_output_mean_squared_error: 71587.7703 - val_loss: 73758.8678 - val_recon_loss: 1.0108 - val_reg_output_loss: 73657.7903 - val_recon_mean_squared_error: 1.0108 - val_reg_output_mean_squared_error: 73657.7903\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 72167.9738 - recon_loss: 1.1958 - reg_output_loss: 72048.3911 - recon_mean_squared_error: 1.1958 - reg_output_mean_squared_error: 72048.3911 - val_loss: 74138.9881 - val_recon_loss: 1.0109 - val_reg_output_loss: 74037.9012 - val_recon_mean_squared_error: 1.0109 - val_reg_output_mean_squared_error: 74037.9012\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 727us/step - loss: 70109.3410 - recon_loss: 1.2175 - reg_output_loss: 69987.5932 - recon_mean_squared_error: 1.2175 - reg_output_mean_squared_error: 69987.5932 - val_loss: 74281.3702 - val_recon_loss: 1.0167 - val_reg_output_loss: 74179.7050 - val_recon_mean_squared_error: 1.0167 - val_reg_output_mean_squared_error: 74179.7050\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 64555.8153 - recon_loss: 1.1494 - reg_output_loss: 64440.8723 - recon_mean_squared_error: 1.1494 - reg_output_mean_squared_error: 64440.8723 - val_loss: 74381.3148 - val_recon_loss: 1.0400 - val_reg_output_loss: 74277.3105 - val_recon_mean_squared_error: 1.0400 - val_reg_output_mean_squared_error: 74277.3105\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 71002.8943 - recon_loss: 1.0921 - reg_output_loss: 70893.6859 - recon_mean_squared_error: 1.0921 - reg_output_mean_squared_error: 70893.6859 - val_loss: 74134.5464 - val_recon_loss: 1.0192 - val_reg_output_loss: 74032.6250 - val_recon_mean_squared_error: 1.0192 - val_reg_output_mean_squared_error: 74032.6250\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 737us/step - loss: 71589.1520 - recon_loss: 1.1086 - reg_output_loss: 71478.2907 - recon_mean_squared_error: 1.1086 - reg_output_mean_squared_error: 71478.2907 - val_loss: 74175.9612 - val_recon_loss: 1.0082 - val_reg_output_loss: 74075.1381 - val_recon_mean_squared_error: 1.0082 - val_reg_output_mean_squared_error: 74075.1381\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 69108.3940 - recon_loss: 1.1728 - reg_output_loss: 68991.1123 - recon_mean_squared_error: 1.1728 - reg_output_mean_squared_error: 68991.1123 - val_loss: 74466.9134 - val_recon_loss: 1.0135 - val_reg_output_loss: 74365.5630 - val_recon_mean_squared_error: 1.0135 - val_reg_output_mean_squared_error: 74365.5630\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 72727.6164 - recon_loss: 1.1191 - reg_output_loss: 72615.7086 - recon_mean_squared_error: 1.1191 - reg_output_mean_squared_error: 72615.7086 - val_loss: 74545.3802 - val_recon_loss: 1.0074 - val_reg_output_loss: 74444.6356 - val_recon_mean_squared_error: 1.0074 - val_reg_output_mean_squared_error: 74444.6356\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 73330.7026 - recon_loss: 1.2856 - reg_output_loss: 73202.1468 - recon_mean_squared_error: 1.2856 - reg_output_mean_squared_error: 73202.1468 - val_loss: 74063.3831 - val_recon_loss: 1.0148 - val_reg_output_loss: 73961.9028 - val_recon_mean_squared_error: 1.0148 - val_reg_output_mean_squared_error: 73961.9028\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70486.9880 - recon_loss: 1.1439 - reg_output_loss: 70372.5996 - recon_mean_squared_error: 1.1439 - reg_output_mean_squared_error: 70372.5996 - val_loss: 73955.6552 - val_recon_loss: 1.0065 - val_reg_output_loss: 73855.0016 - val_recon_mean_squared_error: 1.0065 - val_reg_output_mean_squared_error: 73855.0016\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 68617.1931 - recon_loss: 1.1766 - reg_output_loss: 68499.5368 - recon_mean_squared_error: 1.1766 - reg_output_mean_squared_error: 68499.5368 - val_loss: 74187.6011 - val_recon_loss: 1.0043 - val_reg_output_loss: 74087.1670 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 74087.1670\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 68039.1900 - recon_loss: 1.1988 - reg_output_loss: 67919.3136 - recon_mean_squared_error: 1.1988 - reg_output_mean_squared_error: 67919.3136 - val_loss: 74690.3822 - val_recon_loss: 1.0053 - val_reg_output_loss: 74589.8484 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 74589.8484\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 70762.9134 - recon_loss: 1.1746 - reg_output_loss: 70645.4551 - recon_mean_squared_error: 1.1746 - reg_output_mean_squared_error: 70645.4551 - val_loss: 74626.0083 - val_recon_loss: 1.0047 - val_reg_output_loss: 74525.5338 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 74525.5338\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 668us/step - loss: 73091.7007 - recon_loss: 1.3411 - reg_output_loss: 72957.5909 - recon_mean_squared_error: 1.3411 - reg_output_mean_squared_error: 72957.5909 - val_loss: 73828.3488 - val_recon_loss: 1.0122 - val_reg_output_loss: 73727.1252 - val_recon_mean_squared_error: 1.0122 - val_reg_output_mean_squared_error: 73727.1252\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 70144.0880 - recon_loss: 1.0483 - reg_output_loss: 70039.2591 - recon_mean_squared_error: 1.0483 - reg_output_mean_squared_error: 70039.2591 - val_loss: 73881.0175 - val_recon_loss: 1.0113 - val_reg_output_loss: 73779.8914 - val_recon_mean_squared_error: 1.0113 - val_reg_output_mean_squared_error: 73779.8914\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 70695.5125 - recon_loss: 1.0764 - reg_output_loss: 70587.8772 - recon_mean_squared_error: 1.0764 - reg_output_mean_squared_error: 70587.8772 - val_loss: 73764.0059 - val_recon_loss: 1.0122 - val_reg_output_loss: 73662.7866 - val_recon_mean_squared_error: 1.0122 - val_reg_output_mean_squared_error: 73662.7866\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 71890.3603 - recon_loss: 1.1203 - reg_output_loss: 71778.3344 - recon_mean_squared_error: 1.1203 - reg_output_mean_squared_error: 71778.3344 - val_loss: 73258.1319 - val_recon_loss: 1.0151 - val_reg_output_loss: 73156.6225 - val_recon_mean_squared_error: 1.0151 - val_reg_output_mean_squared_error: 73156.6225\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 72311.2072 - recon_loss: 1.1713 - reg_output_loss: 72194.0747 - recon_mean_squared_error: 1.1713 - reg_output_mean_squared_error: 72194.0747 - val_loss: 73390.1816 - val_recon_loss: 1.0333 - val_reg_output_loss: 73286.8517 - val_recon_mean_squared_error: 1.0333 - val_reg_output_mean_squared_error: 73286.8517\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 74330.5099 - recon_loss: 1.0525 - reg_output_loss: 74225.2607 - recon_mean_squared_error: 1.0525 - reg_output_mean_squared_error: 74225.2607 - val_loss: 73273.8222 - val_recon_loss: 1.0062 - val_reg_output_loss: 73173.1984 - val_recon_mean_squared_error: 1.0062 - val_reg_output_mean_squared_error: 73173.1984\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 72680.4121 - recon_loss: 1.1027 - reg_output_loss: 72570.1406 - recon_mean_squared_error: 1.1027 - reg_output_mean_squared_error: 72570.1406 - val_loss: 73429.4595 - val_recon_loss: 1.0066 - val_reg_output_loss: 73328.7997 - val_recon_mean_squared_error: 1.0066 - val_reg_output_mean_squared_error: 73328.7997\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 71407.5524 - recon_loss: 1.0666 - reg_output_loss: 71300.8940 - recon_mean_squared_error: 1.0666 - reg_output_mean_squared_error: 71300.8940 - val_loss: 73632.9920 - val_recon_loss: 1.0122 - val_reg_output_loss: 73531.7741 - val_recon_mean_squared_error: 1.0122 - val_reg_output_mean_squared_error: 73531.7741\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70771.6472 - recon_loss: 1.1321 - reg_output_loss: 70658.4425 - recon_mean_squared_error: 1.1321 - reg_output_mean_squared_error: 70658.4425 - val_loss: 73735.1727 - val_recon_loss: 1.0065 - val_reg_output_loss: 73634.5225 - val_recon_mean_squared_error: 1.0065 - val_reg_output_mean_squared_error: 73634.5225\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70276.4167 - recon_loss: 1.0699 - reg_output_loss: 70169.4279 - recon_mean_squared_error: 1.0699 - reg_output_mean_squared_error: 70169.4279 - val_loss: 73958.5697 - val_recon_loss: 1.0121 - val_reg_output_loss: 73857.3594 - val_recon_mean_squared_error: 1.0121 - val_reg_output_mean_squared_error: 73857.3594\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 70086.7315 - recon_loss: 1.2665 - reg_output_loss: 69960.0830 - recon_mean_squared_error: 1.2665 - reg_output_mean_squared_error: 69960.0830 - val_loss: 74132.1355 - val_recon_loss: 1.0101 - val_reg_output_loss: 74031.1305 - val_recon_mean_squared_error: 1.0101 - val_reg_output_mean_squared_error: 74031.1305\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 70374.5098 - recon_loss: 1.1798 - reg_output_loss: 70256.5251 - recon_mean_squared_error: 1.1798 - reg_output_mean_squared_error: 70256.5251 - val_loss: 73878.2498 - val_recon_loss: 1.0078 - val_reg_output_loss: 73777.4677 - val_recon_mean_squared_error: 1.0078 - val_reg_output_mean_squared_error: 73777.4677\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70686.5180 - recon_loss: 1.1174 - reg_output_loss: 70574.7754 - recon_mean_squared_error: 1.1174 - reg_output_mean_squared_error: 70574.7754 - val_loss: 73419.6022 - val_recon_loss: 1.0089 - val_reg_output_loss: 73318.7092 - val_recon_mean_squared_error: 1.0089 - val_reg_output_mean_squared_error: 73318.7092\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 640us/step - loss: 69682.5472 - recon_loss: 1.1083 - reg_output_loss: 69571.7150 - recon_mean_squared_error: 1.1083 - reg_output_mean_squared_error: 69571.7150 - val_loss: 73771.1156 - val_recon_loss: 1.0098 - val_reg_output_loss: 73670.1364 - val_recon_mean_squared_error: 1.0098 - val_reg_output_mean_squared_error: 73670.1364\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 68791.7970 - recon_loss: 1.1194 - reg_output_loss: 68679.8529 - recon_mean_squared_error: 1.1194 - reg_output_mean_squared_error: 68679.8529 - val_loss: 74020.2836 - val_recon_loss: 1.0464 - val_reg_output_loss: 73915.6478 - val_recon_mean_squared_error: 1.0464 - val_reg_output_mean_squared_error: 73915.6478\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 70012.7951 - recon_loss: 1.0789 - reg_output_loss: 69904.9035 - recon_mean_squared_error: 1.0789 - reg_output_mean_squared_error: 69904.9035 - val_loss: 73643.7622 - val_recon_loss: 1.0029 - val_reg_output_loss: 73543.4744 - val_recon_mean_squared_error: 1.0029 - val_reg_output_mean_squared_error: 73543.4744\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 70131.0548 - recon_loss: 1.0985 - reg_output_loss: 70021.2010 - recon_mean_squared_error: 1.0985 - reg_output_mean_squared_error: 70021.2010 - val_loss: 73716.2845 - val_recon_loss: 1.0067 - val_reg_output_loss: 73615.6120 - val_recon_mean_squared_error: 1.0067 - val_reg_output_mean_squared_error: 73615.6120\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 70773.7493 - recon_loss: 1.1078 - reg_output_loss: 70662.9661 - recon_mean_squared_error: 1.1078 - reg_output_mean_squared_error: 70662.9661 - val_loss: 73690.4111 - val_recon_loss: 1.0127 - val_reg_output_loss: 73589.1409 - val_recon_mean_squared_error: 1.0127 - val_reg_output_mean_squared_error: 73589.1409\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69349.0233 - recon_loss: 1.0784 - reg_output_loss: 69241.1813 - recon_mean_squared_error: 1.0784 - reg_output_mean_squared_error: 69241.1813 - val_loss: 73895.1569 - val_recon_loss: 1.0293 - val_reg_output_loss: 73792.2302 - val_recon_mean_squared_error: 1.0293 - val_reg_output_mean_squared_error: 73792.2302\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69864.2614 - recon_loss: 1.1053 - reg_output_loss: 69753.7337 - recon_mean_squared_error: 1.1053 - reg_output_mean_squared_error: 69753.7337 - val_loss: 74022.7045 - val_recon_loss: 1.0104 - val_reg_output_loss: 73921.6605 - val_recon_mean_squared_error: 1.0104 - val_reg_output_mean_squared_error: 73921.6605\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 69763.8891 - recon_loss: 1.1046 - reg_output_loss: 69653.4238 - recon_mean_squared_error: 1.1046 - reg_output_mean_squared_error: 69653.4238 - val_loss: 74128.7794 - val_recon_loss: 1.0315 - val_reg_output_loss: 74025.6252 - val_recon_mean_squared_error: 1.0315 - val_reg_output_mean_squared_error: 74025.6252\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 69640.3115 - recon_loss: 1.1048 - reg_output_loss: 69529.8327 - recon_mean_squared_error: 1.1048 - reg_output_mean_squared_error: 69529.8327 - val_loss: 73728.2736 - val_recon_loss: 1.0054 - val_reg_output_loss: 73627.7347 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 73627.7347\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71190.6561 - recon_loss: 1.0703 - reg_output_loss: 71083.6253 - recon_mean_squared_error: 1.0703 - reg_output_mean_squared_error: 71083.6253 - val_loss: 73974.3345 - val_recon_loss: 1.0087 - val_reg_output_loss: 73873.4684 - val_recon_mean_squared_error: 1.0087 - val_reg_output_mean_squared_error: 73873.4684\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71883.0683 - recon_loss: 1.0942 - reg_output_loss: 71773.6528 - recon_mean_squared_error: 1.0942 - reg_output_mean_squared_error: 71773.6528 - val_loss: 73932.0059 - val_recon_loss: 1.0103 - val_reg_output_loss: 73830.9738 - val_recon_mean_squared_error: 1.0103 - val_reg_output_mean_squared_error: 73830.9738\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 72233.3983 - recon_loss: 1.2513 - reg_output_loss: 72108.2657 - recon_mean_squared_error: 1.2513 - reg_output_mean_squared_error: 72108.2657 - val_loss: 73466.6370 - val_recon_loss: 1.0118 - val_reg_output_loss: 73365.4603 - val_recon_mean_squared_error: 1.0118 - val_reg_output_mean_squared_error: 73365.4603\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70319.1875 - recon_loss: 1.1767 - reg_output_loss: 70201.5197 - recon_mean_squared_error: 1.1767 - reg_output_mean_squared_error: 70201.5197 - val_loss: 73500.4187 - val_recon_loss: 1.0058 - val_reg_output_loss: 73399.8386 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 73399.8386\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 69330.6209 - recon_loss: 1.1144 - reg_output_loss: 69219.1822 - recon_mean_squared_error: 1.1144 - reg_output_mean_squared_error: 69219.1822 - val_loss: 73465.3761 - val_recon_loss: 1.0372 - val_reg_output_loss: 73361.6512 - val_recon_mean_squared_error: 1.0372 - val_reg_output_mean_squared_error: 73361.6512\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 69954.8813 - recon_loss: 1.0555 - reg_output_loss: 69849.3306 - recon_mean_squared_error: 1.0555 - reg_output_mean_squared_error: 69849.3306 - val_loss: 73557.2398 - val_recon_loss: 1.0048 - val_reg_output_loss: 73456.7625 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73456.7625\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70856.5568 - recon_loss: 1.0406 - reg_output_loss: 70752.4989 - recon_mean_squared_error: 1.0406 - reg_output_mean_squared_error: 70752.4989 - val_loss: 73733.7863 - val_recon_loss: 1.0091 - val_reg_output_loss: 73632.8800 - val_recon_mean_squared_error: 1.0091 - val_reg_output_mean_squared_error: 73632.8800\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 68066.4729 - recon_loss: 1.1371 - reg_output_loss: 67952.7642 - recon_mean_squared_error: 1.1371 - reg_output_mean_squared_error: 67952.7642 - val_loss: 74078.0891 - val_recon_loss: 1.0073 - val_reg_output_loss: 73977.3566 - val_recon_mean_squared_error: 1.0073 - val_reg_output_mean_squared_error: 73977.3566\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 72041.3424 - recon_loss: 1.0478 - reg_output_loss: 71936.5639 - recon_mean_squared_error: 1.0478 - reg_output_mean_squared_error: 71936.5639 - val_loss: 73829.0430 - val_recon_loss: 1.0074 - val_reg_output_loss: 73728.3030 - val_recon_mean_squared_error: 1.0074 - val_reg_output_mean_squared_error: 73728.3030\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 70753.8982 - recon_loss: 1.0582 - reg_output_loss: 70648.0765 - recon_mean_squared_error: 1.0582 - reg_output_mean_squared_error: 70648.0765 - val_loss: 73881.9359 - val_recon_loss: 1.0060 - val_reg_output_loss: 73781.3378 - val_recon_mean_squared_error: 1.0060 - val_reg_output_mean_squared_error: 73781.3378\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 71450.6099 - recon_loss: 1.0434 - reg_output_loss: 71346.2734 - recon_mean_squared_error: 1.0434 - reg_output_mean_squared_error: 71346.2734 - val_loss: 73652.7558 - val_recon_loss: 1.0182 - val_reg_output_loss: 73550.9309 - val_recon_mean_squared_error: 1.0182 - val_reg_output_mean_squared_error: 73550.9309\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 643us/step - loss: 70070.6062 - recon_loss: 1.0815 - reg_output_loss: 69962.4565 - recon_mean_squared_error: 1.0815 - reg_output_mean_squared_error: 69962.4565 - val_loss: 73447.1327 - val_recon_loss: 1.0052 - val_reg_output_loss: 73346.6170 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 73346.6170\n",
      "Epoch 222/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71458.0516 - recon_loss: 1.0473 - reg_output_loss: 71353.3253 - recon_mean_squared_error: 1.0473 - reg_output_mean_squared_error: 71353.3253 - val_loss: 73172.0939 - val_recon_loss: 1.0032 - val_reg_output_loss: 73071.7750 - val_recon_mean_squared_error: 1.0032 - val_reg_output_mean_squared_error: 73071.7750\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 73692.0760 - recon_loss: 1.0774 - reg_output_loss: 73584.3404 - recon_mean_squared_error: 1.0774 - reg_output_mean_squared_error: 73584.3404 - val_loss: 72844.9864 - val_recon_loss: 1.0058 - val_reg_output_loss: 72744.4047 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 72744.4047\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71531.2153 - recon_loss: 1.0884 - reg_output_loss: 71422.3780 - recon_mean_squared_error: 1.0884 - reg_output_mean_squared_error: 71422.3780 - val_loss: 72702.0272 - val_recon_loss: 1.0226 - val_reg_output_loss: 72599.7698 - val_recon_mean_squared_error: 1.0226 - val_reg_output_mean_squared_error: 72599.7698\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 71557.5165 - recon_loss: 1.0796 - reg_output_loss: 71449.5538 - recon_mean_squared_error: 1.0796 - reg_output_mean_squared_error: 71449.5538 - val_loss: 72828.6697 - val_recon_loss: 1.0062 - val_reg_output_loss: 72728.0478 - val_recon_mean_squared_error: 1.0062 - val_reg_output_mean_squared_error: 72728.0478\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 72920.8539 - recon_loss: 1.0464 - reg_output_loss: 72816.2143 - recon_mean_squared_error: 1.0464 - reg_output_mean_squared_error: 72816.2143 - val_loss: 72545.7742 - val_recon_loss: 1.0080 - val_reg_output_loss: 72444.9772 - val_recon_mean_squared_error: 1.0080 - val_reg_output_mean_squared_error: 72444.9772\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 71352.9860 - recon_loss: 1.1617 - reg_output_loss: 71236.8176 - recon_mean_squared_error: 1.1617 - reg_output_mean_squared_error: 71236.8176 - val_loss: 72667.0302 - val_recon_loss: 1.0043 - val_reg_output_loss: 72566.5981 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 72566.5981\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 71095.9716 - recon_loss: 1.0546 - reg_output_loss: 70990.5080 - recon_mean_squared_error: 1.0546 - reg_output_mean_squared_error: 70990.5080 - val_loss: 73231.0556 - val_recon_loss: 1.0067 - val_reg_output_loss: 73130.3847 - val_recon_mean_squared_error: 1.0067 - val_reg_output_mean_squared_error: 73130.3847\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 655us/step - loss: 68900.3781 - recon_loss: 1.0926 - reg_output_loss: 68791.1179 - recon_mean_squared_error: 1.0926 - reg_output_mean_squared_error: 68791.1179 - val_loss: 73429.2666 - val_recon_loss: 1.0222 - val_reg_output_loss: 73327.0469 - val_recon_mean_squared_error: 1.0222 - val_reg_output_mean_squared_error: 73327.0469\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71370.5051 - recon_loss: 1.0481 - reg_output_loss: 71265.6935 - recon_mean_squared_error: 1.0481 - reg_output_mean_squared_error: 71265.6935 - val_loss: 73140.7603 - val_recon_loss: 1.0045 - val_reg_output_loss: 73040.3047 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73040.3047\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 647us/step - loss: 71246.3964 - recon_loss: 1.0456 - reg_output_loss: 71141.8334 - recon_mean_squared_error: 1.0456 - reg_output_mean_squared_error: 71141.8334 - val_loss: 73137.3739 - val_recon_loss: 1.0245 - val_reg_output_loss: 73034.9191 - val_recon_mean_squared_error: 1.0245 - val_reg_output_mean_squared_error: 73034.9191\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 71781.9659 - recon_loss: 1.0332 - reg_output_loss: 71678.6471 - recon_mean_squared_error: 1.0332 - reg_output_mean_squared_error: 71678.6471 - val_loss: 72995.4855 - val_recon_loss: 1.0032 - val_reg_output_loss: 72895.1702 - val_recon_mean_squared_error: 1.0032 - val_reg_output_mean_squared_error: 72895.1702\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 69020.1298 - recon_loss: 1.0488 - reg_output_loss: 68915.2461 - recon_mean_squared_error: 1.0488 - reg_output_mean_squared_error: 68915.2461 - val_loss: 73032.5278 - val_recon_loss: 1.0756 - val_reg_output_loss: 72924.9706 - val_recon_mean_squared_error: 1.0756 - val_reg_output_mean_squared_error: 72924.9706\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 72431.1106 - recon_loss: 1.0783 - reg_output_loss: 72323.2835 - recon_mean_squared_error: 1.0783 - reg_output_mean_squared_error: 72323.2835 - val_loss: 72967.5431 - val_recon_loss: 1.0041 - val_reg_output_loss: 72867.1314 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 72867.1314\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 71453.5918 - recon_loss: 1.0603 - reg_output_loss: 71347.5575 - recon_mean_squared_error: 1.0603 - reg_output_mean_squared_error: 71347.5575 - val_loss: 72858.5575 - val_recon_loss: 1.0071 - val_reg_output_loss: 72757.8475 - val_recon_mean_squared_error: 1.0071 - val_reg_output_mean_squared_error: 72757.8475\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69454.5807 - recon_loss: 1.0446 - reg_output_loss: 69350.1233 - recon_mean_squared_error: 1.0446 - reg_output_mean_squared_error: 69350.1233 - val_loss: 72764.0206 - val_recon_loss: 1.0067 - val_reg_output_loss: 72663.3525 - val_recon_mean_squared_error: 1.0067 - val_reg_output_mean_squared_error: 72663.3525\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 69492.6058 - recon_loss: 1.0672 - reg_output_loss: 69385.8863 - recon_mean_squared_error: 1.0672 - reg_output_mean_squared_error: 69385.8863 - val_loss: 73190.3334 - val_recon_loss: 1.0190 - val_reg_output_loss: 73088.4314 - val_recon_mean_squared_error: 1.0190 - val_reg_output_mean_squared_error: 73088.4314\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 70159.4479 - recon_loss: 1.0478 - reg_output_loss: 70054.6708 - recon_mean_squared_error: 1.0478 - reg_output_mean_squared_error: 70054.6708 - val_loss: 73372.1333 - val_recon_loss: 1.0078 - val_reg_output_loss: 73271.3558 - val_recon_mean_squared_error: 1.0078 - val_reg_output_mean_squared_error: 73271.3558\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 69663.6377 - recon_loss: 1.0559 - reg_output_loss: 69558.0461 - recon_mean_squared_error: 1.0559 - reg_output_mean_squared_error: 69558.0461 - val_loss: 73484.8467 - val_recon_loss: 1.0044 - val_reg_output_loss: 73384.4102 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73384.4102\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 67788.9360 - recon_loss: 1.1156 - reg_output_loss: 67677.3721 - recon_mean_squared_error: 1.1156 - reg_output_mean_squared_error: 67677.3721 - val_loss: 73247.2364 - val_recon_loss: 1.0068 - val_reg_output_loss: 73146.5522 - val_recon_mean_squared_error: 1.0068 - val_reg_output_mean_squared_error: 73146.5522\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 70316.6458 - recon_loss: 1.0484 - reg_output_loss: 70211.8077 - recon_mean_squared_error: 1.0484 - reg_output_mean_squared_error: 70211.8077 - val_loss: 73377.2258 - val_recon_loss: 1.0051 - val_reg_output_loss: 73276.7202 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 73276.7202\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 68001.6851 - recon_loss: 1.1381 - reg_output_loss: 67887.8759 - recon_mean_squared_error: 1.1381 - reg_output_mean_squared_error: 67887.8759 - val_loss: 73845.8803 - val_recon_loss: 1.0058 - val_reg_output_loss: 73745.2975 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 73745.2975\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70139.4069 - recon_loss: 1.0851 - reg_output_loss: 70030.8981 - recon_mean_squared_error: 1.0851 - reg_output_mean_squared_error: 70030.8981 - val_loss: 73556.4155 - val_recon_loss: 1.0042 - val_reg_output_loss: 73455.9967 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73455.9967\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 69997.4633 - recon_loss: 1.0235 - reg_output_loss: 69895.1174 - recon_mean_squared_error: 1.0235 - reg_output_mean_squared_error: 69895.1174 - val_loss: 73698.3405 - val_recon_loss: 1.0047 - val_reg_output_loss: 73597.8703 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 73597.8703\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 72877.9602 - recon_loss: 1.0795 - reg_output_loss: 72770.0143 - recon_mean_squared_error: 1.0795 - reg_output_mean_squared_error: 72770.0143 - val_loss: 73399.2706 - val_recon_loss: 1.0093 - val_reg_output_loss: 73298.3438 - val_recon_mean_squared_error: 1.0093 - val_reg_output_mean_squared_error: 73298.3438\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 70580.8573 - recon_loss: 1.0455 - reg_output_loss: 70476.3100 - recon_mean_squared_error: 1.0455 - reg_output_mean_squared_error: 70476.3100 - val_loss: 73058.4113 - val_recon_loss: 1.0070 - val_reg_output_loss: 72957.7086 - val_recon_mean_squared_error: 1.0070 - val_reg_output_mean_squared_error: 72957.7086\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68877.3747 - recon_loss: 1.0600 - reg_output_loss: 68771.3792 - recon_mean_squared_error: 1.0600 - reg_output_mean_squared_error: 68771.3792 - val_loss: 73262.7972 - val_recon_loss: 1.0070 - val_reg_output_loss: 73162.0991 - val_recon_mean_squared_error: 1.0070 - val_reg_output_mean_squared_error: 73162.0991\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 68955.0079 - recon_loss: 1.0557 - reg_output_loss: 68849.4339 - recon_mean_squared_error: 1.0557 - reg_output_mean_squared_error: 68849.4339 - val_loss: 73023.0963 - val_recon_loss: 1.0067 - val_reg_output_loss: 72922.4288 - val_recon_mean_squared_error: 1.0067 - val_reg_output_mean_squared_error: 72922.4288\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 69432.8270 - recon_loss: 1.0330 - reg_output_loss: 69329.5260 - recon_mean_squared_error: 1.0330 - reg_output_mean_squared_error: 69329.5260 - val_loss: 73067.0502 - val_recon_loss: 1.0066 - val_reg_output_loss: 72966.3944 - val_recon_mean_squared_error: 1.0066 - val_reg_output_mean_squared_error: 72966.3944\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 68783.3990 - recon_loss: 1.0478 - reg_output_loss: 68678.6229 - recon_mean_squared_error: 1.0478 - reg_output_mean_squared_error: 68678.6229 - val_loss: 73008.7611 - val_recon_loss: 1.0075 - val_reg_output_loss: 72908.0103 - val_recon_mean_squared_error: 1.0075 - val_reg_output_mean_squared_error: 72908.0103\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 710us/step - loss: 70094.0908 - recon_loss: 1.0223 - reg_output_loss: 69991.8599 - recon_mean_squared_error: 1.0223 - reg_output_mean_squared_error: 69991.8599 - val_loss: 73490.8100 - val_recon_loss: 1.0049 - val_reg_output_loss: 73390.3203 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73390.3203\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 67723.8067 - recon_loss: 1.0324 - reg_output_loss: 67620.5663 - recon_mean_squared_error: 1.0324 - reg_output_mean_squared_error: 67620.5663 - val_loss: 73595.0214 - val_recon_loss: 1.0058 - val_reg_output_loss: 73494.4397 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 73494.4397\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 71079.5947 - recon_loss: 1.0352 - reg_output_loss: 70976.0795 - recon_mean_squared_error: 1.0352 - reg_output_mean_squared_error: 70976.0795 - val_loss: 73243.3877 - val_recon_loss: 1.0061 - val_reg_output_loss: 73142.7777 - val_recon_mean_squared_error: 1.0061 - val_reg_output_mean_squared_error: 73142.7777\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 740us/step - loss: 69515.7691 - recon_loss: 1.0294 - reg_output_loss: 69412.8311 - recon_mean_squared_error: 1.0294 - reg_output_mean_squared_error: 69412.8311 - val_loss: 73479.4756 - val_recon_loss: 1.0119 - val_reg_output_loss: 73378.2894 - val_recon_mean_squared_error: 1.0119 - val_reg_output_mean_squared_error: 73378.2894\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 787us/step - loss: 70729.8086 - recon_loss: 1.0472 - reg_output_loss: 70625.0835 - recon_mean_squared_error: 1.0472 - reg_output_mean_squared_error: 70625.0835 - val_loss: 73215.3147 - val_recon_loss: 1.0201 - val_reg_output_loss: 73113.3069 - val_recon_mean_squared_error: 1.0201 - val_reg_output_mean_squared_error: 73113.3069\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 740us/step - loss: 72450.4720 - recon_loss: 1.0881 - reg_output_loss: 72341.6639 - recon_mean_squared_error: 1.0881 - reg_output_mean_squared_error: 72341.6639 - val_loss: 72867.8619 - val_recon_loss: 1.0068 - val_reg_output_loss: 72767.1789 - val_recon_mean_squared_error: 1.0068 - val_reg_output_mean_squared_error: 72767.1789\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 740us/step - loss: 71372.5755 - recon_loss: 1.0281 - reg_output_loss: 71269.7641 - recon_mean_squared_error: 1.0281 - reg_output_mean_squared_error: 71269.7641 - val_loss: 72726.3033 - val_recon_loss: 1.0059 - val_reg_output_loss: 72625.7100 - val_recon_mean_squared_error: 1.0059 - val_reg_output_mean_squared_error: 72625.7100\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 70928.5114 - recon_loss: 1.0208 - reg_output_loss: 70826.4313 - recon_mean_squared_error: 1.0208 - reg_output_mean_squared_error: 70826.4313 - val_loss: 73049.0191 - val_recon_loss: 1.0526 - val_reg_output_loss: 72943.7623 - val_recon_mean_squared_error: 1.0526 - val_reg_output_mean_squared_error: 72943.7623\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70618.8767 - recon_loss: 1.0353 - reg_output_loss: 70515.3423 - recon_mean_squared_error: 1.0353 - reg_output_mean_squared_error: 70515.3423 - val_loss: 73107.8837 - val_recon_loss: 1.0097 - val_reg_output_loss: 73006.9167 - val_recon_mean_squared_error: 1.0097 - val_reg_output_mean_squared_error: 73006.9167\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 723us/step - loss: 72030.9999 - recon_loss: 1.0418 - reg_output_loss: 71926.8227 - recon_mean_squared_error: 1.0418 - reg_output_mean_squared_error: 71926.8227 - val_loss: 73012.9998 - val_recon_loss: 1.0055 - val_reg_output_loss: 72912.4541 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 72912.4541\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71451.7311 - recon_loss: 1.0596 - reg_output_loss: 71345.7726 - recon_mean_squared_error: 1.0596 - reg_output_mean_squared_error: 71345.7726 - val_loss: 72938.7316 - val_recon_loss: 1.0041 - val_reg_output_loss: 72838.3211 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 72838.3211\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 69738.2993 - recon_loss: 1.0352 - reg_output_loss: 69634.7831 - recon_mean_squared_error: 1.0352 - reg_output_mean_squared_error: 69634.7831 - val_loss: 73083.9436 - val_recon_loss: 1.0185 - val_reg_output_loss: 72982.0919 - val_recon_mean_squared_error: 1.0185 - val_reg_output_mean_squared_error: 72982.0919\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 72850.0928 - recon_loss: 1.0510 - reg_output_loss: 72744.9956 - recon_mean_squared_error: 1.0510 - reg_output_mean_squared_error: 72744.9956 - val_loss: 72964.4805 - val_recon_loss: 1.0124 - val_reg_output_loss: 72863.2455 - val_recon_mean_squared_error: 1.0124 - val_reg_output_mean_squared_error: 72863.2455\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 71616.0040 - recon_loss: 1.0291 - reg_output_loss: 71513.0972 - recon_mean_squared_error: 1.0291 - reg_output_mean_squared_error: 71513.0972 - val_loss: 72868.6023 - val_recon_loss: 1.0036 - val_reg_output_loss: 72768.2394 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 72768.2394\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 68152.2560 - recon_loss: 1.0504 - reg_output_loss: 68047.2169 - recon_mean_squared_error: 1.0504 - reg_output_mean_squared_error: 68047.2169 - val_loss: 73090.7778 - val_recon_loss: 1.0141 - val_reg_output_loss: 72989.3663 - val_recon_mean_squared_error: 1.0141 - val_reg_output_mean_squared_error: 72989.3663\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 668us/step - loss: 69760.2634 - recon_loss: 1.0418 - reg_output_loss: 69656.0846 - recon_mean_squared_error: 1.0418 - reg_output_mean_squared_error: 69656.0846 - val_loss: 72726.8241 - val_recon_loss: 1.0048 - val_reg_output_loss: 72626.3436 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 72626.3436\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 68243.0115 - recon_loss: 1.0707 - reg_output_loss: 68135.9368 - recon_mean_squared_error: 1.0707 - reg_output_mean_squared_error: 68135.9368 - val_loss: 72998.6987 - val_recon_loss: 1.0038 - val_reg_output_loss: 72898.3148 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72898.3148\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71549.4746 - recon_loss: 1.0324 - reg_output_loss: 71446.2399 - recon_mean_squared_error: 1.0324 - reg_output_mean_squared_error: 71446.2399 - val_loss: 73006.2939 - val_recon_loss: 1.0059 - val_reg_output_loss: 72905.7058 - val_recon_mean_squared_error: 1.0059 - val_reg_output_mean_squared_error: 72905.7058\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70369.3951 - recon_loss: 1.0216 - reg_output_loss: 70267.2321 - recon_mean_squared_error: 1.0216 - reg_output_mean_squared_error: 70267.2321 - val_loss: 72935.9138 - val_recon_loss: 1.0039 - val_reg_output_loss: 72835.5281 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 72835.5281\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 70698.4208 - recon_loss: 1.0291 - reg_output_loss: 70595.5072 - recon_mean_squared_error: 1.0291 - reg_output_mean_squared_error: 70595.5072 - val_loss: 72939.7378 - val_recon_loss: 1.0047 - val_reg_output_loss: 72839.2703 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 72839.2703\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 650us/step - loss: 70858.1829 - recon_loss: 1.0297 - reg_output_loss: 70755.2167 - recon_mean_squared_error: 1.0297 - reg_output_mean_squared_error: 70755.2167 - val_loss: 72811.8712 - val_recon_loss: 1.0051 - val_reg_output_loss: 72711.3595 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 72711.3595\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 69970.6825 - recon_loss: 1.0260 - reg_output_loss: 69868.0848 - recon_mean_squared_error: 1.0260 - reg_output_mean_squared_error: 69868.0848 - val_loss: 72959.8461 - val_recon_loss: 1.0069 - val_reg_output_loss: 72859.1539 - val_recon_mean_squared_error: 1.0069 - val_reg_output_mean_squared_error: 72859.1539\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 733us/step - loss: 69315.3002 - recon_loss: 1.0180 - reg_output_loss: 69213.5019 - recon_mean_squared_error: 1.0180 - reg_output_mean_squared_error: 69213.5019 - val_loss: 73328.8712 - val_recon_loss: 1.0066 - val_reg_output_loss: 73228.2098 - val_recon_mean_squared_error: 1.0066 - val_reg_output_mean_squared_error: 73228.2098\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 727us/step - loss: 68421.4571 - recon_loss: 1.0220 - reg_output_loss: 68319.2555 - recon_mean_squared_error: 1.0220 - reg_output_mean_squared_error: 68319.2555 - val_loss: 73370.0745 - val_recon_loss: 1.0054 - val_reg_output_loss: 73269.5377 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 73269.5377\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 737us/step - loss: 70547.5928 - recon_loss: 1.0254 - reg_output_loss: 70445.0489 - recon_mean_squared_error: 1.0254 - reg_output_mean_squared_error: 70445.0489 - val_loss: 73261.2566 - val_recon_loss: 1.0055 - val_reg_output_loss: 73160.7056 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 73160.7056\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 748us/step - loss: 69944.1276 - recon_loss: 1.0314 - reg_output_loss: 69840.9860 - recon_mean_squared_error: 1.0314 - reg_output_mean_squared_error: 69840.9860 - val_loss: 73429.0098 - val_recon_loss: 1.0041 - val_reg_output_loss: 73328.6036 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73328.6036\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 777us/step - loss: 68658.0008 - recon_loss: 1.0179 - reg_output_loss: 68556.2154 - recon_mean_squared_error: 1.0179 - reg_output_mean_squared_error: 68556.2154 - val_loss: 73097.6873 - val_recon_loss: 1.0101 - val_reg_output_loss: 72996.6772 - val_recon_mean_squared_error: 1.0101 - val_reg_output_mean_squared_error: 72996.6772\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 71990.1747 - recon_loss: 1.0265 - reg_output_loss: 71887.5285 - recon_mean_squared_error: 1.0265 - reg_output_mean_squared_error: 71887.5285 - val_loss: 73009.1759 - val_recon_loss: 1.0051 - val_reg_output_loss: 72908.6644 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 72908.6644\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 69950.4191 - recon_loss: 1.0208 - reg_output_loss: 69848.3422 - recon_mean_squared_error: 1.0208 - reg_output_mean_squared_error: 69848.3422 - val_loss: 73190.9239 - val_recon_loss: 1.0033 - val_reg_output_loss: 73090.5925 - val_recon_mean_squared_error: 1.0033 - val_reg_output_mean_squared_error: 73090.5925\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 71370.8451 - recon_loss: 1.0641 - reg_output_loss: 71264.4365 - recon_mean_squared_error: 1.0641 - reg_output_mean_squared_error: 71264.4365 - val_loss: 72880.0009 - val_recon_loss: 1.0046 - val_reg_output_loss: 72779.5419 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 72779.5419\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 69012.1390 - recon_loss: 1.0344 - reg_output_loss: 68908.6941 - recon_mean_squared_error: 1.0344 - reg_output_mean_squared_error: 68908.6941 - val_loss: 72970.1464 - val_recon_loss: 1.0035 - val_reg_output_loss: 72869.7912 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 72869.7912\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 740us/step - loss: 69346.8951 - recon_loss: 1.0358 - reg_output_loss: 69243.3161 - recon_mean_squared_error: 1.0358 - reg_output_mean_squared_error: 69243.3161 - val_loss: 73294.5080 - val_recon_loss: 1.0042 - val_reg_output_loss: 73194.0908 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73194.0908\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68177.5029 - recon_loss: 1.0130 - reg_output_loss: 68076.2061 - recon_mean_squared_error: 1.0130 - reg_output_mean_squared_error: 68076.2061 - val_loss: 73581.5539 - val_recon_loss: 1.0095 - val_reg_output_loss: 73480.6069 - val_recon_mean_squared_error: 1.0095 - val_reg_output_mean_squared_error: 73480.6069\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 67554.5490 - recon_loss: 1.0246 - reg_output_loss: 67452.0911 - recon_mean_squared_error: 1.0246 - reg_output_mean_squared_error: 67452.0911 - val_loss: 73894.4339 - val_recon_loss: 1.0041 - val_reg_output_loss: 73794.0273 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73794.0273\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68565.4506 - recon_loss: 1.0207 - reg_output_loss: 68463.3838 - recon_mean_squared_error: 1.0207 - reg_output_mean_squared_error: 68463.3838 - val_loss: 73926.3748 - val_recon_loss: 1.0053 - val_reg_output_loss: 73825.8498 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 73825.8498\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 69917.2954 - recon_loss: 1.0187 - reg_output_loss: 69815.4287 - recon_mean_squared_error: 1.0187 - reg_output_mean_squared_error: 69815.4287 - val_loss: 73676.6111 - val_recon_loss: 1.0055 - val_reg_output_loss: 73576.0641 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 73576.0641\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 71030.3041 - recon_loss: 1.0125 - reg_output_loss: 70929.0551 - recon_mean_squared_error: 1.0125 - reg_output_mean_squared_error: 70929.0551 - val_loss: 73564.4300 - val_recon_loss: 1.0041 - val_reg_output_loss: 73464.0188 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73464.0188\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 710us/step - loss: 68620.1544 - recon_loss: 1.0269 - reg_output_loss: 68517.4656 - recon_mean_squared_error: 1.0269 - reg_output_mean_squared_error: 68517.4656 - val_loss: 73404.9422 - val_recon_loss: 1.0037 - val_reg_output_loss: 73304.5748 - val_recon_mean_squared_error: 1.0037 - val_reg_output_mean_squared_error: 73304.5748\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 67645.4930 - recon_loss: 1.0204 - reg_output_loss: 67543.4541 - recon_mean_squared_error: 1.0204 - reg_output_mean_squared_error: 67543.4541 - val_loss: 73603.2366 - val_recon_loss: 1.0036 - val_reg_output_loss: 73502.8744 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 73502.8744\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 66975.1621 - recon_loss: 1.0202 - reg_output_loss: 66873.1440 - recon_mean_squared_error: 1.0202 - reg_output_mean_squared_error: 66873.1440 - val_loss: 73945.0838 - val_recon_loss: 1.0043 - val_reg_output_loss: 73844.6564 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 73844.6564\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 67869.5257 - recon_loss: 1.0113 - reg_output_loss: 67768.3998 - recon_mean_squared_error: 1.0113 - reg_output_mean_squared_error: 67768.3998 - val_loss: 74086.0523 - val_recon_loss: 1.0044 - val_reg_output_loss: 73985.6127 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73985.6127\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 68290.8348 - recon_loss: 1.0164 - reg_output_loss: 68189.1983 - recon_mean_squared_error: 1.0164 - reg_output_mean_squared_error: 68189.1983 - val_loss: 73755.7450 - val_recon_loss: 1.0036 - val_reg_output_loss: 73655.3856 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 73655.3856\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 68529.5541 - recon_loss: 1.0588 - reg_output_loss: 68423.6693 - recon_mean_squared_error: 1.0588 - reg_output_mean_squared_error: 68423.6693 - val_loss: 73683.1834 - val_recon_loss: 1.0050 - val_reg_output_loss: 73582.6880 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73582.6880\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 69666.4439 - recon_loss: 1.0261 - reg_output_loss: 69563.8313 - recon_mean_squared_error: 1.0261 - reg_output_mean_squared_error: 69563.8313 - val_loss: 73297.4823 - val_recon_loss: 1.0040 - val_reg_output_loss: 73197.0814 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 73197.0814\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 69271.1784 - recon_loss: 1.0088 - reg_output_loss: 69170.2999 - recon_mean_squared_error: 1.0088 - reg_output_mean_squared_error: 69170.2999 - val_loss: 73077.3184 - val_recon_loss: 1.0090 - val_reg_output_loss: 72976.4222 - val_recon_mean_squared_error: 1.0090 - val_reg_output_mean_squared_error: 72976.4222\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 64556.2090 - recon_loss: 1.0184 - reg_output_loss: 64454.3669 - recon_mean_squared_error: 1.0184 - reg_output_mean_squared_error: 64454.3669 - val_loss: 73610.3622 - val_recon_loss: 1.0047 - val_reg_output_loss: 73509.8941 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 73509.8941\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 70243.6388 - recon_loss: 1.0184 - reg_output_loss: 70141.8010 - recon_mean_squared_error: 1.0184 - reg_output_mean_squared_error: 70141.8010 - val_loss: 73291.8102 - val_recon_loss: 1.0069 - val_reg_output_loss: 73191.1170 - val_recon_mean_squared_error: 1.0069 - val_reg_output_mean_squared_error: 73191.1170\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 70770.2470 - recon_loss: 1.0080 - reg_output_loss: 70669.4442 - recon_mean_squared_error: 1.0080 - reg_output_mean_squared_error: 70669.4442 - val_loss: 73165.5972 - val_recon_loss: 1.0111 - val_reg_output_loss: 73064.4831 - val_recon_mean_squared_error: 1.0111 - val_reg_output_mean_squared_error: 73064.4831\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 69185.3995 - recon_loss: 1.0115 - reg_output_loss: 69084.2456 - recon_mean_squared_error: 1.0115 - reg_output_mean_squared_error: 69084.2456 - val_loss: 73183.6303 - val_recon_loss: 1.0031 - val_reg_output_loss: 73083.3195 - val_recon_mean_squared_error: 1.0031 - val_reg_output_mean_squared_error: 73083.3195\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 66798.2688 - recon_loss: 1.0133 - reg_output_loss: 66696.9358 - recon_mean_squared_error: 1.0133 - reg_output_mean_squared_error: 66696.9358 - val_loss: 73304.3858 - val_recon_loss: 1.0028 - val_reg_output_loss: 73204.1078 - val_recon_mean_squared_error: 1.0028 - val_reg_output_mean_squared_error: 73204.1078\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70813.7120 - recon_loss: 1.0153 - reg_output_loss: 70712.1822 - recon_mean_squared_error: 1.0153 - reg_output_mean_squared_error: 70712.1822 - val_loss: 73352.8619 - val_recon_loss: 1.0033 - val_reg_output_loss: 73252.5364 - val_recon_mean_squared_error: 1.0033 - val_reg_output_mean_squared_error: 73252.5364\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 72583.7425 - recon_loss: 1.0072 - reg_output_loss: 72483.0230 - recon_mean_squared_error: 1.0072 - reg_output_mean_squared_error: 72483.0230 - val_loss: 73142.2448 - val_recon_loss: 1.0044 - val_reg_output_loss: 73041.8006 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73041.8006\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 70160.6115 - recon_loss: 1.0116 - reg_output_loss: 70059.4501 - recon_mean_squared_error: 1.0116 - reg_output_mean_squared_error: 70059.4501 - val_loss: 73452.2805 - val_recon_loss: 1.0036 - val_reg_output_loss: 73351.9178 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 73351.9178\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 71080.3168 - recon_loss: 1.0156 - reg_output_loss: 70978.7538 - recon_mean_squared_error: 1.0156 - reg_output_mean_squared_error: 70978.7538 - val_loss: 73214.0970 - val_recon_loss: 1.0052 - val_reg_output_loss: 73113.5761 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 73113.5761\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 69328.9083 - recon_loss: 1.0110 - reg_output_loss: 69227.8042 - recon_mean_squared_error: 1.0110 - reg_output_mean_squared_error: 69227.8042 - val_loss: 73734.8488 - val_recon_loss: 1.0041 - val_reg_output_loss: 73634.4394 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73634.4394\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 71224.6678 - recon_loss: 1.0079 - reg_output_loss: 71123.8823 - recon_mean_squared_error: 1.0079 - reg_output_mean_squared_error: 71123.8823 - val_loss: 73116.3291 - val_recon_loss: 1.0049 - val_reg_output_loss: 73015.8403 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73015.8403\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 73045.8067 - recon_loss: 1.0089 - reg_output_loss: 72944.9117 - recon_mean_squared_error: 1.0089 - reg_output_mean_squared_error: 72944.9117 - val_loss: 73147.2173 - val_recon_loss: 1.0043 - val_reg_output_loss: 73046.7892 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 73046.7892\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 72715.5359 - recon_loss: 1.0078 - reg_output_loss: 72614.7574 - recon_mean_squared_error: 1.0078 - reg_output_mean_squared_error: 72614.7574 - val_loss: 72995.6339 - val_recon_loss: 1.0038 - val_reg_output_loss: 72895.2586 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72895.2586\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 73653.8354 - recon_loss: 1.0066 - reg_output_loss: 73553.1776 - recon_mean_squared_error: 1.0066 - reg_output_mean_squared_error: 73553.1776 - val_loss: 72748.6138 - val_recon_loss: 1.0039 - val_reg_output_loss: 72648.2211 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 72648.2211\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 74265.3404 - recon_loss: 1.0042 - reg_output_loss: 74164.9168 - recon_mean_squared_error: 1.0042 - reg_output_mean_squared_error: 74164.9168 - val_loss: 72537.2739 - val_recon_loss: 1.0040 - val_reg_output_loss: 72436.8778 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 72436.8778\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 69433.3848 - recon_loss: 1.0068 - reg_output_loss: 69332.7045 - recon_mean_squared_error: 1.0068 - reg_output_mean_squared_error: 69332.7045 - val_loss: 72680.9086 - val_recon_loss: 1.0036 - val_reg_output_loss: 72580.5456 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 72580.5456\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 68937.1884 - recon_loss: 1.0096 - reg_output_loss: 68836.2304 - recon_mean_squared_error: 1.0096 - reg_output_mean_squared_error: 68836.2304 - val_loss: 72782.7775 - val_recon_loss: 1.0044 - val_reg_output_loss: 72682.3378 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 72682.3378\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70406.3986 - recon_loss: 1.0041 - reg_output_loss: 70305.9902 - recon_mean_squared_error: 1.0041 - reg_output_mean_squared_error: 70305.9902 - val_loss: 72873.4628 - val_recon_loss: 1.0042 - val_reg_output_loss: 72773.0411 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 72773.0411\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 66711.3072 - recon_loss: 1.0056 - reg_output_loss: 66610.7466 - recon_mean_squared_error: 1.0056 - reg_output_mean_squared_error: 66610.7466 - val_loss: 73504.6588 - val_recon_loss: 1.0050 - val_reg_output_loss: 73404.1628 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73404.1628\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 66998.0329 - recon_loss: 1.0107 - reg_output_loss: 66896.9626 - recon_mean_squared_error: 1.0107 - reg_output_mean_squared_error: 66896.9626 - val_loss: 73902.6992 - val_recon_loss: 1.0048 - val_reg_output_loss: 73802.2241 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73802.2241\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 740us/step - loss: 70150.1949 - recon_loss: 1.0045 - reg_output_loss: 70049.7405 - recon_mean_squared_error: 1.0045 - reg_output_mean_squared_error: 70049.7405 - val_loss: 73441.2302 - val_recon_loss: 1.0040 - val_reg_output_loss: 73340.8319 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 73340.8319\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68993.3368 - recon_loss: 1.0052 - reg_output_loss: 68892.8156 - recon_mean_squared_error: 1.0052 - reg_output_mean_squared_error: 68892.8156 - val_loss: 73740.0933 - val_recon_loss: 1.0048 - val_reg_output_loss: 73639.6153 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73639.6153\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 73987.2518 - recon_loss: 1.0031 - reg_output_loss: 73886.9448 - recon_mean_squared_error: 1.0031 - reg_output_mean_squared_error: 73886.9448 - val_loss: 73424.8580 - val_recon_loss: 1.0043 - val_reg_output_loss: 73324.4264 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 73324.4264\n",
      "Epoch 319/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 68281.6179 - recon_loss: 1.0078 - reg_output_loss: 68180.8383 - recon_mean_squared_error: 1.0078 - reg_output_mean_squared_error: 68180.8383 - val_loss: 73429.0855 - val_recon_loss: 1.0036 - val_reg_output_loss: 73328.7269 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 73328.7269\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 66961.1084 - recon_loss: 1.0027 - reg_output_loss: 66860.8336 - recon_mean_squared_error: 1.0027 - reg_output_mean_squared_error: 66860.8336 - val_loss: 73381.5286 - val_recon_loss: 1.0039 - val_reg_output_loss: 73281.1403 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 73281.1403\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 67917.9625 - recon_loss: 1.0083 - reg_output_loss: 67817.1371 - recon_mean_squared_error: 1.0083 - reg_output_mean_squared_error: 67817.1371 - val_loss: 73317.3844 - val_recon_loss: 1.0035 - val_reg_output_loss: 73217.0325 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 73217.0325\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 67731.2960 - recon_loss: 1.0101 - reg_output_loss: 67630.2876 - recon_mean_squared_error: 1.0101 - reg_output_mean_squared_error: 67630.2876 - val_loss: 73553.1141 - val_recon_loss: 1.0031 - val_reg_output_loss: 73452.8053 - val_recon_mean_squared_error: 1.0031 - val_reg_output_mean_squared_error: 73452.8053\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 68366.6556 - recon_loss: 1.0126 - reg_output_loss: 68265.3967 - recon_mean_squared_error: 1.0126 - reg_output_mean_squared_error: 68265.3967 - val_loss: 73514.6906 - val_recon_loss: 1.0035 - val_reg_output_loss: 73414.3387 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 73414.3387\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 68962.5859 - recon_loss: 1.0066 - reg_output_loss: 68861.9249 - recon_mean_squared_error: 1.0066 - reg_output_mean_squared_error: 68861.9249 - val_loss: 73805.6506 - val_recon_loss: 1.0038 - val_reg_output_loss: 73705.2703 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 73705.2703\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68387.7214 - recon_loss: 1.0039 - reg_output_loss: 68287.3306 - recon_mean_squared_error: 1.0039 - reg_output_mean_squared_error: 68287.3306 - val_loss: 73498.1491 - val_recon_loss: 1.0040 - val_reg_output_loss: 73397.7466 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 73397.7466\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 71916.0862 - recon_loss: 1.0053 - reg_output_loss: 71815.5584 - recon_mean_squared_error: 1.0053 - reg_output_mean_squared_error: 71815.5584 - val_loss: 73385.5834 - val_recon_loss: 1.0039 - val_reg_output_loss: 73285.1938 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 73285.1938\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 70894.3416 - recon_loss: 1.0074 - reg_output_loss: 70793.6008 - recon_mean_squared_error: 1.0074 - reg_output_mean_squared_error: 70793.6008 - val_loss: 73363.3994 - val_recon_loss: 1.0042 - val_reg_output_loss: 73262.9844 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73262.9844\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 68737.9946 - recon_loss: 1.0013 - reg_output_loss: 68637.8651 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 68637.8651 - val_loss: 73394.6850 - val_recon_loss: 1.0067 - val_reg_output_loss: 73294.0194 - val_recon_mean_squared_error: 1.0067 - val_reg_output_mean_squared_error: 73294.0194\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70506.6775 - recon_loss: 1.0144 - reg_output_loss: 70405.2368 - recon_mean_squared_error: 1.0144 - reg_output_mean_squared_error: 70405.2368 - val_loss: 73147.4538 - val_recon_loss: 1.0034 - val_reg_output_loss: 73047.1169 - val_recon_mean_squared_error: 1.0034 - val_reg_output_mean_squared_error: 73047.1169\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 68330.9991 - recon_loss: 1.0036 - reg_output_loss: 68230.6439 - recon_mean_squared_error: 1.0036 - reg_output_mean_squared_error: 68230.6439 - val_loss: 73122.2234 - val_recon_loss: 1.0042 - val_reg_output_loss: 73021.8031 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73021.8031\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 66969.8388 - recon_loss: 1.0020 - reg_output_loss: 66869.6416 - recon_mean_squared_error: 1.0020 - reg_output_mean_squared_error: 66869.6416 - val_loss: 73213.2809 - val_recon_loss: 1.0042 - val_reg_output_loss: 73112.8572 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73112.8572\n",
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 64986.6466 - recon_loss: 1.0044 - reg_output_loss: 64886.2039 - recon_mean_squared_error: 1.0044 - reg_output_mean_squared_error: 64886.2039 - val_loss: 73414.3431 - val_recon_loss: 1.0041 - val_reg_output_loss: 73313.9353 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73313.9353\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 66358.7326 - recon_loss: 1.0150 - reg_output_loss: 66257.2322 - recon_mean_squared_error: 1.0150 - reg_output_mean_squared_error: 66257.2322 - val_loss: 73663.3678 - val_recon_loss: 1.0039 - val_reg_output_loss: 73562.9744 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 73562.9744\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 69945.5079 - recon_loss: 1.0077 - reg_output_loss: 69844.7401 - recon_mean_squared_error: 1.0077 - reg_output_mean_squared_error: 69844.7401 - val_loss: 73131.1184 - val_recon_loss: 1.0034 - val_reg_output_loss: 73030.7775 - val_recon_mean_squared_error: 1.0034 - val_reg_output_mean_squared_error: 73030.7775\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 67254.9682 - recon_loss: 1.0021 - reg_output_loss: 67154.7540 - recon_mean_squared_error: 1.0021 - reg_output_mean_squared_error: 67154.7540 - val_loss: 73124.4734 - val_recon_loss: 1.0044 - val_reg_output_loss: 73024.0303 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73024.0303\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 64294.0384 - recon_loss: 1.0067 - reg_output_loss: 64193.3710 - recon_mean_squared_error: 1.0067 - reg_output_mean_squared_error: 64193.3710 - val_loss: 73462.7231 - val_recon_loss: 1.0049 - val_reg_output_loss: 73362.2328 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73362.2328\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 68744.8289 - recon_loss: 1.0041 - reg_output_loss: 68644.4216 - recon_mean_squared_error: 1.0041 - reg_output_mean_squared_error: 68644.4216 - val_loss: 73294.9216 - val_recon_loss: 1.0045 - val_reg_output_loss: 73194.4678 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73194.4678\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71572.5148 - recon_loss: 1.0075 - reg_output_loss: 71471.7636 - recon_mean_squared_error: 1.0075 - reg_output_mean_squared_error: 71471.7636 - val_loss: 73117.0388 - val_recon_loss: 1.0048 - val_reg_output_loss: 73016.5606 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73016.5606\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 69328.1413 - recon_loss: 1.0046 - reg_output_loss: 69227.6852 - recon_mean_squared_error: 1.0046 - reg_output_mean_squared_error: 69227.6852 - val_loss: 72942.3609 - val_recon_loss: 1.0053 - val_reg_output_loss: 72841.8269 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 72841.8269\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 68856.8031 - recon_loss: 1.0035 - reg_output_loss: 68756.4567 - recon_mean_squared_error: 1.0035 - reg_output_mean_squared_error: 68756.4567 - val_loss: 73129.6069 - val_recon_loss: 1.0051 - val_reg_output_loss: 73029.0972 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 73029.0972\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 69220.3406 - recon_loss: 1.0028 - reg_output_loss: 69120.0635 - recon_mean_squared_error: 1.0028 - reg_output_mean_squared_error: 69120.0635 - val_loss: 73060.3459 - val_recon_loss: 1.0053 - val_reg_output_loss: 72959.8197 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 72959.8197\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 70448.7679 - recon_loss: 1.0011 - reg_output_loss: 70348.6609 - recon_mean_squared_error: 1.0011 - reg_output_mean_squared_error: 70348.6609 - val_loss: 72958.0159 - val_recon_loss: 1.0037 - val_reg_output_loss: 72857.6428 - val_recon_mean_squared_error: 1.0037 - val_reg_output_mean_squared_error: 72857.6428\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 69587.1305 - recon_loss: 1.0025 - reg_output_loss: 69486.8848 - recon_mean_squared_error: 1.0025 - reg_output_mean_squared_error: 69486.8848 - val_loss: 72659.2962 - val_recon_loss: 1.0046 - val_reg_output_loss: 72558.8362 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 72558.8362\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 69371.1171 - recon_loss: 1.0065 - reg_output_loss: 69270.4646 - recon_mean_squared_error: 1.0065 - reg_output_mean_squared_error: 69270.4646 - val_loss: 72913.6072 - val_recon_loss: 1.0135 - val_reg_output_loss: 72812.2538 - val_recon_mean_squared_error: 1.0135 - val_reg_output_mean_squared_error: 72812.2538\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 72850.0272 - recon_loss: 1.0020 - reg_output_loss: 72749.8315 - recon_mean_squared_error: 1.0020 - reg_output_mean_squared_error: 72749.8315 - val_loss: 72916.0137 - val_recon_loss: 1.0054 - val_reg_output_loss: 72815.4794 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 72815.4794\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 72209.4422 - recon_loss: 1.0007 - reg_output_loss: 72109.3766 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 72109.3766 - val_loss: 73025.5059 - val_recon_loss: 1.0054 - val_reg_output_loss: 72924.9669 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 72924.9669\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 69934.8416 - recon_loss: 1.0007 - reg_output_loss: 69834.7717 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 69834.7717 - val_loss: 73070.4947 - val_recon_loss: 1.0051 - val_reg_output_loss: 72969.9869 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 72969.9869\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 73372.1164 - recon_loss: 1.0062 - reg_output_loss: 73271.4981 - recon_mean_squared_error: 1.0062 - reg_output_mean_squared_error: 73271.4981 - val_loss: 73145.7628 - val_recon_loss: 1.0032 - val_reg_output_loss: 73045.4484 - val_recon_mean_squared_error: 1.0032 - val_reg_output_mean_squared_error: 73045.4484\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 68656.9478 - recon_loss: 1.0013 - reg_output_loss: 68556.8186 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 68556.8186 - val_loss: 73346.0278 - val_recon_loss: 1.0042 - val_reg_output_loss: 73245.6031 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73245.6031\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 67819.4580 - recon_loss: 1.0044 - reg_output_loss: 67719.0144 - recon_mean_squared_error: 1.0044 - reg_output_mean_squared_error: 67719.0144 - val_loss: 73756.5769 - val_recon_loss: 1.0046 - val_reg_output_loss: 73656.1222 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73656.1222\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 71305.7702 - recon_loss: 1.0005 - reg_output_loss: 71205.7204 - recon_mean_squared_error: 1.0005 - reg_output_mean_squared_error: 71205.7204 - val_loss: 73559.9928 - val_recon_loss: 1.0049 - val_reg_output_loss: 73459.4991 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73459.4991\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 70965.6097 - recon_loss: 1.0020 - reg_output_loss: 70865.4142 - recon_mean_squared_error: 1.0020 - reg_output_mean_squared_error: 70865.4142 - val_loss: 73550.9769 - val_recon_loss: 1.0041 - val_reg_output_loss: 73450.5678 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73450.5678\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 710us/step - loss: 72379.0717 - recon_loss: 1.0004 - reg_output_loss: 72279.0349 - recon_mean_squared_error: 1.0004 - reg_output_mean_squared_error: 72279.0349 - val_loss: 73749.1034 - val_recon_loss: 1.0050 - val_reg_output_loss: 73648.6000 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73648.6000\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 73180.7195 - recon_loss: 1.0008 - reg_output_loss: 73080.6422 - recon_mean_squared_error: 1.0008 - reg_output_mean_squared_error: 73080.6422 - val_loss: 73453.8797 - val_recon_loss: 1.0035 - val_reg_output_loss: 73353.5275 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 73353.5275\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 70124.5715 - recon_loss: 1.0012 - reg_output_loss: 70024.4476 - recon_mean_squared_error: 1.0012 - reg_output_mean_squared_error: 70024.4476 - val_loss: 73597.5319 - val_recon_loss: 1.0040 - val_reg_output_loss: 73497.1300 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 73497.1300\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 72250.2665 - recon_loss: 1.0006 - reg_output_loss: 72150.2072 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 72150.2072 - val_loss: 73299.5997 - val_recon_loss: 1.0042 - val_reg_output_loss: 73199.1812 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73199.1812\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 73189.7564 - recon_loss: 1.0000 - reg_output_loss: 73089.7519 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 73089.7519 - val_loss: 73199.2909 - val_recon_loss: 1.0046 - val_reg_output_loss: 73098.8325 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73098.8325\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 657us/step - loss: 73356.3651 - recon_loss: 1.0000 - reg_output_loss: 73256.3611 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 73256.3611 - val_loss: 72825.1681 - val_recon_loss: 1.0036 - val_reg_output_loss: 72724.8066 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 72724.8066\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 73978.5921 - recon_loss: 1.0001 - reg_output_loss: 73878.5876 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 73878.5876 - val_loss: 72688.3466 - val_recon_loss: 1.0036 - val_reg_output_loss: 72587.9853 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 72587.9853\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 71866.2497 - recon_loss: 1.0007 - reg_output_loss: 71766.1810 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 71766.1810 - val_loss: 72881.2991 - val_recon_loss: 1.0056 - val_reg_output_loss: 72780.7372 - val_recon_mean_squared_error: 1.0056 - val_reg_output_mean_squared_error: 72780.7372\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 668us/step - loss: 71737.0105 - recon_loss: 1.0028 - reg_output_loss: 71636.7322 - recon_mean_squared_error: 1.0028 - reg_output_mean_squared_error: 71636.7322 - val_loss: 72446.7467 - val_recon_loss: 1.0036 - val_reg_output_loss: 72346.3839 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 72346.3839\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 72677.4855 - recon_loss: 1.0000 - reg_output_loss: 72577.4872 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 72577.4872 - val_loss: 72607.8412 - val_recon_loss: 1.0037 - val_reg_output_loss: 72507.4717 - val_recon_mean_squared_error: 1.0037 - val_reg_output_mean_squared_error: 72507.4717\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 72734.5104 - recon_loss: 1.0000 - reg_output_loss: 72634.5126 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 72634.5126 - val_loss: 72572.8309 - val_recon_loss: 1.0046 - val_reg_output_loss: 72472.3730 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 72472.3730\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 72044.2027 - recon_loss: 1.0004 - reg_output_loss: 71944.1640 - recon_mean_squared_error: 1.0004 - reg_output_mean_squared_error: 71944.1640 - val_loss: 72489.1692 - val_recon_loss: 1.0046 - val_reg_output_loss: 72388.7141 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 72388.7141\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 70306.5955 - recon_loss: 1.0000 - reg_output_loss: 70206.5959 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 70206.5959 - val_loss: 72831.4017 - val_recon_loss: 1.0048 - val_reg_output_loss: 72730.9216 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 72730.9216\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 70382.2564 - recon_loss: 1.0010 - reg_output_loss: 70282.1525 - recon_mean_squared_error: 1.0010 - reg_output_mean_squared_error: 70282.1525 - val_loss: 73147.2084 - val_recon_loss: 1.0042 - val_reg_output_loss: 73046.7931 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73046.7931\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 68320.4197 - recon_loss: 1.0009 - reg_output_loss: 68220.3319 - recon_mean_squared_error: 1.0009 - reg_output_mean_squared_error: 68220.3319 - val_loss: 73489.5150 - val_recon_loss: 1.0055 - val_reg_output_loss: 73388.9653 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 73388.9653\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 72191.5745 - recon_loss: 1.0000 - reg_output_loss: 72091.5712 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 72091.5712 - val_loss: 73279.1273 - val_recon_loss: 1.0041 - val_reg_output_loss: 73178.7166 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73178.7166\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70694.4982 - recon_loss: 1.0004 - reg_output_loss: 70594.4580 - recon_mean_squared_error: 1.0004 - reg_output_mean_squared_error: 70594.4580 - val_loss: 73222.9647 - val_recon_loss: 1.0044 - val_reg_output_loss: 73122.5209 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73122.5209\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 68305.5453 - recon_loss: 1.0007 - reg_output_loss: 68205.4781 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 68205.4781 - val_loss: 73705.5969 - val_recon_loss: 1.0034 - val_reg_output_loss: 73605.2550 - val_recon_mean_squared_error: 1.0034 - val_reg_output_mean_squared_error: 73605.2550\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 71116.1919 - recon_loss: 1.0012 - reg_output_loss: 71016.0737 - recon_mean_squared_error: 1.0012 - reg_output_mean_squared_error: 71016.0737 - val_loss: 73602.0653 - val_recon_loss: 1.0050 - val_reg_output_loss: 73501.5619 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73501.5619\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 70641.2997 - recon_loss: 0.9998 - reg_output_loss: 70541.3163 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 70541.3163 - val_loss: 73491.0653 - val_recon_loss: 1.0045 - val_reg_output_loss: 73390.6178 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73390.6178\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 70206.6249 - recon_loss: 1.0016 - reg_output_loss: 70106.4691 - recon_mean_squared_error: 1.0016 - reg_output_mean_squared_error: 70106.4691 - val_loss: 73561.9466 - val_recon_loss: 1.0043 - val_reg_output_loss: 73461.5188 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 73461.5188\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 70410.6095 - recon_loss: 0.9998 - reg_output_loss: 70310.6288 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 70310.6288 - val_loss: 73434.0356 - val_recon_loss: 1.0037 - val_reg_output_loss: 73333.6694 - val_recon_mean_squared_error: 1.0037 - val_reg_output_mean_squared_error: 73333.6694\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 75531.0198 - recon_loss: 1.0003 - reg_output_loss: 75430.9867 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 75430.9867 - val_loss: 72993.3703 - val_recon_loss: 1.0061 - val_reg_output_loss: 72892.7583 - val_recon_mean_squared_error: 1.0061 - val_reg_output_mean_squared_error: 72892.7583\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 71028.6488 - recon_loss: 1.0000 - reg_output_loss: 70928.6522 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 70928.6522 - val_loss: 72900.0598 - val_recon_loss: 1.0043 - val_reg_output_loss: 72799.6305 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 72799.6305\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 72372.3286 - recon_loss: 1.0025 - reg_output_loss: 72272.0791 - recon_mean_squared_error: 1.0025 - reg_output_mean_squared_error: 72272.0791 - val_loss: 72842.1322 - val_recon_loss: 1.0044 - val_reg_output_loss: 72741.6913 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 72741.6913\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 653us/step - loss: 72309.7912 - recon_loss: 1.0004 - reg_output_loss: 72209.7497 - recon_mean_squared_error: 1.0004 - reg_output_mean_squared_error: 72209.7497 - val_loss: 72977.1744 - val_recon_loss: 1.0037 - val_reg_output_loss: 72876.8003 - val_recon_mean_squared_error: 1.0037 - val_reg_output_mean_squared_error: 72876.8003\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 74668.7436 - recon_loss: 0.9999 - reg_output_loss: 74568.7514 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 74568.7514 - val_loss: 72947.2084 - val_recon_loss: 1.0038 - val_reg_output_loss: 72846.8288 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72846.8288\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 68452.7111 - recon_loss: 1.0001 - reg_output_loss: 68352.6953 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 68352.6953 - val_loss: 73323.4400 - val_recon_loss: 1.0046 - val_reg_output_loss: 73222.9778 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73222.9778\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 70930.3416 - recon_loss: 1.0002 - reg_output_loss: 70830.3235 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 70830.3235 - val_loss: 73516.2781 - val_recon_loss: 1.0043 - val_reg_output_loss: 73415.8459 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 73415.8459\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 730us/step - loss: 74179.8148 - recon_loss: 1.0001 - reg_output_loss: 74079.8056 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 74079.8056 - val_loss: 73294.0342 - val_recon_loss: 1.0047 - val_reg_output_loss: 73193.5656 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 73193.5656\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 71729.2613 - recon_loss: 1.0003 - reg_output_loss: 71629.2287 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 71629.2287 - val_loss: 73568.1544 - val_recon_loss: 1.0048 - val_reg_output_loss: 73467.6706 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73467.6706\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 68624.9472 - recon_loss: 1.0002 - reg_output_loss: 68524.9285 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 68524.9285 - val_loss: 74013.5222 - val_recon_loss: 1.0045 - val_reg_output_loss: 73913.0678 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73913.0678\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 72918.5963 - recon_loss: 1.0000 - reg_output_loss: 72818.5933 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 72818.5933 - val_loss: 74015.5912 - val_recon_loss: 1.0039 - val_reg_output_loss: 73915.2047 - val_recon_mean_squared_error: 1.0039 - val_reg_output_mean_squared_error: 73915.2047\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 71819.3541 - recon_loss: 1.0001 - reg_output_loss: 71719.3441 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 71719.3441 - val_loss: 73929.6431 - val_recon_loss: 1.0050 - val_reg_output_loss: 73829.1453 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73829.1453\n",
      "Epoch 387/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 69302.0436 - recon_loss: 1.0013 - reg_output_loss: 69201.9143 - recon_mean_squared_error: 1.0013 - reg_output_mean_squared_error: 69201.9143 - val_loss: 74313.0253 - val_recon_loss: 1.0047 - val_reg_output_loss: 74212.5572 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 74212.5572\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 71763.2745 - recon_loss: 0.9999 - reg_output_loss: 71663.2821 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 71663.2821 - val_loss: 74421.7000 - val_recon_loss: 1.0040 - val_reg_output_loss: 74321.2978 - val_recon_mean_squared_error: 1.0040 - val_reg_output_mean_squared_error: 74321.2978\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 71022.7001 - recon_loss: 1.0077 - reg_output_loss: 70921.9293 - recon_mean_squared_error: 1.0077 - reg_output_mean_squared_error: 70921.9293 - val_loss: 74424.5850 - val_recon_loss: 1.0049 - val_reg_output_loss: 74324.0925 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 74324.0925\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 70166.6316 - recon_loss: 0.9998 - reg_output_loss: 70066.6492 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 70066.6492 - val_loss: 74397.5672 - val_recon_loss: 1.0048 - val_reg_output_loss: 74297.0853 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 74297.0853\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 68970.3738 - recon_loss: 1.0003 - reg_output_loss: 68870.3424 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 68870.3424 - val_loss: 74784.9769 - val_recon_loss: 1.0050 - val_reg_output_loss: 74684.4809 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 74684.4809\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 72214.9437 - recon_loss: 0.9997 - reg_output_loss: 72114.9777 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 72114.9777 - val_loss: 74923.7300 - val_recon_loss: 1.0050 - val_reg_output_loss: 74823.2281 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 74823.2281\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 68945.2103 - recon_loss: 1.0007 - reg_output_loss: 68845.1389 - recon_mean_squared_error: 1.0007 - reg_output_mean_squared_error: 68845.1389 - val_loss: 75091.5725 - val_recon_loss: 1.0046 - val_reg_output_loss: 74991.1144 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 74991.1144\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 69618.5884 - recon_loss: 1.0000 - reg_output_loss: 69518.5904 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 69518.5904 - val_loss: 74733.4312 - val_recon_loss: 1.0042 - val_reg_output_loss: 74633.0091 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 74633.0091\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 688us/step - loss: 74449.6534 - recon_loss: 1.0002 - reg_output_loss: 74349.6287 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 74349.6287 - val_loss: 74635.8709 - val_recon_loss: 1.0050 - val_reg_output_loss: 74535.3672 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 74535.3672\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 73674.3056 - recon_loss: 1.0002 - reg_output_loss: 73574.2868 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 73574.2868 - val_loss: 74478.6044 - val_recon_loss: 1.0053 - val_reg_output_loss: 74378.0716 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 74378.0716\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 710us/step - loss: 71587.7957 - recon_loss: 0.9999 - reg_output_loss: 71487.8090 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 71487.8090 - val_loss: 74525.4603 - val_recon_loss: 1.0045 - val_reg_output_loss: 74425.0044 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 74425.0044\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 70901.6615 - recon_loss: 1.0020 - reg_output_loss: 70801.4629 - recon_mean_squared_error: 1.0020 - reg_output_mean_squared_error: 70801.4629 - val_loss: 74864.7300 - val_recon_loss: 1.0046 - val_reg_output_loss: 74764.2681 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 74764.2681\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 71453.9466 - recon_loss: 0.9997 - reg_output_loss: 71353.9764 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 71353.9764 - val_loss: 74418.2394 - val_recon_loss: 1.0046 - val_reg_output_loss: 74317.7756 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 74317.7756\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 723us/step - loss: 72083.3529 - recon_loss: 1.0005 - reg_output_loss: 71983.3003 - recon_mean_squared_error: 1.0005 - reg_output_mean_squared_error: 71983.3003 - val_loss: 74322.6156 - val_recon_loss: 1.0048 - val_reg_output_loss: 74222.1319 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 74222.1319\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 685us/step - loss: 73872.2638 - recon_loss: 0.9997 - reg_output_loss: 73772.2959 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 73772.2959 - val_loss: 74086.7034 - val_recon_loss: 1.0045 - val_reg_output_loss: 73986.2584 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73986.2584\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 747us/step - loss: 76137.5465 - recon_loss: 0.9999 - reg_output_loss: 76037.5554 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 76037.5554 - val_loss: 73797.3847 - val_recon_loss: 1.0050 - val_reg_output_loss: 73696.8872 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73696.8872\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 74306.8415 - recon_loss: 1.0002 - reg_output_loss: 74206.8247 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 74206.8247 - val_loss: 73614.3520 - val_recon_loss: 1.0061 - val_reg_output_loss: 73513.7413 - val_recon_mean_squared_error: 1.0061 - val_reg_output_mean_squared_error: 73513.7413\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 75239.9958 - recon_loss: 1.0006 - reg_output_loss: 75139.9321 - recon_mean_squared_error: 1.0006 - reg_output_mean_squared_error: 75139.9321 - val_loss: 73649.2672 - val_recon_loss: 1.0049 - val_reg_output_loss: 73548.7769 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73548.7769\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 727us/step - loss: 75055.3212 - recon_loss: 0.9996 - reg_output_loss: 74955.3573 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 74955.3573 - val_loss: 73443.3905 - val_recon_loss: 1.0049 - val_reg_output_loss: 73342.9047 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73342.9047\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 73783.6263 - recon_loss: 1.0008 - reg_output_loss: 73683.5506 - recon_mean_squared_error: 1.0008 - reg_output_mean_squared_error: 73683.5506 - val_loss: 73593.9653 - val_recon_loss: 1.0049 - val_reg_output_loss: 73493.4794 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73493.4794\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 71948.7115 - recon_loss: 0.9997 - reg_output_loss: 71848.7444 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 71848.7444 - val_loss: 74042.2097 - val_recon_loss: 1.0057 - val_reg_output_loss: 73941.6381 - val_recon_mean_squared_error: 1.0057 - val_reg_output_mean_squared_error: 73941.6381\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 74777.7337 - recon_loss: 1.0001 - reg_output_loss: 74677.7193 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 74677.7193 - val_loss: 73903.6566 - val_recon_loss: 1.0046 - val_reg_output_loss: 73803.1987 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73803.1987\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 75639.6158 - recon_loss: 1.0022 - reg_output_loss: 75539.3986 - recon_mean_squared_error: 1.0022 - reg_output_mean_squared_error: 75539.3986 - val_loss: 73933.2695 - val_recon_loss: 1.0049 - val_reg_output_loss: 73832.7769 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 73832.7769\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 73842.0554 - recon_loss: 1.0000 - reg_output_loss: 73742.0585 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 73742.0585 - val_loss: 73598.1291 - val_recon_loss: 1.0056 - val_reg_output_loss: 73497.5700 - val_recon_mean_squared_error: 1.0056 - val_reg_output_mean_squared_error: 73497.5700\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 73157.8063 - recon_loss: 0.9998 - reg_output_loss: 73057.8243 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 73057.8243 - val_loss: 73781.5714 - val_recon_loss: 1.0041 - val_reg_output_loss: 73681.1628 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73681.1628\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 747us/step - loss: 72753.8012 - recon_loss: 1.0003 - reg_output_loss: 72653.7678 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 72653.7678 - val_loss: 73796.3309 - val_recon_loss: 1.0047 - val_reg_output_loss: 73695.8591 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 73695.8591\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 73255.6894 - recon_loss: 0.9998 - reg_output_loss: 73155.7079 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 73155.7079 - val_loss: 73770.4495 - val_recon_loss: 1.0046 - val_reg_output_loss: 73669.9898 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73669.9898\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 74036.4120 - recon_loss: 0.9996 - reg_output_loss: 73936.4505 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 73936.4505 - val_loss: 73712.5783 - val_recon_loss: 1.0050 - val_reg_output_loss: 73612.0808 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73612.0808\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 71285.9492 - recon_loss: 0.9999 - reg_output_loss: 71185.9622 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 71185.9622 - val_loss: 74256.2781 - val_recon_loss: 1.0047 - val_reg_output_loss: 74155.8064 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 74155.8064\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 71590.4904 - recon_loss: 1.0000 - reg_output_loss: 71490.4923 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 71490.4923 - val_loss: 74328.8756 - val_recon_loss: 1.0053 - val_reg_output_loss: 74228.3475 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 74228.3475\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 73384.9295 - recon_loss: 0.9998 - reg_output_loss: 73284.9480 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 73284.9480 - val_loss: 74214.9294 - val_recon_loss: 1.0042 - val_reg_output_loss: 74114.5041 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 74114.5041\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 72601.3200 - recon_loss: 1.0069 - reg_output_loss: 72500.6308 - recon_mean_squared_error: 1.0069 - reg_output_mean_squared_error: 72500.6308 - val_loss: 74502.5694 - val_recon_loss: 1.0061 - val_reg_output_loss: 74401.9622 - val_recon_mean_squared_error: 1.0061 - val_reg_output_mean_squared_error: 74401.9622\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 730us/step - loss: 73309.2577 - recon_loss: 0.9998 - reg_output_loss: 73209.2778 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 73209.2778 - val_loss: 74483.4080 - val_recon_loss: 1.0050 - val_reg_output_loss: 74382.9122 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 74382.9122\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 74666.2529 - recon_loss: 1.0021 - reg_output_loss: 74566.0455 - recon_mean_squared_error: 1.0021 - reg_output_mean_squared_error: 74566.0455 - val_loss: 74000.7320 - val_recon_loss: 1.0048 - val_reg_output_loss: 73900.2555 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73900.2555\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 712us/step - loss: 76932.0465 - recon_loss: 0.9996 - reg_output_loss: 76832.0890 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76832.0890 - val_loss: 73872.3628 - val_recon_loss: 1.0052 - val_reg_output_loss: 73771.8427 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 73771.8427\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 77460.5463 - recon_loss: 1.0000 - reg_output_loss: 77360.5440 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 77360.5440 - val_loss: 73739.9848 - val_recon_loss: 1.0051 - val_reg_output_loss: 73639.4738 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 73639.4738\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 77639.3786 - recon_loss: 0.9997 - reg_output_loss: 77539.4093 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 77539.4093 - val_loss: 73504.2239 - val_recon_loss: 1.0050 - val_reg_output_loss: 73403.7228 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73403.7228\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 77357.4414 - recon_loss: 0.9999 - reg_output_loss: 77257.4485 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 77257.4485 - val_loss: 73288.1970 - val_recon_loss: 1.0044 - val_reg_output_loss: 73187.7595 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73187.7595\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 663us/step - loss: 75930.9210 - recon_loss: 0.9996 - reg_output_loss: 75830.9656 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75830.9656 - val_loss: 73224.5198 - val_recon_loss: 1.0047 - val_reg_output_loss: 73124.0555 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 73124.0555\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 727us/step - loss: 76179.4910 - recon_loss: 1.0003 - reg_output_loss: 76079.4588 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 76079.4588 - val_loss: 73224.1042 - val_recon_loss: 1.0047 - val_reg_output_loss: 73123.6348 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 73123.6348\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 76033.0531 - recon_loss: 0.9999 - reg_output_loss: 75933.0669 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 75933.0669 - val_loss: 73232.6961 - val_recon_loss: 1.0052 - val_reg_output_loss: 73132.1733 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 73132.1733\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 74515.6681 - recon_loss: 0.9997 - reg_output_loss: 74415.6958 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 74415.6958 - val_loss: 73227.9816 - val_recon_loss: 1.0046 - val_reg_output_loss: 73127.5191 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73127.5191\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 76359.7697 - recon_loss: 0.9998 - reg_output_loss: 76259.7929 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 76259.7929 - val_loss: 73093.6395 - val_recon_loss: 1.0042 - val_reg_output_loss: 72993.2142 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 72993.2142\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 723us/step - loss: 76178.4607 - recon_loss: 0.9997 - reg_output_loss: 76078.4921 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76078.4921 - val_loss: 73234.8889 - val_recon_loss: 1.0052 - val_reg_output_loss: 73134.3680 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 73134.3680\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 75776.9932 - recon_loss: 0.9997 - reg_output_loss: 75677.0213 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 75677.0213 - val_loss: 73114.0553 - val_recon_loss: 1.0055 - val_reg_output_loss: 73013.5028 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 73013.5028\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 75270.3584 - recon_loss: 0.9998 - reg_output_loss: 75170.3777 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 75170.3777 - val_loss: 73074.9095 - val_recon_loss: 1.0042 - val_reg_output_loss: 72974.4864 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 72974.4864\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 78608.6621 - recon_loss: 0.9997 - reg_output_loss: 78508.6873 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 78508.6873 - val_loss: 72920.9533 - val_recon_loss: 1.0053 - val_reg_output_loss: 72820.4275 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 72820.4275\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 76984.9043 - recon_loss: 0.9996 - reg_output_loss: 76884.9427 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76884.9427 - val_loss: 72810.3391 - val_recon_loss: 1.0047 - val_reg_output_loss: 72709.8695 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 72709.8695\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 77983.7565 - recon_loss: 0.9997 - reg_output_loss: 77883.7906 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 77883.7906 - val_loss: 72750.0242 - val_recon_loss: 1.0057 - val_reg_output_loss: 72649.4505 - val_recon_mean_squared_error: 1.0057 - val_reg_output_mean_squared_error: 72649.4505\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 75790.2459 - recon_loss: 0.9997 - reg_output_loss: 75690.2769 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 75690.2769 - val_loss: 72780.6362 - val_recon_loss: 1.0043 - val_reg_output_loss: 72680.2056 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 72680.2056\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 660us/step - loss: 76701.5029 - recon_loss: 0.9997 - reg_output_loss: 76601.5287 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76601.5287 - val_loss: 72606.6936 - val_recon_loss: 1.0037 - val_reg_output_loss: 72506.3253 - val_recon_mean_squared_error: 1.0037 - val_reg_output_mean_squared_error: 72506.3253\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 76430.5820 - recon_loss: 0.9997 - reg_output_loss: 76330.6165 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76330.6165 - val_loss: 72551.1844 - val_recon_loss: 1.0049 - val_reg_output_loss: 72450.6967 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 72450.6967\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 76026.9517 - recon_loss: 0.9996 - reg_output_loss: 75926.9936 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75926.9936 - val_loss: 72440.5352 - val_recon_loss: 1.0050 - val_reg_output_loss: 72340.0302 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 72340.0302\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 718us/step - loss: 76903.5264 - recon_loss: 1.0000 - reg_output_loss: 76803.5309 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 76803.5309 - val_loss: 72623.0511 - val_recon_loss: 1.0053 - val_reg_output_loss: 72522.5213 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 72522.5213\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 75872.4218 - recon_loss: 0.9996 - reg_output_loss: 75772.4635 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75772.4635 - val_loss: 72664.9047 - val_recon_loss: 1.0045 - val_reg_output_loss: 72564.4564 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 72564.4564\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 76269.2508 - recon_loss: 0.9997 - reg_output_loss: 76169.2826 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76169.2826 - val_loss: 72581.1911 - val_recon_loss: 1.0058 - val_reg_output_loss: 72480.6128 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 72480.6128\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 727us/step - loss: 73794.2358 - recon_loss: 0.9999 - reg_output_loss: 73694.2508 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 73694.2508 - val_loss: 72676.3209 - val_recon_loss: 1.0036 - val_reg_output_loss: 72575.9591 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 72575.9591\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 75295.6765 - recon_loss: 0.9996 - reg_output_loss: 75195.7113 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75195.7113 - val_loss: 72745.8134 - val_recon_loss: 1.0061 - val_reg_output_loss: 72645.1978 - val_recon_mean_squared_error: 1.0061 - val_reg_output_mean_squared_error: 72645.1978\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 75466.6690 - recon_loss: 0.9998 - reg_output_loss: 75366.6922 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 75366.6922 - val_loss: 72732.3775 - val_recon_loss: 1.0056 - val_reg_output_loss: 72631.8166 - val_recon_mean_squared_error: 1.0056 - val_reg_output_mean_squared_error: 72631.8166\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 75049.1687 - recon_loss: 0.9997 - reg_output_loss: 74949.1964 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 74949.1964 - val_loss: 72644.2795 - val_recon_loss: 1.0038 - val_reg_output_loss: 72543.9044 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72543.9044\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 76354.3524 - recon_loss: 1.0000 - reg_output_loss: 76254.3564 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 76254.3564 - val_loss: 72526.3659 - val_recon_loss: 1.0038 - val_reg_output_loss: 72425.9841 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72425.9841\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 74177.0336 - recon_loss: 0.9996 - reg_output_loss: 74077.0758 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 74077.0758 - val_loss: 72648.0525 - val_recon_loss: 1.0035 - val_reg_output_loss: 72547.7042 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 72547.7042\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 75454.6720 - recon_loss: 0.9998 - reg_output_loss: 75354.6893 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 75354.6893 - val_loss: 72429.4592 - val_recon_loss: 1.0051 - val_reg_output_loss: 72328.9464 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 72328.9464\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 76217.1911 - recon_loss: 0.9996 - reg_output_loss: 76117.2278 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76117.2278 - val_loss: 72472.5072 - val_recon_loss: 1.0051 - val_reg_output_loss: 72371.9984 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 72371.9984\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 75588.7909 - recon_loss: 1.0001 - reg_output_loss: 75488.7829 - recon_mean_squared_error: 1.0001 - reg_output_mean_squared_error: 75488.7829 - val_loss: 72596.7622 - val_recon_loss: 1.0048 - val_reg_output_loss: 72496.2817 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 72496.2817\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 670us/step - loss: 78636.6806 - recon_loss: 0.9996 - reg_output_loss: 78536.7210 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 78536.7210 - val_loss: 72547.6256 - val_recon_loss: 1.0047 - val_reg_output_loss: 72447.1581 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 72447.1581\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 76215.0358 - recon_loss: 0.9996 - reg_output_loss: 76115.0717 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76115.0717 - val_loss: 72603.0328 - val_recon_loss: 1.0044 - val_reg_output_loss: 72502.5925 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 72502.5925\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 74521.9120 - recon_loss: 0.9997 - reg_output_loss: 74421.9456 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 74421.9456 - val_loss: 72729.8128 - val_recon_loss: 1.0064 - val_reg_output_loss: 72629.1756 - val_recon_mean_squared_error: 1.0064 - val_reg_output_mean_squared_error: 72629.1756\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 673us/step - loss: 76007.0099 - recon_loss: 0.9999 - reg_output_loss: 75907.0180 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 75907.0180 - val_loss: 72613.5066 - val_recon_loss: 1.0053 - val_reg_output_loss: 72512.9778 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 72512.9778\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 76545.5040 - recon_loss: 0.9997 - reg_output_loss: 76445.5348 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76445.5348 - val_loss: 72630.0444 - val_recon_loss: 1.0038 - val_reg_output_loss: 72529.6603 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72529.6603\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 76348.6076 - recon_loss: 0.9996 - reg_output_loss: 76248.6470 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76248.6470 - val_loss: 72608.6106 - val_recon_loss: 1.0064 - val_reg_output_loss: 72507.9669 - val_recon_mean_squared_error: 1.0064 - val_reg_output_mean_squared_error: 72507.9669\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 75724.1115 - recon_loss: 0.9999 - reg_output_loss: 75624.1258 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 75624.1258 - val_loss: 72653.9119 - val_recon_loss: 1.0048 - val_reg_output_loss: 72553.4284 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 72553.4284\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 75129.4928 - recon_loss: 0.9997 - reg_output_loss: 75029.5178 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 75029.5178 - val_loss: 72614.3948 - val_recon_loss: 1.0054 - val_reg_output_loss: 72513.8553 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 72513.8553\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 76836.2854 - recon_loss: 0.9998 - reg_output_loss: 76736.3040 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 76736.3040 - val_loss: 72565.2848 - val_recon_loss: 1.0041 - val_reg_output_loss: 72464.8737 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 72464.8737\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 733us/step - loss: 76379.5606 - recon_loss: 0.9996 - reg_output_loss: 76279.5966 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76279.5966 - val_loss: 72700.7713 - val_recon_loss: 1.0044 - val_reg_output_loss: 72600.3338 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 72600.3338\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 76445.7021 - recon_loss: 0.9997 - reg_output_loss: 76345.7294 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76345.7294 - val_loss: 72696.4730 - val_recon_loss: 1.0056 - val_reg_output_loss: 72595.9116 - val_recon_mean_squared_error: 1.0056 - val_reg_output_mean_squared_error: 72595.9116\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 75935.4234 - recon_loss: 0.9997 - reg_output_loss: 75835.4495 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 75835.4495 - val_loss: 72629.6111 - val_recon_loss: 1.0052 - val_reg_output_loss: 72529.0880 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 72529.0880\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 74881.7540 - recon_loss: 0.9998 - reg_output_loss: 74781.7782 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 74781.7782 - val_loss: 72840.3594 - val_recon_loss: 1.0049 - val_reg_output_loss: 72739.8737 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 72739.8737\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 75869.0176 - recon_loss: 0.9998 - reg_output_loss: 75769.0379 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 75769.0379 - val_loss: 72832.4247 - val_recon_loss: 1.0050 - val_reg_output_loss: 72731.9194 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 72731.9194\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 693us/step - loss: 75854.7090 - recon_loss: 0.9996 - reg_output_loss: 75754.7451 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75754.7451 - val_loss: 72908.4430 - val_recon_loss: 1.0049 - val_reg_output_loss: 72807.9531 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 72807.9531\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 76794.3916 - recon_loss: 0.9997 - reg_output_loss: 76694.4260 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76694.4260 - val_loss: 72965.0842 - val_recon_loss: 1.0038 - val_reg_output_loss: 72864.7017 - val_recon_mean_squared_error: 1.0038 - val_reg_output_mean_squared_error: 72864.7017\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 720us/step - loss: 75823.9944 - recon_loss: 0.9996 - reg_output_loss: 75724.0297 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75724.0297 - val_loss: 72847.0464 - val_recon_loss: 1.0052 - val_reg_output_loss: 72746.5228 - val_recon_mean_squared_error: 1.0052 - val_reg_output_mean_squared_error: 72746.5228\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 717us/step - loss: 76113.1743 - recon_loss: 0.9996 - reg_output_loss: 76013.2117 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76013.2117 - val_loss: 72995.9908 - val_recon_loss: 1.0049 - val_reg_output_loss: 72895.4987 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 72895.4987\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 76161.0568 - recon_loss: 0.9996 - reg_output_loss: 76061.0943 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76061.0943 - val_loss: 72970.8809 - val_recon_loss: 1.0049 - val_reg_output_loss: 72870.3947 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 72870.3947\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 77888.7210 - recon_loss: 0.9996 - reg_output_loss: 77788.7610 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 77788.7610 - val_loss: 73027.4895 - val_recon_loss: 1.0047 - val_reg_output_loss: 72927.0156 - val_recon_mean_squared_error: 1.0047 - val_reg_output_mean_squared_error: 72927.0156\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 730us/step - loss: 76316.2956 - recon_loss: 0.9997 - reg_output_loss: 76216.3286 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76216.3286 - val_loss: 73107.6367 - val_recon_loss: 1.0044 - val_reg_output_loss: 73007.1922 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73007.1922\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 76094.7127 - recon_loss: 0.9996 - reg_output_loss: 75994.7523 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75994.7523 - val_loss: 73245.3047 - val_recon_loss: 1.0042 - val_reg_output_loss: 73144.8887 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73144.8887\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 74594.3036 - recon_loss: 0.9997 - reg_output_loss: 74494.3375 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 74494.3375 - val_loss: 73408.2984 - val_recon_loss: 1.0042 - val_reg_output_loss: 73307.8759 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73307.8759\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 710us/step - loss: 76015.5004 - recon_loss: 0.9995 - reg_output_loss: 75915.5459 - recon_mean_squared_error: 0.9995 - reg_output_mean_squared_error: 75915.5459 - val_loss: 73602.9375 - val_recon_loss: 1.0036 - val_reg_output_loss: 73502.5834 - val_recon_mean_squared_error: 1.0036 - val_reg_output_mean_squared_error: 73502.5834\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 76025.2018 - recon_loss: 0.9996 - reg_output_loss: 75925.2428 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75925.2428 - val_loss: 73589.0013 - val_recon_loss: 1.0059 - val_reg_output_loss: 73488.4102 - val_recon_mean_squared_error: 1.0059 - val_reg_output_mean_squared_error: 73488.4102\n",
      "Epoch 477/500\n",
      "300/300 [==============================] - 0s 707us/step - loss: 76158.3781 - recon_loss: 0.9998 - reg_output_loss: 76058.3993 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 76058.3993 - val_loss: 73644.6466 - val_recon_loss: 1.0041 - val_reg_output_loss: 73544.2375 - val_recon_mean_squared_error: 1.0041 - val_reg_output_mean_squared_error: 73544.2375\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 730us/step - loss: 75275.9289 - recon_loss: 0.9996 - reg_output_loss: 75175.9707 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75175.9707 - val_loss: 73760.8491 - val_recon_loss: 1.0051 - val_reg_output_loss: 73660.3419 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 73660.3419\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 76589.6998 - recon_loss: 0.9997 - reg_output_loss: 76489.7334 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76489.7334 - val_loss: 73735.7937 - val_recon_loss: 1.0042 - val_reg_output_loss: 73635.3750 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73635.3750\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 75135.4760 - recon_loss: 0.9996 - reg_output_loss: 75035.5124 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75035.5124 - val_loss: 73801.6131 - val_recon_loss: 1.0043 - val_reg_output_loss: 73701.1855 - val_recon_mean_squared_error: 1.0043 - val_reg_output_mean_squared_error: 73701.1855\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 76460.5490 - recon_loss: 0.9996 - reg_output_loss: 76360.5870 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76360.5870 - val_loss: 73675.5859 - val_recon_loss: 1.0035 - val_reg_output_loss: 73575.2392 - val_recon_mean_squared_error: 1.0035 - val_reg_output_mean_squared_error: 73575.2392\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 687us/step - loss: 74972.3639 - recon_loss: 0.9996 - reg_output_loss: 74872.3985 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 74872.3985 - val_loss: 73557.1191 - val_recon_loss: 1.0048 - val_reg_output_loss: 73456.6416 - val_recon_mean_squared_error: 1.0048 - val_reg_output_mean_squared_error: 73456.6416\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 75865.2565 - recon_loss: 0.9996 - reg_output_loss: 75765.2969 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75765.2969 - val_loss: 73748.0111 - val_recon_loss: 1.0054 - val_reg_output_loss: 73647.4698 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 73647.4698\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 697us/step - loss: 75957.9481 - recon_loss: 0.9996 - reg_output_loss: 75857.9865 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75857.9865 - val_loss: 73699.8077 - val_recon_loss: 1.0056 - val_reg_output_loss: 73599.2502 - val_recon_mean_squared_error: 1.0056 - val_reg_output_mean_squared_error: 73599.2502\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 75632.3370 - recon_loss: 0.9996 - reg_output_loss: 75532.3771 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75532.3771 - val_loss: 73586.0611 - val_recon_loss: 1.0056 - val_reg_output_loss: 73485.5034 - val_recon_mean_squared_error: 1.0056 - val_reg_output_mean_squared_error: 73485.5034\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 733us/step - loss: 75117.9133 - recon_loss: 1.0003 - reg_output_loss: 75017.8845 - recon_mean_squared_error: 1.0003 - reg_output_mean_squared_error: 75017.8845 - val_loss: 73648.1144 - val_recon_loss: 1.0053 - val_reg_output_loss: 73547.5798 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 73547.5798\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 703us/step - loss: 75201.4086 - recon_loss: 1.0000 - reg_output_loss: 75101.4056 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 75101.4056 - val_loss: 73674.8006 - val_recon_loss: 1.0053 - val_reg_output_loss: 73574.2739 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 73574.2739\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 75103.6108 - recon_loss: 0.9998 - reg_output_loss: 75003.6314 - recon_mean_squared_error: 0.9998 - reg_output_mean_squared_error: 75003.6314 - val_loss: 73821.1958 - val_recon_loss: 1.0046 - val_reg_output_loss: 73720.7356 - val_recon_mean_squared_error: 1.0046 - val_reg_output_mean_squared_error: 73720.7356\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 710us/step - loss: 76490.8664 - recon_loss: 0.9996 - reg_output_loss: 76390.9068 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 76390.9068 - val_loss: 73822.1923 - val_recon_loss: 1.0051 - val_reg_output_loss: 73721.6864 - val_recon_mean_squared_error: 1.0051 - val_reg_output_mean_squared_error: 73721.6864\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 75023.3784 - recon_loss: 0.9999 - reg_output_loss: 74923.3861 - recon_mean_squared_error: 0.9999 - reg_output_mean_squared_error: 74923.3861 - val_loss: 74040.1320 - val_recon_loss: 1.0054 - val_reg_output_loss: 73939.5944 - val_recon_mean_squared_error: 1.0054 - val_reg_output_mean_squared_error: 73939.5944\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 75954.1817 - recon_loss: 0.9996 - reg_output_loss: 75854.2210 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75854.2210 - val_loss: 74057.5945 - val_recon_loss: 1.0045 - val_reg_output_loss: 73957.1441 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73957.1441\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 677us/step - loss: 75131.3677 - recon_loss: 0.9996 - reg_output_loss: 75031.4055 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75031.4055 - val_loss: 74035.2550 - val_recon_loss: 1.0055 - val_reg_output_loss: 73934.7019 - val_recon_mean_squared_error: 1.0055 - val_reg_output_mean_squared_error: 73934.7019\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 75037.5905 - recon_loss: 0.9997 - reg_output_loss: 74937.6211 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 74937.6211 - val_loss: 73980.8097 - val_recon_loss: 1.0050 - val_reg_output_loss: 73880.3109 - val_recon_mean_squared_error: 1.0050 - val_reg_output_mean_squared_error: 73880.3109\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 667us/step - loss: 76946.6576 - recon_loss: 0.9997 - reg_output_loss: 76846.6832 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 76846.6832 - val_loss: 73951.8030 - val_recon_loss: 1.0044 - val_reg_output_loss: 73851.3600 - val_recon_mean_squared_error: 1.0044 - val_reg_output_mean_squared_error: 73851.3600\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 713us/step - loss: 75431.1938 - recon_loss: 0.9996 - reg_output_loss: 75331.2324 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75331.2324 - val_loss: 73882.6803 - val_recon_loss: 1.0042 - val_reg_output_loss: 73782.2586 - val_recon_mean_squared_error: 1.0042 - val_reg_output_mean_squared_error: 73782.2586\n",
      "Epoch 496/500\n",
      "300/300 [==============================] - 0s 683us/step - loss: 75460.5638 - recon_loss: 1.0002 - reg_output_loss: 75360.5479 - recon_mean_squared_error: 1.0002 - reg_output_mean_squared_error: 75360.5479 - val_loss: 73915.0047 - val_recon_loss: 1.0045 - val_reg_output_loss: 73814.5556 - val_recon_mean_squared_error: 1.0045 - val_reg_output_mean_squared_error: 73814.5556\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 700us/step - loss: 74927.4653 - recon_loss: 0.9995 - reg_output_loss: 74827.5114 - recon_mean_squared_error: 0.9995 - reg_output_mean_squared_error: 74827.5114 - val_loss: 74003.0163 - val_recon_loss: 1.0058 - val_reg_output_loss: 73902.4381 - val_recon_mean_squared_error: 1.0058 - val_reg_output_mean_squared_error: 73902.4381\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 733us/step - loss: 75244.3038 - recon_loss: 0.9996 - reg_output_loss: 75144.3398 - recon_mean_squared_error: 0.9996 - reg_output_mean_squared_error: 75144.3398 - val_loss: 73992.2867 - val_recon_loss: 1.0053 - val_reg_output_loss: 73891.7586 - val_recon_mean_squared_error: 1.0053 - val_reg_output_mean_squared_error: 73891.7586\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 690us/step - loss: 75931.9637 - recon_loss: 1.0000 - reg_output_loss: 75831.9590 - recon_mean_squared_error: 1.0000 - reg_output_mean_squared_error: 75831.9590 - val_loss: 74106.5555 - val_recon_loss: 1.0060 - val_reg_output_loss: 74005.9522 - val_recon_mean_squared_error: 1.0060 - val_reg_output_mean_squared_error: 74005.9522\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 680us/step - loss: 75303.6726 - recon_loss: 0.9997 - reg_output_loss: 75203.7002 - recon_mean_squared_error: 0.9997 - reg_output_mean_squared_error: 75203.7002 - val_loss: 74148.2825 - val_recon_loss: 1.0049 - val_reg_output_loss: 74047.7888 - val_recon_mean_squared_error: 1.0049 - val_reg_output_mean_squared_error: 74047.7888\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"recon\": X_train, \"reg_output\": y_train},\n",
    "    validation_data=(X_valid, {\"recon\": X_valid, \"reg_output\": y_valid}),\n",
    "    epochs=hps[\"num_epochs\"],\n",
    "    batch_size=hps[\"batch_size\"],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Now I'll generate learning curves with `plotly`.  These are good for logging with `mlflow` or other similar experiment tracking libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df[\"step\"] = hist_df.index\n",
    "\n",
    "plot_df = hist_df.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"step\",\n",
    "        \"loss\",\n",
    "        \"val_loss\",\n",
    "        \"reg_output_loss\",\n",
    "        \"val_reg_output_loss\",\n",
    "        \"recon_loss\",\n",
    "        \"val_recon_loss\",\n",
    "    ],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_long = pd.melt(\n",
    "    plot_df, id_vars=\"step\", var_name=\"type\", value_name=\"loss_value\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "type=loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "loss",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          76779.03841145833,
          76777.44651041667,
          76776.607578125,
          76777.93765625,
          76775.87348958333,
          76771.59416666666,
          76762.84369791667,
          76766.206875,
          76768.7465625,
          76773.12895833333,
          76760.53046875,
          76747.07322916666,
          76741.7615625,
          76749.62395833334,
          76730.44442708333,
          76724.81078125,
          76714.486640625,
          76701.313203125,
          76722.05109375,
          76714.15052083334,
          76670.30546875,
          76655.84755208333,
          76548.65963541667,
          76500.419375,
          76418.19666666667,
          76554.07819010416,
          76323.604375,
          76439.80453125,
          76280.20697916667,
          76063.2990625,
          76019.64890625,
          75973.17033854166,
          75779.99244791667,
          75821.866640625,
          75334.07890625,
          75301.01122395834,
          75474.66875,
          75072.91061197917,
          75059.09005859375,
          74626.43473958333,
          74931.198125,
          74573.92829427084,
          74486.76958333333,
          74576.86450520833,
          74233.43833333334,
          73960.53205729167,
          73555.09552083333,
          74009.35057291666,
          73257.27755208334,
          72504.39541666667,
          73240.950703125,
          72902.31786458334,
          72312.10739583333,
          72794.89697916666,
          71738.56604166667,
          72628.76989583333,
          71674.17701822917,
          72096.90802083333,
          73023.17104166666,
          71820.64638020833,
          70907.23458333334,
          71579.4346875,
          71807.19041666666,
          71351.24453125,
          70937.40171875,
          71057.72067708333,
          70952.37584635416,
          70136.22411458334,
          71302.875,
          69601.48338541666,
          69848.29104166667,
          70236.88994791667,
          70361.05645833333,
          69233.83791666667,
          69195.64552083334,
          69407.44541666667,
          70476.94494791667,
          70539.91197916666,
          70129.43651041666,
          69600.10451822917,
          70015.56953125,
          68597.4759765625,
          69292.039375,
          70746.947421875,
          70399.7753125,
          69558.25674479167,
          67870.234453125,
          69259.90361979167,
          68295.88234375,
          68902.62852864583,
          69559.37046875,
          69148.730703125,
          69323.63317708333,
          69788.60169270834,
          69710.14498697917,
          67587.08065104167,
          72556.823515625,
          71400.99557291667,
          71780.69203125,
          69435.02770833333,
          69764.46739583333,
          70677.30703125,
          69472.60661458333,
          70958.86072916667,
          66372.10875,
          71894.07541666667,
          69540.70286458333,
          70728.50856770833,
          71383.70606770834,
          69796.9065625,
          71292.73145833334,
          69245.7378125,
          74423.63986979167,
          70069.439921875,
          72476.17536458334,
          71134.27828125,
          72438.18958333334,
          69068.29744791667,
          70205.84986979167,
          70336.51104166667,
          71193.67345052083,
          70185.97677083334,
          71518.89244791666,
          70003.19770833333,
          70929.12294270833,
          68970.10885416667,
          70127.80377604166,
          74575.90583333334,
          70839.36114583333,
          70660.61807291667,
          72776.978671875,
          74190.20026041666,
          70997.95033854166,
          67780.93114583334,
          71452.8725,
          71683.8141015625,
          73121.84791666667,
          72553.08572916666,
          68368.85860026041,
          70542.35994791667,
          70734.17877604166,
          69976.18171875,
          69310.42041666666,
          72994.33421875,
          67860.14328125,
          74733.83083333333,
          72227.86786458333,
          73852.23213541666,
          72929.66473958333,
          76963.909375,
          74195.93291666667,
          72031.71427083333,
          73111.36065104167,
          70338.217109375,
          70343.55708333333,
          73538.453984375,
          70576.68356770833,
          69694.02565104167,
          72226.36440104166,
          72080.85739583333,
          71634.82703125,
          69075.50291666666,
          72533.72510416666,
          68564.97265625,
          71342.62358723958,
          72886.37020182292,
          73422.9895703125,
          71357.26684895833,
          73956.99841145833,
          72170.69046875,
          72748.90158854167,
          71329.494375,
          72411.20348958333,
          69788.838671875,
          71700.46294270833,
          72167.97380208333,
          70109.3409765625,
          64555.8153125,
          71002.89427083333,
          71589.15203125,
          69108.39403645834,
          72727.61640625,
          73330.70260416667,
          70486.98799479166,
          68617.193125,
          68039.19,
          70762.91338541667,
          73091.70072916667,
          70144.08802083334,
          70695.5125,
          71890.36026041667,
          72311.20716145834,
          74330.50994791667,
          72680.41208333333,
          71407.55239583334,
          70771.64721354167,
          70276.41666666667,
          70086.73151041666,
          70374.50981770833,
          70686.51796875,
          69682.54721354166,
          68791.79703125,
          70012.79513020834,
          70131.05484375,
          70773.74932291667,
          69349.02333333333,
          69864.26135416667,
          69763.88908854166,
          69640.31145833334,
          71190.65606770833,
          71883.06833333333,
          72233.39833333333,
          70319.18747395833,
          69330.62088541666,
          69954.88130208333,
          70856.55682291667,
          68066.47286458334,
          72041.34244791667,
          70753.898203125,
          71450.60986979166,
          70070.60625,
          71458.0515625,
          73692.07596354166,
          71531.2153125,
          71557.51651041667,
          72920.85390625,
          71352.986015625,
          71095.97158854167,
          68900.37813802084,
          71370.50513020833,
          71246.39643880208,
          71781.965859375,
          69020.12981770834,
          72431.11061197917,
          71453.591796875,
          69454.58067708333,
          69492.60583333333,
          70159.447890625,
          69663.63770833334,
          67788.93598958333,
          70316.64578125,
          68001.6851171875,
          70139.40692708333,
          69997.46333333333,
          72877.96018229167,
          70580.85734375,
          68877.37471354166,
          68955.00794270834,
          69432.82697916667,
          68783.39895833333,
          70094.09083333334,
          67723.80669270833,
          71079.59471354166,
          69515.76911458334,
          70729.80861979167,
          72450.47197916667,
          71372.57551432292,
          70928.51143229166,
          70618.87671875,
          72030.99994791667,
          71451.73114583333,
          69738.29932291666,
          72850.09279947917,
          71616.00401041667,
          68152.25600260416,
          69760.263359375,
          68243.01145833333,
          71549.474609375,
          70369.39510416667,
          70698.42075520834,
          70858.18291666667,
          69970.6825,
          69315.30015625,
          68421.457109375,
          70547.59278645834,
          69944.127578125,
          68658.00083333334,
          71990.17473958334,
          69950.4190625,
          71370.84510416667,
          69012.13901692709,
          69346.89505208333,
          68177.50291666666,
          67554.54901041667,
          68565.45059895833,
          69917.2954296875,
          71030.304140625,
          68620.15442708334,
          67645.49299479167,
          66975.16213541667,
          67869.52572916666,
          68290.83484375,
          68529.55411458333,
          69666.44390625,
          69271.17838053385,
          64556.208958333336,
          70243.63877604167,
          70770.24697916667,
          69185.39953125,
          66798.26877604167,
          70813.71197916666,
          72583.74247395834,
          70160.61151692708,
          71080.31677083333,
          69328.90834635416,
          71224.6678125,
          73045.80671875,
          72715.5359375,
          73653.835390625,
          74265.34036458333,
          69433.38479166667,
          68937.18841145834,
          70406.39860677083,
          66711.3071875,
          66998.03291666666,
          70150.19489583334,
          68993.33677083334,
          73987.25184895833,
          68281.61791666667,
          66961.10841145834,
          67917.9625,
          67731.29598958333,
          68366.65559895833,
          68962.58588541667,
          68387.72135416667,
          71916.086171875,
          70894.34161458333,
          68737.99458333333,
          70506.6775,
          68330.99912760417,
          66969.83876302083,
          64986.64658854167,
          66358.73263020834,
          69945.50794270834,
          67254.96815104167,
          64294.038385416665,
          68744.82893229167,
          71572.51484375,
          69328.14127604167,
          68856.80309895833,
          69220.340625,
          70448.76791666666,
          69587.13046875,
          69371.117109375,
          72850.02723958333,
          72209.44223958334,
          69934.84161458333,
          73372.11638020833,
          68656.9478125,
          67819.45799479166,
          71305.77018229167,
          70965.60971354166,
          72379.07166666667,
          73180.71947916667,
          70124.57151041667,
          72250.26651041667,
          73189.75635416666,
          73356.36510416666,
          73978.59208333334,
          71866.2496875,
          71737.01052083333,
          72677.48546875,
          72734.510390625,
          72044.2026953125,
          70306.59552083333,
          70382.25635416666,
          68320.4196875,
          72191.57447916667,
          70694.49822916667,
          68305.54526041666,
          71116.191875,
          70641.2997265625,
          70206.62489583333,
          70410.60947916667,
          75531.019765625,
          71028.64877604166,
          72372.32859375,
          72309.79119791667,
          74668.74359375,
          68452.71111979167,
          70930.34158854166,
          74179.81484375,
          71729.26131510417,
          68624.94721354167,
          72918.59625,
          71819.35408854167,
          69302.04356770833,
          71763.27447916666,
          71022.70005208334,
          70166.63161458333,
          68970.373828125,
          72214.94369791666,
          68945.21028645833,
          69618.58844401041,
          74449.65341145833,
          73674.30559895834,
          71587.79567708333,
          70901.66145833333,
          71453.946640625,
          72083.35290364583,
          73872.26377604167,
          76137.54645833334,
          74306.84145833334,
          75239.99575520834,
          75055.32125,
          73783.6262890625,
          71948.71151041667,
          74777.7337109375,
          75639.61578125,
          73842.05544270833,
          73157.80625,
          72753.80115885417,
          73255.68940104167,
          74036.411953125,
          71285.94921875,
          71590.4904296875,
          73384.92947916666,
          72601.32,
          73309.25770833333,
          74666.252890625,
          76932.04645833334,
          77460.54630208333,
          77639.37864583333,
          77357.44135416667,
          75930.92104166666,
          76179.49096354167,
          76033.053125,
          74515.668125,
          76359.76973958334,
          76178.46065104166,
          75776.9932421875,
          75270.35838541666,
          78608.66205729167,
          76984.90432291667,
          77983.75645833333,
          75790.2459375,
          76701.50294270834,
          76430.58200520833,
          76026.95171875,
          76903.52635416666,
          75872.421796875,
          76269.25078125,
          73794.23583333334,
          75295.67651041667,
          75466.66895833334,
          75049.16875,
          76354.35239583334,
          74177.03364583333,
          75454.67203125,
          76217.19109375,
          75588.79088541666,
          78636.68059895834,
          76215.03578125,
          74521.9119921875,
          76007.00989583334,
          76545.50401041667,
          76348.607578125,
          75724.11151041667,
          75129.4928125,
          76836.285390625,
          76379.56057291667,
          76445.70208333334,
          75935.42338541667,
          74881.75395833333,
          75869.01755208333,
          75854.70895833333,
          76794.39161458334,
          75823.99442708334,
          76113.17427083333,
          76161.05677083334,
          77888.72098958334,
          76316.295625,
          76094.71265625,
          74594.30361979167,
          76015.50041666666,
          76025.20182291667,
          76158.378125,
          75275.92885416666,
          76589.69984375,
          75135.47598958333,
          76460.54895833334,
          74972.36385416667,
          75865.25651041667,
          75957.948125,
          75632.33697916666,
          75117.91325520833,
          75201.40864583333,
          75103.61076822916,
          76490.86635416666,
          75023.378359375,
          75954.18171875,
          75131.36774739584,
          75037.59049479167,
          76946.65760416667,
          75431.19380208333,
          75460.56377604167,
          74927.4653125,
          75244.30375,
          75931.963671875,
          75303.67255208333
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=val_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "val_loss",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "val_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          72269.72546875,
          72264.1503125,
          72285.3728125,
          72272.17125,
          72267.6459375,
          72251.4878125,
          72259.721875,
          72262.081875,
          72275.3490625,
          72268.86578125,
          72272.94046875,
          72287.37375,
          72295.67671875,
          72284.8275,
          72278.9990625,
          72285.704375,
          72317.28890625,
          72355.019375,
          72314.0096875,
          72326.50359375,
          72354.82859375,
          72433.2859375,
          72556.4878125,
          72875.02,
          73007.1521875,
          73205.34640625,
          73595.881875,
          74095.88125,
          74995.68796875,
          76866.0175,
          78347.23296875,
          79661.98296875,
          80400.58265625,
          82166.99375,
          84984.29734375,
          89804.8940625,
          90550.4234375,
          95681.6946875,
          100102.0071875,
          104434.8446875,
          107447.1734375,
          111957.04125,
          117698.18375,
          125501.744375,
          128056.540625,
          130591.6571875,
          134939.93625,
          141854.623125,
          144963.989375,
          161458.1046875,
          166954.9271875,
          176599.3415625,
          184628.47625,
          190064.5559375,
          204464.953125,
          202438.681875,
          209503.75125,
          210998.476875,
          207286.47125,
          216957.239375,
          225559.954375,
          230995.17375,
          227894.964375,
          235113.175625,
          243121.581875,
          250017.615,
          251646.244375,
          251693.124375,
          250515.5375,
          270256.576875,
          261848.085625,
          260519.454375,
          259723.394375,
          267557.314375,
          279454.54875,
          283512.534375,
          291774.6625,
          277246.83625,
          274851.500625,
          278200.579375,
          284472.528125,
          292592.40875,
          286270.38,
          280205.231875,
          263899.664375,
          262167.40125,
          286040.65125,
          277123.244375,
          273656.13125,
          265711.198125,
          253923.765625,
          245129.4234375,
          242649.205,
          232929.79625,
          233545.96625,
          226501.5115625,
          208176.161875,
          195997.9359375,
          184860.4271875,
          187256.0559375,
          186578.5359375,
          182081.96375,
          180550.2296875,
          174847.1128125,
          173418.596875,
          164001.015,
          162838.92875,
          155433.4153125,
          142976.800625,
          140579.924375,
          134627.3840625,
          135347.75875,
          121825.2240625,
          118304.2246875,
          113822.3396875,
          112991.1846875,
          106475.3621875,
          106497.6753125,
          104782.8509375,
          104562.9,
          100272.2121875,
          99363.7115625,
          97115.67765625,
          94434.9584375,
          92764.6534375,
          93307.89375,
          91624.2178125,
          87103.97515625,
          86765.03640625,
          86330.82171875,
          85351.46625,
          82698.62875,
          83282.7996875,
          82653.23890625,
          82032.39359375,
          81838.24828125,
          80455.2078125,
          78982.95234375,
          79950.14578125,
          78476.3975,
          78123.6646875,
          77659.959375,
          77488.21453125,
          76713.50140625,
          78147.20984375,
          77354.81390625,
          77305.46203125,
          76499.74484375,
          75897.7884375,
          74624.0059375,
          74232.85421875,
          74303.36046875,
          74357.0003125,
          74671.0453125,
          75590.3284375,
          75347.10625,
          76202.40265625,
          76421.768125,
          75381.06328125,
          74474.8646875,
          74604.0671875,
          75362.565,
          74292.3575,
          75349.5115625,
          74923.8709375,
          74123.42484375,
          73945.71671875,
          73962.28328125,
          73386.8128125,
          73518.4453125,
          73269.268125,
          73613.2096875,
          73655.55703125,
          74007.501875,
          73758.8678125,
          74138.988125,
          74281.37015625,
          74381.31484375,
          74134.54640625,
          74175.96125,
          74466.9134375,
          74545.38015625,
          74063.383125,
          73955.65515625,
          74187.60109375,
          74690.3821875,
          74626.00828125,
          73828.34875,
          73881.0175,
          73764.0059375,
          73258.131875,
          73390.1815625,
          73273.8221875,
          73429.45953125,
          73632.99203125,
          73735.17265625,
          73958.5696875,
          74132.13546875,
          73878.24984375,
          73419.6021875,
          73771.115625,
          74020.28359375,
          73643.7621875,
          73716.28453125,
          73690.41109375,
          73895.156875,
          74022.70453125,
          74128.779375,
          73728.27359375,
          73974.33453125,
          73932.0059375,
          73466.63703125,
          73500.41875,
          73465.37609375,
          73557.23984375,
          73733.78625,
          74078.0890625,
          73829.04296875,
          73881.9359375,
          73652.75578125,
          73447.13265625,
          73172.09390625,
          72844.98640625,
          72702.0271875,
          72828.6696875,
          72545.77421875,
          72667.03015625,
          73231.055625,
          73429.2665625,
          73140.7603125,
          73137.37390625,
          72995.48546875,
          73032.5278125,
          72967.543125,
          72858.5575,
          72764.020625,
          73190.3334375,
          73372.13328125,
          73484.84671875,
          73247.23640625,
          73377.22578125,
          73845.8803125,
          73556.41546875,
          73698.34046875,
          73399.270625,
          73058.41125,
          73262.7971875,
          73023.09625,
          73067.05015625,
          73008.76109375,
          73490.81,
          73595.02140625,
          73243.38765625,
          73479.475625,
          73215.3146875,
          72867.861875,
          72726.30328125,
          73049.0190625,
          73107.88375,
          73012.99984375,
          72938.7315625,
          73083.94359375,
          72964.48046875,
          72868.60234375,
          73090.7778125,
          72726.8240625,
          72998.69875,
          73006.29390625,
          72935.91375,
          72939.7378125,
          72811.87125,
          72959.84609375,
          73328.87125,
          73370.07453125,
          73261.2565625,
          73429.00984375,
          73097.68734375,
          73009.1759375,
          73190.92390625,
          72880.0009375,
          72970.14640625,
          73294.50796875,
          73581.55390625,
          73894.43390625,
          73926.37484375,
          73676.61109375,
          73564.43,
          73404.9421875,
          73603.2365625,
          73945.08375,
          74086.05234375,
          73755.745,
          73683.1834375,
          73297.48234375,
          73077.3184375,
          73610.3621875,
          73291.81015625,
          73165.5971875,
          73183.6303125,
          73304.38578125,
          73352.861875,
          73142.24484375,
          73452.28046875,
          73214.09703125,
          73734.84875,
          73116.3290625,
          73147.21734375,
          72995.63390625,
          72748.61375,
          72537.27390625,
          72680.90859375,
          72782.7775,
          72873.4628125,
          73504.65875,
          73902.69921875,
          73441.23015625,
          73740.09328125,
          73424.85796875,
          73429.08546875,
          73381.52859375,
          73317.384375,
          73553.1140625,
          73514.690625,
          73805.650625,
          73498.1490625,
          73385.5834375,
          73363.399375,
          73394.685,
          73147.45375,
          73122.2234375,
          73213.2809375,
          73414.343125,
          73663.3678125,
          73131.1184375,
          73124.4734375,
          73462.723125,
          73294.9215625,
          73117.03875,
          72942.3609375,
          73129.606875,
          73060.3459375,
          72958.0159375,
          72659.29625,
          72913.6071875,
          72916.01375,
          73025.5059375,
          73070.4946875,
          73145.7628125,
          73346.0278125,
          73756.576875,
          73559.9928125,
          73550.976875,
          73749.1034375,
          73453.8796875,
          73597.531875,
          73299.5996875,
          73199.2909375,
          72825.168125,
          72688.3465625,
          72881.2990625,
          72446.74671875,
          72607.84125,
          72572.8309375,
          72489.16921875,
          72831.40171875,
          73147.2084375,
          73489.515,
          73279.12734375,
          73222.9646875,
          73705.596875,
          73602.0653125,
          73491.0653125,
          73561.9465625,
          73434.035625,
          72993.3703125,
          72900.05984375,
          72842.1321875,
          72977.174375,
          72947.2084375,
          73323.44,
          73516.278125,
          73294.03421875,
          73568.154375,
          74013.5221875,
          74015.59125,
          73929.643125,
          74313.0253125,
          74421.7,
          74424.585,
          74397.5671875,
          74784.976875,
          74923.73,
          75091.5725,
          74733.43125,
          74635.8709375,
          74478.604375,
          74525.4603125,
          74864.73,
          74418.239375,
          74322.615625,
          74086.7034375,
          73797.3846875,
          73614.35203125,
          73649.2671875,
          73443.39046875,
          73593.9653125,
          74042.2096875,
          73903.6565625,
          73933.26953125,
          73598.1290625,
          73781.57140625,
          73796.3309375,
          73770.44953125,
          73712.57828125,
          74256.278125,
          74328.875625,
          74214.929375,
          74502.569375,
          74483.40796875,
          74000.73203125,
          73872.3628125,
          73739.98484375,
          73504.22390625,
          73288.19703125,
          73224.51984375,
          73224.10421875,
          73232.69609375,
          73227.9815625,
          73093.63953125,
          73234.88890625,
          73114.0553125,
          73074.90953125,
          72920.95328125,
          72810.3390625,
          72750.02421875,
          72780.63625,
          72606.69359375,
          72551.184375,
          72440.53515625,
          72623.05109375,
          72664.9046875,
          72581.19109375,
          72676.3209375,
          72745.8134375,
          72732.3775,
          72644.27953125,
          72526.3659375,
          72648.0525,
          72429.45921875,
          72472.5071875,
          72596.7621875,
          72547.625625,
          72603.0328125,
          72729.8128125,
          72613.5065625,
          72630.044375,
          72608.610625,
          72653.911875,
          72614.39484375,
          72565.28484375,
          72700.77125,
          72696.47296875,
          72629.61109375,
          72840.359375,
          72832.4246875,
          72908.44296875,
          72965.08421875,
          72847.04640625,
          72995.99078125,
          72970.8809375,
          73027.48953125,
          73107.63671875,
          73245.3046875,
          73408.2984375,
          73602.9375,
          73589.00125,
          73644.6465625,
          73760.8490625,
          73735.79375,
          73801.613125,
          73675.5859375,
          73557.1190625,
          73748.01109375,
          73699.80765625,
          73586.06109375,
          73648.114375,
          73674.800625,
          73821.19578125,
          73822.19234375,
          74040.13203125,
          74057.59453125,
          74035.255,
          73980.8096875,
          73951.80296875,
          73882.6803125,
          73915.0046875,
          74003.01625,
          73992.28671875,
          74106.55546875,
          74148.2825
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=reg_output_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "reg_output_loss",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "reg_output_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          76678.85145833333,
          76677.389375,
          76676.580625,
          76677.92010416667,
          76675.85197916666,
          76671.5315625,
          76662.75735677083,
          76665.93973958334,
          76668.63083333333,
          76672.99447916666,
          76660.45182291667,
          76646.8671875,
          76641.60838541666,
          76649.38002604166,
          76630.19328125,
          76624.52682291667,
          76614.0796875,
          76600.86276041667,
          76621.04364583333,
          76613.19479166667,
          76569.81557291666,
          76554.81057291667,
          76447.7325,
          76398.45653645834,
          76315.69927083333,
          76451.6976171875,
          76214.99390625,
          76335.979140625,
          76171.29880208333,
          75949.83104166666,
          75911.2034375,
          75857.48315104167,
          75669.62265625,
          75705.60067708333,
          75223.75927083334,
          75146.66190104166,
          75356.59958333333,
          74952.7093359375,
          74936.78524088542,
          74499.32463541666,
          74801.75690104166,
          74408.59567708333,
          74342.29072916666,
          74432.05231770834,
          74057.77697916667,
          73777.18640625,
          73417.81041666666,
          73872.15252604167,
          73112.33213541667,
          72356.65932291666,
          73077.71372395834,
          72761.70901041667,
          72161.78841145833,
          72627.31401041667,
          71590.60408854167,
          72446.81505208333,
          71503.71953125,
          71910.25057291667,
          72807.96520833333,
          71664.04638020834,
          70733.6278125,
          71389.49411458333,
          71640.92177083333,
          71172.27854166667,
          70780.70046875,
          70829.64427083333,
          70806.231171875,
          69953.80473958333,
          71153.52453125,
          69432.950546875,
          69650.78135416667,
          70097.21328125,
          70125.04802083333,
          69060.51036458333,
          69061.738203125,
          69256.45328125,
          70327.99510416666,
          70366.23385416667,
          69959.16630208334,
          69434.130625,
          69844.51739583333,
          68412.01303385416,
          69126.63236979167,
          70544.64359375,
          70231.59505208333,
          69412.96572916667,
          67682.56588541667,
          69115.97114583333,
          68108.85947916667,
          68726.923203125,
          69376.73815104166,
          68999.2175,
          69177.2084375,
          69313.17822916666,
          69583.42397135416,
          67326.65401041666,
          72405.54635416667,
          71225.70533854167,
          71651.69109375,
          69311.467421875,
          69636.23861979166,
          70529.59348958333,
          69323.75958333333,
          70796.89515625,
          66175.0846875,
          71704.22505208333,
          69397.01453125,
          70583.04895833334,
          71226.41453125,
          69639.19104166667,
          71129.75776041667,
          69088.45020833334,
          74229.96061197917,
          69921.17002604167,
          72313.95180989584,
          71014.24783854166,
          72272.56484375,
          68941.99291666667,
          70051.82213541666,
          70193.86744791667,
          71055.905703125,
          70040.31520833333,
          71400.43166666667,
          69838.70276041667,
          70804.879453125,
          68787.89802083334,
          69994.59322916667,
          74448.78885416666,
          70717.43151041666,
          70526.10635416667,
          72655.27075520833,
          74062.01958333333,
          70856.08817708334,
          67638.125,
          71327.731875,
          71537.82130208334,
          73000.27619791667,
          72422.38229166667,
          68254.36953776042,
          70404.51833333333,
          70607.06940104166,
          69863.17932291667,
          69148.05067708333,
          72877.88598958333,
          67738.22114583333,
          74612.72630208333,
          72114.302421875,
          73720.50088541667,
          72813.20166666666,
          76854.00635416666,
          74077.10078125,
          71894.42682291666,
          72994.62216145833,
          70223.010546875,
          70227.763125,
          73427.48708333333,
          70467.32244791667,
          69577.37442708333,
          72106.64177083333,
          71954.4865625,
          71517.20177083333,
          68963.19598958333,
          72413.40734375,
          68452.1215625,
          71226.80151692708,
          72770.42916015624,
          73287.81865885417,
          71248.04833333334,
          73839.02822916667,
          72061.98135416667,
          72635.51208333333,
          71221.772421875,
          72295.90609375,
          69674.89484375,
          71587.7703125,
          72048.39114583333,
          69987.5931640625,
          64440.87234375,
          70893.68588541666,
          71478.29069010417,
          68991.11234375,
          72615.70864583334,
          73202.14677083334,
          70372.599609375,
          68499.53677083334,
          67919.31356770833,
          70645.45513020833,
          72957.5909375,
          70039.25911458333,
          70587.87723958334,
          71778.334375,
          72194.07473958333,
          74225.26072916666,
          72570.140625,
          71300.89401041667,
          70658.4425,
          70169.427890625,
          69960.08299479166,
          70256.525078125,
          70574.77536458333,
          69571.71497395834,
          68679.85291666667,
          69904.90348958333,
          70021.20104166666,
          70662.96609375,
          69241.18125,
          69753.73369791667,
          69653.42377604167,
          69529.83270833333,
          71083.62526041667,
          71773.65276041666,
          72108.26572916667,
          70201.51973958334,
          69219.1821875,
          69849.330625,
          70752.49888020834,
          67952.76416666666,
          71936.56390625,
          70648.07645833334,
          71346.2734375,
          69962.45645833333,
          71353.3253125,
          73584.34041666667,
          71422.37796875,
          71449.55375,
          72816.21432291667,
          71236.81758463541,
          70990.50802083334,
          68791.117890625,
          71265.69348958334,
          71141.83337239583,
          71678.64713541667,
          68915.24606770833,
          72323.2834765625,
          71347.5575,
          69350.12333333334,
          69385.88625,
          70054.67078125,
          69558.04609375,
          67677.37205729166,
          70211.80765625,
          67887.87591145834,
          70030.89807291667,
          69895.11739583334,
          72770.014296875,
          70476.3100390625,
          68771.37924479166,
          68849.43385416667,
          69329.52604166667,
          68678.62294270833,
          69991.85989583333,
          67620.566328125,
          70976.079453125,
          69412.83114583333,
          70625.08354166667,
          72341.66385416666,
          71269.76412760417,
          70826.43125,
          70515.34231770833,
          71926.82265625,
          71345.77255208333,
          69634.78307291666,
          72744.99557291667,
          71513.09716145834,
          68047.21692708334,
          69656.08458333333,
          68135.93677083333,
          71446.23986979167,
          70267.23208333334,
          70595.50721354167,
          70755.21666666666,
          69868.08479166667,
          69213.501875,
          68319.25549479167,
          70445.04890625,
          69840.98604166666,
          68556.21541666667,
          71887.52848958333,
          69848.3421875,
          71264.43653645834,
          68908.694140625,
          69243.31609375,
          68076.20614583333,
          67452.09114583333,
          68463.38380208334,
          69815.42865885417,
          70929.05510416666,
          68517.46557291667,
          67543.45411458334,
          66873.14395833333,
          67768.39984375,
          68189.19833333333,
          68423.66932291667,
          69563.83125,
          69170.29985026042,
          64454.366875,
          70141.80098958334,
          70669.44416666667,
          69084.24557291667,
          66696.93583333334,
          70712.18223958333,
          72483.02302083334,
          70059.45012369791,
          70978.75380208333,
          69227.80420572916,
          71123.88234375,
          72944.91166666667,
          72614.75739583334,
          73553.177578125,
          74164.91677083333,
          69332.704453125,
          68836.230390625,
          70305.990234375,
          66610.74661458333,
          66896.962578125,
          70049.74046875,
          68892.81557291666,
          73886.944765625,
          68180.83833333333,
          66860.83364583334,
          67817.13708333333,
          67630.287578125,
          68265.39666666667,
          68861.92494791666,
          68287.33057291666,
          71815.55838541666,
          70793.60078125,
          68637.86510416666,
          70405.23677083333,
          68230.64389322916,
          66869.641640625,
          64886.20385416667,
          66257.23221354166,
          69844.74005208333,
          67154.75403645834,
          64193.37096354167,
          68644.42161458333,
          71471.76359375,
          69227.68520833334,
          68756.45666666667,
          69120.06354166666,
          70348.6609375,
          69486.88479166667,
          69270.46463541666,
          72749.83153645834,
          72109.3765625,
          69834.77171875,
          73271.49809895833,
          68556.81861979167,
          67719.01440104167,
          71205.72041666666,
          70865.41419270834,
          72279.03489583333,
          73080.6421875,
          70024.44760416666,
          72150.20723958334,
          73089.75192708333,
          73256.36109375,
          73878.58760416666,
          71766.18098958333,
          71636.73223958333,
          72577.4871875,
          72634.51260416667,
          71944.16395833333,
          70206.5959375,
          70282.1525,
          68220.33192708333,
          72091.57119791667,
          70594.45796875,
          68205.47807291667,
          71016.07369791667,
          70541.31631510417,
          70106.4690625,
          70310.62880208333,
          75430.98666666666,
          70928.65223958333,
          72272.07911458334,
          72209.74973958333,
          74568.75143229167,
          68352.69528645833,
          70830.32354166667,
          74079.80557291667,
          71629.22869791667,
          68524.92846354167,
          72818.59333333334,
          71719.34411458333,
          69201.91434895834,
          71663.28208333334,
          70921.92927083334,
          70066.64916666667,
          68870.34236979167,
          72114.97770833333,
          68845.13888020834,
          69518.590390625,
          74349.62869791666,
          73574.28682291666,
          71487.80901041666,
          70801.46286458333,
          71353.97640625,
          71983.30026041667,
          73772.2959375,
          76037.55541666667,
          74206.8246875,
          75139.93208333333,
          74955.35729166666,
          73683.55055989583,
          71848.744375,
          74677.71934895833,
          75539.39856770834,
          73742.05848958333,
          73057.82432291667,
          72653.76783854167,
          73155.70791666667,
          73936.45046875,
          71185.9621875,
          71490.492265625,
          73284.948046875,
          72500.63078125,
          73209.27783854166,
          74566.04552083333,
          76832.08901041666,
          77360.54401041666,
          77539.40927083333,
          77257.44854166667,
          75830.96559895833,
          76079.458828125,
          75933.06690104166,
          74415.69578125,
          76259.79291666667,
          76078.49213541667,
          75677.021328125,
          75170.37765625,
          78508.68734375,
          76884.94265625,
          77883.790625,
          75690.27690104167,
          76601.52875,
          76330.61651041667,
          75926.99359375,
          76803.5309375,
          75772.463515625,
          76169.28260416667,
          73694.25083333334,
          75195.711328125,
          75366.69223958334,
          74949.19640625,
          76254.35640625,
          74077.07578125,
          75354.68927083333,
          76117.22783203125,
          75488.78286458334,
          78536.721015625,
          76115.07171875,
          74421.94561197917,
          75907.01802083333,
          76445.53479166667,
          76248.64697916666,
          75624.12575520833,
          75029.5178125,
          76736.30403645833,
          76279.59661458334,
          76345.72942708334,
          75835.44950520834,
          74781.77822916667,
          75769.03786458333,
          75754.74510416666,
          76694.42604166667,
          75724.0296875,
          76013.21174479167,
          76061.09427083333,
          77788.76104166667,
          76216.32864583333,
          75994.75229166666,
          74494.3375,
          75915.5459375,
          75925.24276041667,
          76058.39927083334,
          75175.97067708333,
          76489.73338541666,
          75035.51244791667,
          76360.58703125,
          74872.39854166667,
          75765.29692708333,
          75857.98645833334,
          75532.37708333334,
          75017.88453125,
          75101.40559895833,
          75003.63139322917,
          76390.90682291667,
          74923.38609375,
          75854.22104166666,
          75031.4055078125,
          74937.62114583333,
          76846.68321614583,
          75331.23239583333,
          75360.54794270833,
          74827.51140625,
          75144.33979166667,
          75831.958984375,
          75203.70020833334
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=val_reg_output_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "val_reg_output_loss",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "val_reg_output_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          72138.20328125,
          72136.76859375,
          72128.59953125,
          72130.3740625,
          72137.3759375,
          72132.210625,
          72138.42046875,
          72143.495,
          72151.95625,
          72155.263125,
          72155.5465625,
          72157.8878125,
          72154.98828125,
          72163.3734375,
          72169.03203125,
          72168.2565625,
          72202.2990625,
          72221.156875,
          72199.28578125,
          72212.9825,
          72242.7409375,
          72295.65796875,
          72398.895625,
          72547.24953125,
          72841.1096875,
          73051.14828125,
          73422.28015625,
          73914.07515625,
          74748.2578125,
          75910.2971875,
          76992.728125,
          78455.3615625,
          80178.330625,
          81858.8828125,
          84588.16265625,
          87753.2025,
          89921.399375,
          95253.175625,
          99844.0565625,
          104052.6359375,
          106882.3071875,
          111731.4453125,
          117347.878125,
          122681.155,
          127095.8484375,
          130276.451875,
          133617.06875,
          138084.3009375,
          144458.2253125,
          161097.085,
          165936.4965625,
          175118.0996875,
          183631.15,
          189757.973125,
          203322.946875,
          201620.435625,
          209224.408125,
          210751.560625,
          206438.724375,
          216602.48,
          225100.805625,
          230638.775625,
          227753.848125,
          234732.00875,
          242993.985,
          249851.608125,
          251471.846875,
          251552.94875,
          250272.2175,
          269876.314375,
          261654.39875,
          260283.128125,
          259567.685625,
          267278.786875,
          279337.14625,
          283302.84625,
          291634.434375,
          277092.324375,
          274712.7775,
          278081.18125,
          284279.9725,
          292457.251875,
          286142.06,
          280086.520625,
          263718.064375,
          261987.254375,
          285878.23625,
          276979.0575,
          273480.050625,
          265589.591875,
          253712.866875,
          244842.9528125,
          242484.373125,
          232820.07375,
          233226.745,
          226374.4953125,
          208046.1215625,
          195798.053125,
          184707.2409375,
          187076.1834375,
          186214.5740625,
          181960.68125,
          180435.246875,
          174555.5146875,
          173300.82375,
          163886.48375,
          162732.89375,
          155174.6975,
          142873.7228125,
          140477.1484375,
          134523.845625,
          134981.18625,
          121651.5028125,
          118199.721875,
          113719.3409375,
          112886.2821875,
          106370.6046875,
          106254.1671875,
          104656.014375,
          104456.8609375,
          100169.2059375,
          99259.9640625,
          97011.38578125,
          94331.9096875,
          92659.8446875,
          93198.15296875,
          91523.27828125,
          86987.52359375,
          86660.484375,
          86229.26171875,
          85251.0403125,
          82591.23375,
          83177.36,
          82550.973125,
          81901.230625,
          81736.83671875,
          80354.474375,
          78881.48875,
          79841.20328125,
          78373.666875,
          78022.60484375,
          77558.2096875,
          77384.1475,
          76606.37625,
          78045.5515625,
          77249.5821875,
          77203.709375,
          76395.830625,
          75793.3565625,
          74516.43859375,
          74129.9315625,
          74201.546875,
          74256.351875,
          74569.66125,
          75486.670625,
          75245.34375,
          76100.19140625,
          76320.03203125,
          75278.90671875,
          74362.985625,
          74503.355625,
          75260.0534375,
          74187.37796875,
          75248.7525,
          74823.00578125,
          74015.53234375,
          73843.6196875,
          73861.4009375,
          73285.8375,
          73414.6896875,
          73167.56375,
          73512.4178125,
          73552.22,
          73891.0721875,
          73657.7903125,
          74037.90125,
          74179.705,
          74277.31046875,
          74032.625,
          74075.138125,
          74365.56296875,
          74444.635625,
          73961.9028125,
          73855.0015625,
          74087.16703125,
          74589.8484375,
          74525.53375,
          73727.12515625,
          73779.89140625,
          73662.7865625,
          73156.6225,
          73286.85171875,
          73173.1984375,
          73328.7996875,
          73531.7740625,
          73634.5225,
          73857.359375,
          74031.13046875,
          73777.46765625,
          73318.70921875,
          73670.13640625,
          73915.6478125,
          73543.474375,
          73615.61203125,
          73589.1409375,
          73792.23015625,
          73921.66046875,
          74025.62515625,
          73627.7346875,
          73873.4684375,
          73830.97375,
          73365.4603125,
          73399.83859375,
          73361.65125,
          73456.7625,
          73632.88,
          73977.3565625,
          73728.30296875,
          73781.3378125,
          73550.9309375,
          73346.61703125,
          73071.775,
          72744.4046875,
          72599.76984375,
          72728.0478125,
          72444.9771875,
          72566.598125,
          73130.3846875,
          73327.046875,
          73040.3046875,
          73034.9190625,
          72895.17015625,
          72924.970625,
          72867.13140625,
          72757.8475,
          72663.3525,
          73088.43140625,
          73271.35578125,
          73384.41015625,
          73146.5521875,
          73276.72015625,
          73745.2975,
          73455.99671875,
          73597.8703125,
          73298.34375,
          72957.70859375,
          73162.0990625,
          72922.42875,
          72966.394375,
          72908.0103125,
          73390.3203125,
          73494.4396875,
          73142.77765625,
          73378.289375,
          73113.306875,
          72767.17890625,
          72625.71,
          72943.76234375,
          73006.91671875,
          72912.4540625,
          72838.32109375,
          72982.091875,
          72863.24546875,
          72768.239375,
          72989.36625,
          72626.34359375,
          72898.31484375,
          72905.70578125,
          72835.528125,
          72839.2703125,
          72711.35953125,
          72859.15390625,
          73228.20984375,
          73269.53765625,
          73160.705625,
          73328.60359375,
          72996.6771875,
          72908.664375,
          73090.5925,
          72779.541875,
          72869.79125,
          73194.09078125,
          73480.606875,
          73794.02734375,
          73825.84984375,
          73576.0640625,
          73464.01875,
          73304.57484375,
          73502.874375,
          73844.65640625,
          73985.61265625,
          73655.385625,
          73582.68796875,
          73197.08140625,
          72976.4221875,
          73509.8940625,
          73191.11703125,
          73064.483125,
          73083.31953125,
          73204.1078125,
          73252.53640625,
          73041.800625,
          73351.9178125,
          73113.57609375,
          73634.439375,
          73015.8403125,
          73046.78921875,
          72895.25859375,
          72648.22109375,
          72436.8778125,
          72580.545625,
          72682.3378125,
          72773.04109375,
          73404.1628125,
          73802.2240625,
          73340.831875,
          73639.6153125,
          73324.42640625,
          73328.726875,
          73281.1403125,
          73217.0325,
          73452.8053125,
          73414.33875,
          73705.2703125,
          73397.7465625,
          73285.19375,
          73262.984375,
          73294.019375,
          73047.116875,
          73021.803125,
          73112.8571875,
          73313.9353125,
          73562.974375,
          73030.7775,
          73024.0303125,
          73362.2328125,
          73194.4678125,
          73016.560625,
          72841.826875,
          73029.0971875,
          72959.8196875,
          72857.6428125,
          72558.83625,
          72812.25375,
          72815.479375,
          72924.966875,
          72969.986875,
          73045.4484375,
          73245.603125,
          73656.1221875,
          73459.4990625,
          73450.5678125,
          73648.6,
          73353.5275,
          73497.13,
          73199.18125,
          73098.8325,
          72724.8065625,
          72587.9853125,
          72780.7371875,
          72346.38390625,
          72507.47171875,
          72472.37296875,
          72388.7140625,
          72730.9215625,
          73046.793125,
          73388.9653125,
          73178.7165625,
          73122.5209375,
          73605.255,
          73501.561875,
          73390.6178125,
          73461.51875,
          73333.669375,
          72892.75828125,
          72799.63046875,
          72741.69125,
          72876.8003125,
          72846.82875,
          73222.9778125,
          73415.8459375,
          73193.565625,
          73467.670625,
          73913.0678125,
          73915.2046875,
          73829.1453125,
          74212.5571875,
          74321.2978125,
          74324.0925,
          74297.0853125,
          74684.4809375,
          74823.228125,
          74991.114375,
          74633.0090625,
          74535.3671875,
          74378.0715625,
          74425.004375,
          74764.268125,
          74317.775625,
          74222.131875,
          73986.2584375,
          73696.8871875,
          73513.74125,
          73548.776875,
          73342.9046875,
          73493.479375,
          73941.638125,
          73803.19875,
          73832.776875,
          73497.57,
          73681.1628125,
          73695.8590625,
          73669.98984375,
          73612.08078125,
          74155.80640625,
          74228.3475,
          74114.5040625,
          74401.9621875,
          74382.9121875,
          73900.25546875,
          73771.84265625,
          73639.47375,
          73403.7228125,
          73187.75953125,
          73124.05546875,
          73123.63484375,
          73132.17328125,
          73127.5190625,
          72993.21421875,
          73134.36796875,
          73013.5028125,
          72974.48640625,
          72820.4275,
          72709.86953125,
          72649.45046875,
          72680.205625,
          72506.3253125,
          72450.69671875,
          72340.03015625,
          72522.52125,
          72564.45640625,
          72480.6128125,
          72575.9590625,
          72645.1978125,
          72631.8165625,
          72543.904375,
          72425.9840625,
          72547.70421875,
          72328.94640625,
          72371.9984375,
          72496.28171875,
          72447.158125,
          72502.5925,
          72629.175625,
          72512.9778125,
          72529.6603125,
          72507.966875,
          72553.4284375,
          72513.8553125,
          72464.87375,
          72600.33375,
          72595.9115625,
          72529.08796875,
          72739.87375,
          72731.919375,
          72807.953125,
          72864.70171875,
          72746.5228125,
          72895.49875,
          72870.3946875,
          72927.015625,
          73007.1921875,
          73144.88875,
          73307.8759375,
          73502.5834375,
          73488.41015625,
          73544.2375,
          73660.341875,
          73635.375,
          73701.18546875,
          73575.23921875,
          73456.6415625,
          73647.46984375,
          73599.25015625,
          73485.5034375,
          73547.57984375,
          73574.27390625,
          73720.735625,
          73721.68640625,
          73939.594375,
          73957.1440625,
          73934.701875,
          73880.3109375,
          73851.36,
          73782.25859375,
          73814.555625,
          73902.438125,
          73891.75859375,
          74005.9521875,
          74047.78875
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=recon_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "recon_loss",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "recon_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          1.0018679491678875,
          1.0005699157714845,
          1.0002669016520183,
          1.0001737594604492,
          1.0002146132787069,
          1.0006205701828004,
          1.0008642959594727,
          1.0026723130544026,
          1.0011580181121826,
          1.0013458522160847,
          1.000785036087036,
          1.002058170636495,
          1.0015366315841674,
          1.0024389584859212,
          1.0025115315119426,
          1.0028333934148153,
          1.0040722187360127,
          1.0045051336288453,
          1.0100777339935303,
          1.0095564786593119,
          1.0049007352193196,
          1.0103706900278728,
          1.0092712910970052,
          1.019628767967224,
          1.0249752187728882,
          1.0238105591138205,
          1.0861022408803305,
          1.0382488505045573,
          1.0890758959452311,
          1.134681879679362,
          1.0844562117258707,
          1.1568690474828085,
          1.1036998812357586,
          1.1626574023564658,
          1.1031957753499348,
          1.5434886233011882,
          1.1807013034820557,
          1.2020085779825846,
          1.2230468734105429,
          1.271101427078247,
          1.2944107230504354,
          1.65332901318868,
          1.4447868156433106,
          1.4481195418039958,
          1.7566146755218506,
          1.8334509023030598,
          1.372846934000651,
          1.3719866975148518,
          1.4494589535395304,
          1.4773633321126303,
          1.63237242380778,
          1.4060899178187052,
          1.5031846745808919,
          1.6758321110407512,
          1.4796179262797038,
          1.8195405197143555,
          1.704581044514974,
          1.8665703550974528,
          2.1520600001017254,
          1.5659980297088623,
          1.7360690593719483,
          1.899407065709432,
          1.6626938120524088,
          1.7896603933970134,
          1.5670149866739909,
          2.2807653967539467,
          1.461445229848226,
          1.824193247159322,
          1.4935031429926555,
          1.6853287712732952,
          1.9750981267293295,
          1.396763547261556,
          2.3600816535949707,
          1.7332740275065104,
          1.3390771134694417,
          1.5099175961812337,
          1.489498167037964,
          1.7367761929829915,
          1.702704521814982,
          1.6597353410720825,
          1.7105198987325032,
          1.8546261501312256,
          1.6540703837076822,
          2.0230352290471396,
          1.6817968495686848,
          1.4529126358032227,
          1.8766911872227987,
          1.4393246873219807,
          1.8702278518676758,
          1.7570554320017497,
          1.8263216416041057,
          1.4951345507303875,
          1.4642489433288575,
          4.7542405128479,
          1.267212454477946,
          2.604272247950236,
          1.5127761618296305,
          1.7529038190841675,
          1.2900115394592284,
          1.2355995273590088,
          1.2822889232635497,
          1.4771339019139609,
          1.4884674342473347,
          1.6196563243865967,
          1.970241494178772,
          1.8985046243667603,
          1.4368842840194702,
          1.4545924599965414,
          1.5729171387354532,
          1.5771553611755371,
          1.6297368335723876,
          1.572875944773356,
          1.9367921956380207,
          1.4826956780751546,
          1.622231429417928,
          1.2003121089935302,
          1.656252040863037,
          1.2630471102396648,
          1.5402773507436116,
          1.4264338175455729,
          1.377687463760376,
          1.456620216369629,
          1.1846060530344644,
          1.644944772720337,
          1.242437014579773,
          1.8221053727467855,
          1.3321072244644165,
          1.2711715014775593,
          1.2192940139770507,
          1.345114638010661,
          1.2170794709523518,
          1.2818077087402344,
          1.4186254930496216,
          1.4280665667851766,
          1.251408748626709,
          1.4599261379241943,
          1.215713356335958,
          1.3070403083165487,
          1.1448937956492107,
          1.3784188588460287,
          1.2710946464538575,
          1.130024340947469,
          1.623704571723938,
          1.1644835392634074,
          1.2192198022206624,
          1.211043093999227,
          1.1356567064921061,
          1.3173129383722941,
          1.1646276028951008,
          1.099033946990967,
          1.1883165041605632,
          1.3728739134470622,
          1.1673870770136516,
          1.1520631710688274,
          1.1579383754730224,
          1.109669431845347,
          1.093615681330363,
          1.1665093533198039,
          1.1972219149271648,
          1.2637074534098307,
          1.1762523301442465,
          1.1230742931365967,
          1.2031758085886637,
          1.128508644104004,
          1.158216775258382,
          1.1594090843200684,
          1.351707592010498,
          1.0921820751825968,
          1.1797002840042115,
          1.087089729309082,
          1.133890479405721,
          1.0772209787368774,
          1.1529730319976808,
          1.1394353723526,
          1.1269214502970377,
          1.195827256043752,
          1.2174823141098023,
          1.1494298807779948,
          1.092083125114441,
          1.1086115630467732,
          1.1728161112467448,
          1.1190747117996216,
          1.285555518468221,
          1.143884220123291,
          1.1765674034754434,
          1.198766450881958,
          1.1745837910970052,
          1.3411010519663493,
          1.048290139834086,
          1.0763554906845092,
          1.1202571074167886,
          1.171322832107544,
          1.0524964427947998,
          1.1027173852920533,
          1.0665806357065837,
          1.1320506223042806,
          1.0698904991149902,
          1.2664908011754354,
          1.1798452711105347,
          1.1174236257870993,
          1.1083261744181314,
          1.1194398196538289,
          1.0789164574941,
          1.0985385529200236,
          1.10783234278361,
          1.078417355219523,
          1.1052768882115682,
          1.1046496057510375,
          1.1047903108596802,
          1.0703109455108644,
          1.0941564019521077,
          1.2513256120681762,
          1.1766713889439901,
          1.1143889300028482,
          1.0555068159103393,
          1.040579522450765,
          1.1370863087972005,
          1.0477836012840271,
          1.0582223828633626,
          1.0433649285634359,
          1.0815027952194214,
          1.0472620137532551,
          1.077353450457255,
          1.0883753824234008,
          1.0796329561869304,
          1.0463937520980835,
          1.1616900658607483,
          1.054632577896118,
          1.0926062933603922,
          1.0481117137273153,
          1.0456342601776123,
          1.0331835921605428,
          1.04883785088857,
          1.078271697362264,
          1.0603453985850015,
          1.0445708497365316,
          1.0671961530049643,
          1.0477720085779827,
          1.0559153318405152,
          1.1156367937723795,
          1.0483805878957113,
          1.1380926688512167,
          1.0850897518793743,
          1.0234582583109537,
          1.0794577169418336,
          1.045476999282837,
          1.0599520794550579,
          1.0557424465815226,
          1.033008213043213,
          1.047758560180664,
          1.0223154560724894,
          1.032402834892273,
          1.0351556428273518,
          1.0293797254562378,
          1.0472494268417358,
          1.088079603513082,
          1.0281108697255452,
          1.0208029476801554,
          1.0353398497899373,
          1.0417671060562135,
          1.059585353533427,
          1.035161329905192,
          1.0509707180658976,
          1.0290661986668905,
          1.050396146774292,
          1.041790033976237,
          1.0707469129562377,
          1.0323522758483887,
          1.0216295512517293,
          1.0291302712758381,
          1.02966251373291,
          1.0259766085942585,
          1.0179850053787232,
          1.022007902463277,
          1.025437847773234,
          1.0314162349700928,
          1.0178501256306967,
          1.0264665428797404,
          1.0207688919703166,
          1.064085750579834,
          1.0344489940007529,
          1.0357866112391154,
          1.0129667552312216,
          1.0245814355214438,
          1.0206704092025758,
          1.0186613591512044,
          1.0124859015146892,
          1.0268891509373983,
          1.0203914101918539,
          1.0201776202519734,
          1.0112624279658,
          1.0163676786422728,
          1.058849171002706,
          1.0261278374989828,
          1.0087864033381144,
          1.0184157943725587,
          1.0183832852045696,
          1.0080313110351562,
          1.011539543469747,
          1.0133295933405557,
          1.0153070418039958,
          1.007191883722941,
          1.011616800626119,
          1.0156360292434692,
          1.011041096051534,
          1.0078641764322918,
          1.0089485724767049,
          1.0077870400746662,
          1.0065758482615152,
          1.0042322619756063,
          1.0067999410629271,
          1.0095774984359742,
          1.004087085723877,
          1.0056035614013672,
          1.0107044013341269,
          1.0045416657129924,
          1.0052136421203612,
          1.003069477081299,
          1.0077926365534464,
          1.0027443250020345,
          1.0082588489850361,
          1.0100824848810832,
          1.012589135169983,
          1.0066093007723491,
          1.0039090712865193,
          1.0052792739868164,
          1.0074106725056966,
          1.0012923860549927,
          1.0144070355097452,
          1.0035508195559184,
          1.0019693930943807,
          1.004429357846578,
          1.0150095558166503,
          1.0076793940862019,
          1.0021394427617392,
          1.0066778103510539,
          1.004074403444926,
          1.0075111865997315,
          1.0045646492640177,
          1.0034643642107646,
          1.0027724885940552,
          1.0010696617762247,
          1.0024642276763915,
          1.0065255006154379,
          1.001956094900767,
          1.0006595182418823,
          1.0007012780507405,
          1.0061791928609212,
          1.0012896649042766,
          1.0044314384460449,
          1.0004965241750081,
          1.001959745089213,
          1.0003659868240355,
          1.000775980949402,
          1.0012342929840088,
          1.000593458811442,
          1.0000468397140503,
          1.0000379745165506,
          1.0000537633895874,
          1.0006914631525676,
          1.0027825013796487,
          0.9999805434544882,
          0.9999759817123413,
          1.0003868850072224,
          0.9999968210856119,
          1.0010360288619995,
          1.000878750483195,
          1.000034159819285,
          1.0004045454661052,
          1.000672550201416,
          1.0011845445632934,
          0.9998294281959533,
          1.0015591351191202,
          0.9998059701919556,
          1.0003197693824768,
          0.999962306022644,
          1.0024949725468952,
          1.0004144803682964,
          0.9999211740493774,
          1.0001492341359457,
          1.0001824021339416,
          1.000097476641337,
          1.0003281132380168,
          1.0001931381225586,
          1.0000316190719605,
          1.0000976832707722,
          1.0012885888417562,
          0.99992240746816,
          1.00770747423172,
          0.9998207521438599,
          1.000311054388682,
          0.9996587483088175,
          1.0007124392191569,
          0.9999769473075867,
          1.000245238939921,
          1.000188830693563,
          0.9998613707224528,
          1.0019877338409424,
          0.9997022867202758,
          1.0005294450124105,
          0.9996778996785481,
          0.9999125909805298,
          1.0001727263132731,
          1.000637313524882,
          0.9996398735046387,
          1.000758457183838,
          0.9996692204475403,
          1.0001433157920838,
          1.0021663363774618,
          0.999969121615092,
          0.999815289179484,
          1.0003306611378988,
          0.999815723101298,
          0.9996118927001953,
          0.9998683015505473,
          0.9999867145220439,
          0.9998104484875997,
          1.0068851312001545,
          0.9997949679692586,
          1.0020756006240845,
          0.9995758040746053,
          1.0000246826807657,
          0.9996913655598958,
          0.9999254854520162,
          0.9995523198445638,
          1.0003209733963012,
          0.9998635164896648,
          0.9997277863820394,
          0.9997707351048788,
          0.9996893739700318,
          0.9997193209330241,
          0.9998050959904988,
          0.9997441220283508,
          0.999618779818217,
          0.9996533759435018,
          0.9996918662389119,
          0.9997456312179566,
          0.9996581570307413,
          0.9995837839444478,
          0.9999515247344971,
          0.9995842464764912,
          0.9996768649419149,
          0.9998502508799235,
          0.9996487172444661,
          0.9997680759429932,
          0.9997247886657715,
          0.9999560038248698,
          0.9995790878931682,
          0.9998268890380859,
          0.999623072942098,
          1.000076620578766,
          0.9996002467473348,
          0.9996448087692261,
          0.9996601104736328,
          0.9999126354853313,
          0.9996909825007121,
          0.9996048482259114,
          0.9998581949869791,
          0.999749460220337,
          0.9998112424214681,
          0.9996341371536255,
          0.9997264115015666,
          0.9997418228785196,
          0.9997537835439047,
          0.9997972393035889,
          0.9996352195739746,
          0.9996548557281494,
          0.9996437295277913,
          0.9996235672632853,
          0.9996285231908163,
          0.9996010891596476,
          0.9996726989746094,
          0.9996024703979492,
          0.9996578073501587,
          0.9995437733332316,
          0.9995845063527425,
          0.9997840070724487,
          0.9995793120066325,
          0.9996641254425049,
          0.9996333154042562,
          0.9996147966384887,
          0.9996482753753662,
          0.9995995457967123,
          0.9996162780125936,
          0.999597487449646,
          1.0002828884124755,
          1.0000256745020548,
          0.9997890003522237,
          0.9995947233835856,
          0.9999241026242575,
          0.9996090046564738,
          0.9996202468872071,
          0.9996872313817342,
          0.9997442340850831,
          0.9996142919858296,
          1.0001628176371256,
          0.9995338900883992,
          0.9996372524897258,
          1.0000496753056844,
          0.9997205018997193
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "type=val_recon_loss<br>step=%{x}<br>loss_value=%{y}<extra></extra>",
         "legendgroup": "val_recon_loss",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "val_recon_loss",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "xaxis": "x",
         "y": [
          1.3152224349975585,
          1.2738205146789552,
          1.5677404832839965,
          1.4179745292663575,
          1.3026998805999757,
          1.1927723646163941,
          1.2130167055130006,
          1.1858676528930665,
          1.233915033340454,
          1.1360268688201904,
          1.173934087753296,
          1.2948563194274902,
          1.406879997253418,
          1.2145398473739624,
          1.0996821928024292,
          1.1744693470001222,
          1.1498979663848876,
          1.3386289405822753,
          1.1472416877746583,
          1.1352127933502196,
          1.1208770084381103,
          1.376277027130127,
          1.575915117263794,
          3.2776939868927,
          1.6604274129867553,
          1.5419894504547118,
          1.7360133743286132,
          1.8180601024627685,
          2.474304676055908,
          9.55720245361328,
          13.545050630569458,
          12.066212711334229,
          2.2225065279006957,
          3.081105365753174,
          3.9613462829589845,
          20.51692337036133,
          6.290240230560303,
          4.285200252532959,
          2.5795051670074463,
          3.822089729309082,
          5.648654499053955,
          2.25596321105957,
          3.503062620162964,
          28.205886917114256,
          9.606924934387207,
          3.152035665512085,
          13.228690700531006,
          37.7032246017456,
          5.0576432418823245,
          3.6101795482635497,
          10.18431074142456,
          14.812412576675415,
          9.973266277313233,
          3.065827932357788,
          11.420066051483154,
          8.18243465423584,
          2.7934103202819824,
          2.469169788360596,
          8.4774880027771,
          3.547613334655762,
          4.591474742889404,
          3.563979606628418,
          1.411155366897583,
          3.811689920425415,
          1.2759781169891358,
          1.6600790882110597,
          1.7439566516876222,
          1.4017384433746338,
          2.4331925106048584,
          3.8026766204833984,
          1.9368718242645264,
          2.363266487121582,
          1.5570807838439942,
          2.7853050327301023,
          1.1740190553665162,
          2.0969230842590334,
          1.4022914123535157,
          1.5450886631011962,
          1.3872078895568847,
          1.1940038585662842,
          1.9255898666381837,
          1.3515348434448242,
          1.2832333469390869,
          1.1871013832092285,
          1.8160023307800293,
          1.8014752388000488,
          1.6241419982910157,
          1.441867733001709,
          1.7608247661590577,
          1.2160872077941896,
          2.1089790534973143,
          2.8647259044647218,
          1.648300199508667,
          1.097211742401123,
          3.192211933135986,
          1.270149164199829,
          1.300400686264038,
          1.9988041019439697,
          1.5318661499023438,
          1.7987461185455322,
          3.63964186668396,
          1.2128236103057861,
          1.149824209213257,
          2.9159680366516114,
          1.1777520275115967,
          1.1453031539916991,
          1.060347819328308,
          2.5871836853027346,
          1.0307702922821045,
          1.0277508068084718,
          1.035366611480713,
          3.6657232284545898,
          1.7372035312652587,
          1.045020523071289,
          1.0300041437149048,
          1.0490181493759154,
          1.0475677824020386,
          2.4350885200500487,
          1.2683752632141114,
          1.0603824996948241,
          1.0300610589981078,
          1.0374782466888428,
          1.0429107999801637,
          1.030483784675598,
          1.048089861869812,
          1.0974129772186278,
          1.0093959379196167,
          1.1645168018341066,
          1.0455314016342163,
          1.0156102180480957,
          1.0042490434646607,
          1.0739534902572632,
          1.0543972110748292,
          1.0226574850082397,
          1.3116280937194824,
          1.0141210317611695,
          1.00733455657959,
          1.0146294260025024,
          1.0894306564331055,
          1.0273033666610718,
          1.010601143836975,
          1.017496213912964,
          1.0406795501708985,
          1.0712447214126586,
          1.0165846538543701,
          1.0523117065429688,
          1.0175163078308105,
          1.0391462326049805,
          1.0443213748931885,
          1.0756772041320801,
          1.0292230987548827,
          1.0181377172470092,
          1.006492533683777,
          1.0138325214385986,
          1.0365755939483643,
          1.0176242733001708,
          1.0221116685867309,
          1.0173663091659546,
          1.0215701103210448,
          1.1187869262695314,
          1.0071055221557617,
          1.0251143836975098,
          1.0497956943511964,
          1.0075886726379395,
          1.0086593532562256,
          1.0789254188537598,
          1.0209686803817748,
          1.008820972442627,
          1.0097637891769409,
          1.0375571489334106,
          1.0170463371276854,
          1.0079187154769897,
          1.0333718299865722,
          1.1642954063415527,
          1.0107667922973633,
          1.0108649158477783,
          1.0166569185256957,
          1.0400488376617432,
          1.0192173671722413,
          1.0082233190536498,
          1.0134928178787233,
          1.0074435663223267,
          1.0147904396057128,
          1.0065280246734618,
          1.0043412733078003,
          1.0053349447250366,
          1.0047418928146363,
          1.0122398471832275,
          1.01125648021698,
          1.0122004318237305,
          1.0151057767868041,
          1.0332924699783326,
          1.006236252784729,
          1.0065990924835204,
          1.0121802854537965,
          1.0065007257461547,
          1.0121046495437622,
          1.0100533390045165,
          1.0078158378601074,
          1.0089351987838746,
          1.0097874689102173,
          1.0463583040237427,
          1.0028832340240479,
          1.0067274713516234,
          1.0127098751068115,
          1.0292601537704469,
          1.0104401731491088,
          1.0315420627593994,
          1.0053855562210083,
          1.0086660146713258,
          1.0103273344039918,
          1.011767978668213,
          1.0058032512664794,
          1.0372368335723876,
          1.0047814130783081,
          1.0090579795837402,
          1.007330093383789,
          1.0073952722549437,
          1.0059770822525025,
          1.0182396745681763,
          1.0051595973968506,
          1.0031856298446655,
          1.0058056545257568,
          1.0225757408142089,
          1.0062139987945558,
          1.0079697847366333,
          1.0043072605133057,
          1.006708130836487,
          1.0221943759918213,
          1.0045464372634887,
          1.0245472240447997,
          1.0031514692306518,
          1.0755773448944093,
          1.004116086959839,
          1.0070995426177978,
          1.00669527053833,
          1.0190164709091187,
          1.0077827882766723,
          1.00437096118927,
          1.006847529411316,
          1.0050553369522095,
          1.0058323907852174,
          1.004194736480713,
          1.004698739051819,
          1.0092705059051514,
          1.007028570175171,
          1.0069737672805785,
          1.0066740131378173,
          1.0065676403045654,
          1.0074958610534668,
          1.0048932361602783,
          1.005823211669922,
          1.0061030673980713,
          1.011858205795288,
          1.0200746059417725,
          1.0068250560760499,
          1.0059342527389525,
          1.0525703191757203,
          1.0096744775772095,
          1.0054502201080322,
          1.0041103601455688,
          1.0185148334503173,
          1.0123539113998412,
          1.0036253213882447,
          1.0141205310821533,
          1.004800500869751,
          1.0038383865356446,
          1.0058851718902588,
          1.0038589572906493,
          1.0046801042556763,
          1.0051094102859497,
          1.0069186639785768,
          1.0066130542755127,
          1.0053696155548095,
          1.0055051803588868,
          1.0040527963638306,
          1.0100942850112915,
          1.0050991296768188,
          1.003312153816223,
          1.0045954704284668,
          1.0035469436645508,
          1.004171314239502,
          1.0094779968261718,
          1.0040556383132935,
          1.0052524614334106,
          1.005477123260498,
          1.0041032123565674,
          1.0036721181869508,
          1.0036255645751953,
          1.004278645515442,
          1.0043921995162963,
          1.0035960626602174,
          1.0049518203735353,
          1.004015278816223,
          1.008958444595337,
          1.0046764945983886,
          1.0069339227676393,
          1.0111368942260741,
          1.0031050586700438,
          1.0027705383300782,
          1.003256278038025,
          1.004447536468506,
          1.0036293125152589,
          1.0052132844924926,
          1.0041051197052002,
          1.004886302947998,
          1.0042831325531005,
          1.003755078315735,
          1.0039203596115112,
          1.0039586448669433,
          1.0036321258544922,
          1.0043956184387206,
          1.0042130994796752,
          1.004956946372986,
          1.0047567987442017,
          1.0039832639694213,
          1.0047759914398193,
          1.0043014335632323,
          1.0035819149017333,
          1.0038793420791625,
          1.0035240983963012,
          1.0030828666687013,
          1.0035146045684815,
          1.0038029193878173,
          1.0040231513977051,
          1.0038914966583252,
          1.004150104522705,
          1.0066546058654786,
          1.0033753967285157,
          1.00421368598938,
          1.0042389678955077,
          1.0040751028060912,
          1.0039393281936646,
          1.0034163475036622,
          1.0044356822967528,
          1.0048974275588989,
          1.0045325994491576,
          1.0047765731811524,
          1.005332441329956,
          1.0051024770736694,
          1.0052658414840698,
          1.003732395172119,
          1.004599280357361,
          1.0135374355316162,
          1.0053509855270386,
          1.0053894662857055,
          1.0050688457489014,
          1.003152379989624,
          1.004244475364685,
          1.0045533466339112,
          1.0049456834793091,
          1.0040864086151122,
          1.005037660598755,
          1.003519139289856,
          1.0040278005599976,
          1.0041873407363893,
          1.0045892429351806,
          1.0036199045181275,
          1.0036111164093018,
          1.0056156921386719,
          1.0036358976364135,
          1.0036939573287964,
          1.0045835208892822,
          1.0045546770095826,
          1.0048051118850707,
          1.0041518926620483,
          1.0054925966262818,
          1.0041024589538574,
          1.004434642791748,
          1.003423924446106,
          1.0050410890579224,
          1.0044825315475463,
          1.0042833614349365,
          1.0036614036560059,
          1.0061082363128662,
          1.004289255142212,
          1.0044072628021241,
          1.003745436668396,
          1.0037915849685668,
          1.0046235704421997,
          1.0043171787261962,
          1.0046867895126343,
          1.0048335886001587,
          1.0045455884933472,
          1.0038683557510375,
          1.0049812984466553,
          1.0046768760681153,
          1.00401873588562,
          1.004923620223999,
          1.0048126554489136,
          1.0049551725387573,
          1.0050212860107421,
          1.004577488899231,
          1.0042201614379882,
          1.0050421857833862,
          1.0053289270401,
          1.0045472288131714,
          1.0046173238754272,
          1.0046417284011842,
          1.0048359251022339,
          1.004450888633728,
          1.0049737358093263,
          1.0061074209213257,
          1.004901041984558,
          1.0048568201065065,
          1.0048684883117676,
          1.0057092237472534,
          1.0045763635635376,
          1.0049285221099853,
          1.0055838012695313,
          1.0040910863876342,
          1.0047178602218627,
          1.0046004581451415,
          1.0049716567993163,
          1.004715209007263,
          1.0052870178222657,
          1.0042484378814698,
          1.0060660362243652,
          1.0049619007110595,
          1.0047625017166137,
          1.0052102756500245,
          1.0051134300231934,
          1.0050091791152953,
          1.0043751621246337,
          1.0046533489227294,
          1.0046827220916748,
          1.0052248334884644,
          1.0046328783035279,
          1.004246997833252,
          1.0052086591720581,
          1.0055268287658692,
          1.0042405796051026,
          1.005265245437622,
          1.0046987438201904,
          1.005745267868042,
          1.0043137168884277,
          1.0036790704727172,
          1.0048709535598754,
          1.0050438594818116,
          1.0053086853027344,
          1.0044833278656007,
          1.0057789516448974,
          1.0036196756362914,
          1.0061428594589232,
          1.0056082582473755,
          1.0037584352493285,
          1.0038330411911012,
          1.0034785318374633,
          1.0051260948181153,
          1.0051019096374512,
          1.0048058080673217,
          1.004665584564209,
          1.0043986082077025,
          1.0063645362854003,
          1.0052896213531495,
          1.0038397645950317,
          1.0064418172836305,
          1.004841160774231,
          1.0053963088989257,
          1.0041022491455078,
          1.0043880939483643,
          1.005607657432556,
          1.005236372947693,
          1.0048604202270508,
          1.0050464105606078,
          1.0048909521102904,
          1.003823013305664,
          1.0052341747283935,
          1.0049308776855468,
          1.0048658514022828,
          1.0047391891479491,
          1.0044424772262572,
          1.0041570520401002,
          1.0042369508743285,
          1.0035511684417724,
          1.0059101104736328,
          1.004082818031311,
          1.0050706434249879,
          1.0041845846176147,
          1.0042766857147216,
          1.0034603548049927,
          1.004774913787842,
          1.005416874885559,
          1.0055778455734252,
          1.005584831237793,
          1.0053428220748901,
          1.0052752351760865,
          1.0046002054214478,
          1.0050579690933228,
          1.0053788566589354,
          1.0045069169998169,
          1.0055307531356812,
          1.0049877595901489,
          1.0044250059127808,
          1.004221043586731,
          1.0044937992095948,
          1.0057865858078003,
          1.0052887535095214,
          1.0060311460494995,
          1.0049334049224854
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "step"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "loss_value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(plot_df_long, x=\"step\", y=\"loss_value\", color=\"type\", markers=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "And now I'll evaluate the model on train, valid, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 77031.4203125\n",
      "valid MSE: 74047.7875\n",
      "test MSE:  71776.60328125\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train MSE:\",\n",
    "    model.evaluate(X_train, {\"recon\": X_train, \"reg_output\": y_train}, verbose=0)[4],\n",
    ")\n",
    "print(\n",
    "    \"valid MSE:\",\n",
    "    model.evaluate(X_valid, {\"recon\": X_valid, \"reg_output\": y_valid}, verbose=0)[4],\n",
    ")\n",
    "print(\n",
    "    \"test MSE: \",\n",
    "    model.evaluate(X_test, {\"recon\": X_test, \"reg_output\": y_test}, verbose=0)[4],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsnet-mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
